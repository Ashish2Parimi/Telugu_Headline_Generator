{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish2Parimi/Telugu_Headline_Generator/blob/main/transformer_sentence_pice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lrkhV34tstz"
      },
      "source": [
        "# !pip install tensorflow_text\n",
        "# !pip install sentencepiece\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PqoYuxqvMmy"
      },
      "source": [
        "# import sentencepiece as spm\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=body --vocab_size=8000')\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=heading --vocab_size=2000')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuN0Do6PvMq5"
      },
      "source": [
        "import requests\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "url = 'https://github.com/Ashish2Parimi/Telugu_Headline_Generator/raw/main/data.model'\n",
        "bd_model = requests.get(url).content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGpvHdPt1wx"
      },
      "source": [
        "bd_tokenizer = text.SentencepieceTokenizer(bd_model, out_type=tf.string)\n",
        "hd_tokenizer = bd_tokenizer\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8dORzk1W5M",
        "outputId": "a80f0737-8b08-4018-be07-11b10228f3e6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# data = data.drop(['SNo','date','topic'],axis = 1)\n",
        "data.dropna(axis = 0,inplace = True)\n",
        "\n",
        "# data = data.applymap(lambda x:x.encode(encoding='UTF-8'))\n",
        "for i,b in enumerate(data['body'].values):\n",
        "    if len(b)>1000:\n",
        "        data.drop(i, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def format_data(data):\n",
        "    START = '÷'\n",
        "    END = '■'  \n",
        "       \n",
        "    data['body'] = START + ' ' + data['body'] + ' ' + END \n",
        "    data['heading'] = START + ' ' + data['heading'] + ' ' + END \n",
        "    \n",
        "    data = data.applymap(lambda x: str(x) if isinstance(x, int) or isinstance(x, float) else x)\n",
        "    data['heading'] = data['heading'].str.replace('\\d+', '')\n",
        "\n",
        "    data['body'] = data['body'].str.replace('\\d+', '')    \n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "data = format_data(data)\n",
        "data1 = data[4000:]\n",
        "\n",
        "data = data[:4000]\n",
        "target = data.pop('heading')\n",
        "data = data.pop('body')\n",
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values))\n",
        "len(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRSrT7Nrfpl5",
        "outputId": "e918278a-70c4-435b-fba4-f7693f5fcac8"
      },
      "source": [
        "val_examples = dataset.take(1000)\n",
        "val_examples\n",
        "train_examples = dataset.skip(1000)\n",
        "train_examples "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SkipDataset shapes: ((), ()), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5AnEFdyRxY",
        "outputId": "b3d86c2e-aad6-42d7-abc2-522675dc01c9"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(3).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    print(len(bd.decode('utf-8')))\n",
        "\n",
        "\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "327\n",
            "÷ న్యూఢిల్లీ, జనవరి : అమెరికా కొత్త అధ్యక్షుడుగా బాధ్యతలు చేపట్టిన డోనాల్డ్‌ ట్రంప్‌కు ప్రధాని మోదీ అభినందనలు తెలిపారు. శుక్రవారం రాత్రి ఆయన ట్వీట్‌ చేస్తూ, అమెరికాతో ద్వైపాక్షిక సంబంధాలు మరింత పటిష్ఠం కావాలని, సహకారం ఇంకా విస్తృతం కావాలని ఆకాంక్షించారు. ■\n",
            "256\n",
            "÷ న్యూఢిల్లీ, జూలై  (ఆంధ్రజ్యోతి): కేంద్ర పట్టణాభివృద్ధి శాఖమంత్రిగా రాజీనామ చేసిన ఎన్డీయే ఉప రాష్ట్రపతి అభ్యర్థి ఎం.వెంకయ్యనాయుడికు ఆ శాఖ ఉద్యోగులు సోమవారం ఘనంగా వీడ్కోలు పలికారు. వెంకయ్య మాట్లాడుతూ.. మూడేళ్లలో శాఖలో అందరితో అనుబంధం పెరిగిందని, అందరికీ అభినందనలు తెలిపారు. ■\n",
            "275\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్‌కు మోదీ అభినందనలు  ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEmDuhs0y4sK",
        "outputId": "3795c391-bb3f-4605-ab3e-ca4902cae8df"
      },
      "source": [
        "encoded = hd_tokenizer.tokenize(hd_examples)\n",
        "encoded = hd_tokenizer.string_to_id(encoded)\n",
        "\n",
        "for row in encoded.to_list():\n",
        "  print(row)\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 114, 94, 2064, 3412, 189, 288, 4, 9]\n",
            "[8, 305, 361, 54, 116, 5992, 4, 9]\n",
            "[8, 2629, 14, 1086, 31, 7291, 6, 326, 28, 4, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SvNtpapzNaT",
        "outputId": "21213988-e029-4793-8990-7cbd92c50e21"
      },
      "source": [
        "round_trip = hd_tokenizer.detokenize(encoded)\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్ కు మోదీ అభినందనలు ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7u5Oua-5PNw"
      },
      "source": [
        "def tokenize_pairs(bd, hd):\n",
        "    bd = bd_tokenizer.tokenize(bd)\n",
        "    bd = bd_tokenizer.string_to_id(bd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    bd = tf.dtypes.cast(bd.to_tensor(),dtype=tf.int64)\n",
        "\n",
        "    hd = hd_tokenizer.tokenize(hd)\n",
        "    hd = hd_tokenizer.string_to_id(hd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    hd = tf.dtypes.cast(hd.to_tensor(),dtype=tf.int64)\n",
        "    return bd, hd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5to2UKMU5vmS"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRK87iSP52lQ"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i2iAtT54GR"
      },
      "source": [
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8R7m5BvIIUv",
        "outputId": "f0821348-ba1b-4c58-bf9e-5021bded2884"
      },
      "source": [
        " for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "   print(inp)\n",
        "   print(tar)\n",
        "\n",
        "   break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[   8   75   39 ...    0    0    0]\n",
            " [   8 1078   74 ...    0    0    0]\n",
            " [   8 2052   39 ...    0    0    0]\n",
            " ...\n",
            " [   8  339    5 ...    0    0    0]\n",
            " [   8 3559 2106 ...    0    0    0]\n",
            " [   8  980  202 ...    0    0    0]], shape=(64, 293), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   8 6167 2639 ...    0    0    0]\n",
            " [   8 1194   70 ...    0    0    0]\n",
            " [   8 2052 3572 ...    0    0    0]\n",
            " ...\n",
            " [   8 1474   61 ...    0    0    0]\n",
            " [   8  116  753 ...    0    0    0]\n",
            " [   8  980  202 ...    0    0    0]], shape=(64, 23), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yNLTjK5_RU"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYuFQeC6KEE"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6JNulI_6LwJ"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAuKabZG6Oqp"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8Inwo16T0G"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print('Attention weights are:')\n",
        "  print(temp_attn)\n",
        "  print('Output is:')\n",
        "  print(temp_out)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IemyYhh6U2p"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxeYaMS6Yfz"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhZU_ZX6cNC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BybZGH6e56"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JAKvw26kaz"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_QxZ4F86m_j"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhnK1ldh6oHU"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1x5WqXz6tYz"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30T6ZjA6zTI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uULQomCC60px"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wTDJszGgBL"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giMDqhjdGidX"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpkBGsTHY_I"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYp4In7HbYk"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=bd_tokenizer.vocab_size(),\n",
        "    target_vocab_size=hd_tokenizer.vocab_size(),\n",
        "    pe_input=1000,\n",
        "    pe_target=100,\n",
        "    rate=dropout_rate)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlHUzTVH9s8"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdfpFpVICa1"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsqBRetsIFQG"
      },
      "source": [
        "EPOCHS = 60"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Y7APmcIGKi"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kou1RjYIOWg",
        "outputId": "070ea518-4902-4541-9aa8-893b9d9d7f49"
      },
      "source": [
        "import time\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.9845 Accuracy 0.0000\n",
            "Epoch 1 Loss 8.9265 Accuracy 0.0191\n",
            "Time taken for 1 epoch: 25.37 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.8219 Accuracy 0.0841\n",
            "Epoch 2 Loss 8.7090 Accuracy 0.0967\n",
            "Time taken for 1 epoch: 10.21 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 8.6216 Accuracy 0.0896\n",
            "Epoch 3 Loss 8.5032 Accuracy 0.0969\n",
            "Time taken for 1 epoch: 10.38 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 8.3670 Accuracy 0.0997\n",
            "Epoch 4 Loss 8.2310 Accuracy 0.0973\n",
            "Time taken for 1 epoch: 10.26 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 8.0387 Accuracy 0.1088\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 7.8776 Accuracy 0.1448\n",
            "Time taken for 1 epoch: 10.67 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 7.6915 Accuracy 0.1641\n",
            "Epoch 6 Loss 7.4720 Accuracy 0.1787\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 7.2710 Accuracy 0.1719\n",
            "Epoch 7 Loss 7.0967 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 10.52 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 6.8501 Accuracy 0.1836\n",
            "Epoch 8 Loss 6.7662 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 6.6295 Accuracy 0.1741\n",
            "Epoch 9 Loss 6.5076 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 6.4322 Accuracy 0.1790\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 6.3208 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 11.05 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 6.1993 Accuracy 0.1781\n",
            "Epoch 11 Loss 6.1765 Accuracy 0.1826\n",
            "Time taken for 1 epoch: 10.81 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 6.0343 Accuracy 0.1880\n",
            "Epoch 12 Loss 6.0484 Accuracy 0.1884\n",
            "Time taken for 1 epoch: 10.70 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.9466 Accuracy 0.1877\n",
            "Epoch 13 Loss 5.9325 Accuracy 0.1941\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 5.7635 Accuracy 0.2091\n",
            "Epoch 14 Loss 5.8089 Accuracy 0.2028\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 5.7808 Accuracy 0.2078\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 5.6871 Accuracy 0.2120\n",
            "Time taken for 1 epoch: 10.87 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 5.5443 Accuracy 0.2254\n",
            "Epoch 16 Loss 5.5642 Accuracy 0.2211\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 5.3243 Accuracy 0.2407\n",
            "Epoch 17 Loss 5.4426 Accuracy 0.2284\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 5.3729 Accuracy 0.2330\n",
            "Epoch 18 Loss 5.3217 Accuracy 0.2374\n",
            "Time taken for 1 epoch: 10.63 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 5.3211 Accuracy 0.2342\n",
            "Epoch 19 Loss 5.1950 Accuracy 0.2455\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 5.0380 Accuracy 0.2547\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 5.0752 Accuracy 0.2558\n",
            "Time taken for 1 epoch: 10.96 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 5.0374 Accuracy 0.2537\n",
            "Epoch 21 Loss 4.9335 Accuracy 0.2677\n",
            "Time taken for 1 epoch: 10.65 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 4.8381 Accuracy 0.2735\n",
            "Epoch 22 Loss 4.8056 Accuracy 0.2756\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 4.6044 Accuracy 0.3015\n",
            "Epoch 23 Loss 4.6826 Accuracy 0.2867\n",
            "Time taken for 1 epoch: 10.68 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 4.5648 Accuracy 0.2981\n",
            "Epoch 24 Loss 4.5479 Accuracy 0.2980\n",
            "Time taken for 1 epoch: 10.60 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 4.4337 Accuracy 0.3079\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 4.4223 Accuracy 0.3082\n",
            "Time taken for 1 epoch: 10.93 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 4.3666 Accuracy 0.3130\n",
            "Epoch 26 Loss 4.3002 Accuracy 0.3179\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 4.1701 Accuracy 0.3256\n",
            "Epoch 27 Loss 4.1646 Accuracy 0.3277\n",
            "Time taken for 1 epoch: 10.72 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 4.0007 Accuracy 0.3366\n",
            "Epoch 28 Loss 4.0285 Accuracy 0.3420\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 3.8987 Accuracy 0.3755\n",
            "Epoch 29 Loss 3.9020 Accuracy 0.3556\n",
            "Time taken for 1 epoch: 10.63 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 3.8592 Accuracy 0.3687\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
            "Epoch 30 Loss 3.7642 Accuracy 0.3660\n",
            "Time taken for 1 epoch: 10.89 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 3.6472 Accuracy 0.3960\n",
            "Epoch 31 Loss 3.6272 Accuracy 0.3801\n",
            "Time taken for 1 epoch: 10.67 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 3.5144 Accuracy 0.3935\n",
            "Epoch 32 Loss 3.4885 Accuracy 0.3957\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 3.3592 Accuracy 0.4055\n",
            "Epoch 33 Loss 3.3476 Accuracy 0.4092\n",
            "Time taken for 1 epoch: 10.66 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 3.1952 Accuracy 0.4259\n",
            "Epoch 34 Loss 3.2137 Accuracy 0.4248\n",
            "Time taken for 1 epoch: 10.70 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 2.9426 Accuracy 0.4829\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-7\n",
            "Epoch 35 Loss 3.0562 Accuracy 0.4471\n",
            "Time taken for 1 epoch: 10.80 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.9833 Accuracy 0.4495\n",
            "Epoch 36 Loss 2.9102 Accuracy 0.4636\n",
            "Time taken for 1 epoch: 10.58 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.7331 Accuracy 0.4870\n",
            "Epoch 37 Loss 2.7601 Accuracy 0.4819\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.5890 Accuracy 0.4866\n",
            "Epoch 38 Loss 2.6356 Accuracy 0.4985\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.5158 Accuracy 0.5153\n",
            "Epoch 39 Loss 2.4747 Accuracy 0.5252\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.3366 Accuracy 0.5714\n",
            "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-8\n",
            "Epoch 40 Loss 2.3322 Accuracy 0.5506\n",
            "Time taken for 1 epoch: 10.86 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 2.1839 Accuracy 0.5851\n",
            "Epoch 41 Loss 2.1829 Accuracy 0.5722\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 1.9811 Accuracy 0.6010\n",
            "Epoch 42 Loss 2.0290 Accuracy 0.6014\n",
            "Time taken for 1 epoch: 10.70 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 1.8072 Accuracy 0.6366\n",
            "Epoch 43 Loss 1.8777 Accuracy 0.6285\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 1.6255 Accuracy 0.6997\n",
            "Epoch 44 Loss 1.7258 Accuracy 0.6569\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.5794 Accuracy 0.7049\n",
            "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-9\n",
            "Epoch 45 Loss 1.5784 Accuracy 0.6864\n",
            "Time taken for 1 epoch: 10.82 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 1.3770 Accuracy 0.7168\n",
            "Epoch 46 Loss 1.4453 Accuracy 0.7143\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 1.2254 Accuracy 0.7597\n",
            "Epoch 47 Loss 1.3081 Accuracy 0.7417\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 1.1273 Accuracy 0.8013\n",
            "Epoch 48 Loss 1.1903 Accuracy 0.7662\n",
            "Time taken for 1 epoch: 10.48 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 1.0684 Accuracy 0.7738\n",
            "Epoch 49 Loss 1.0565 Accuracy 0.7924\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.9034 Accuracy 0.8249\n",
            "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-10\n",
            "Epoch 50 Loss 0.9388 Accuracy 0.8166\n",
            "Time taken for 1 epoch: 10.85 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.7665 Accuracy 0.8477\n",
            "Epoch 51 Loss 0.8430 Accuracy 0.8336\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.6767 Accuracy 0.8931\n",
            "Epoch 52 Loss 0.7357 Accuracy 0.8572\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.6236 Accuracy 0.8719\n",
            "Epoch 53 Loss 0.6555 Accuracy 0.8700\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.5480 Accuracy 0.8975\n",
            "Epoch 54 Loss 0.5971 Accuracy 0.8799\n",
            "Time taken for 1 epoch: 10.64 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.4792 Accuracy 0.9125\n",
            "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-11\n",
            "Epoch 55 Loss 0.5336 Accuracy 0.8923\n",
            "Time taken for 1 epoch: 10.82 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.4145 Accuracy 0.9208\n",
            "Epoch 56 Loss 0.4856 Accuracy 0.9009\n",
            "Time taken for 1 epoch: 10.68 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.4384 Accuracy 0.9015\n",
            "Epoch 57 Loss 0.4197 Accuracy 0.9137\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.3224 Accuracy 0.9594\n",
            "Epoch 58 Loss 0.3780 Accuracy 0.9214\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.2752 Accuracy 0.9402\n",
            "Epoch 59 Loss 0.3584 Accuracy 0.9224\n",
            "Time taken for 1 epoch: 10.64 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.2721 Accuracy 0.9510\n",
            "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-12\n",
            "Epoch 60 Loss 0.3220 Accuracy 0.9297\n",
            "Time taken for 1 epoch: 10.86 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2yUqMbpSzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3dd667-86a9-4ac8-f391-45e3625d00f0"
      },
      "source": [
        "for bd_examples, hd_examples in val_examples.batch(1).take(7):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ : ఆర్థిక మంత్రి అరుణ్‌ జైట్లీ సోమవారం ప్రభుత్వ రంగ బ్యాంకుల(పిఎస్ బి) చీఫ్‌లతో సమావేశంకానున్నారు. దాదాపు రోజంతా జరిగే ఈ సమావేశంలో పిఎస్ బిలకు గుది బండగా మారిన మొండి బకాయి(ఎన్‌పిఎ)ల వసూళ్లపైనే ప్రధానంగా చర్చ జరుగుతుందని భావిస్తున్నారు. ఇంకా పిఎస్ బిల పనితీరు, ఒత్తిడిలో ఉన్న రుణాల పరిస్థితి, బ్యాలెన్స్‌ షీట్ల ప్రక్షాళన కోసం బ్యాంకులు తీసుకున్న చర్యలు కూడా చర్చకు రానున్నాయి. ఈ ఆర్థిక సంవత్సరం పిఎస్ బిల చీఫ్‌లతో జైట్లీ జరుపుతున్న తొలి సమావేశం ఇదే. మొండి బకాయిల వసూలు కోసం నాటి బ్యాంకింగ్‌ రెగ్యులేషన్‌ యాక్ట్‌ను సవరిస్తూ ఆర్డినెన్స్‌ జారీ చేశాక జరుగుతున్న ఈ భేటీకి మరింత ప్రాధాన్యత ఏర్పడింది. ఈ ఆర్డినెన్స్‌తో ఎన్‌పిఎల వసూళ్ల కోసం చర్యలు తీసుకోవాలని బ్యాంకులను ఆదేశించే అధికారం ఆర్‌బిఐకి ఏర్పడింది. ఇంకా ఈ సమావేశంలో ప్రధాన మంత్రి జీవన్‌ జ్యోతి బీమా యోజన, ప్రధాన మంత్రి సురక్షా బీమా యోజన, అటల్‌ పెన్షన్‌ యోజన పథకాలపైనా సమీక్షించే అవకాశం ఉంది. ఈ సమావేశానికి ముందే జైట్లీ సార్వత్రిక కనీస ఆదాయం (యుబిఐ), బ్యాడ్‌ బ్యాంక్‌ ఏర్పాటుపై చర్చలు జరుగుతున్నట్టు చెప్పడం విశేషం. ■\n",
            "\n",
            "÷ బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ ■\n",
            "÷ కటక్: ఇంగ్లండ్‌తో జరుగుతున్న సెకండ్ వన్డే మ్యాచ్‌లో భారత జట్టు మూడో వికెట్ పడగొట్టింది.  పరుగులతో దూసుకెళుతున్న ఓపెనింగ్ బ్యాట్స్‌మన్ జాసన్ రాయ్‌ను జడేజా ఔట్ చేశాడు. వ ఓవర్ మొదటి బంతికి క్లీన్ బౌల్డ్ చేశాడు. దీంతో ఇంగ్లండ్ స్కోర్  ఓవర్లు ముగిసే సమయానికి /. మ్యాచ్ గెలిచేందుకు ఇంగ్లండ్ ఇంకా  పరుగులు చేయాల్సి ఉంది. ■\n",
            "\n",
            "÷ కీలక వికెట్ తీసిన జడేజా.. ■\n",
            "÷ \n",
            "ఇస్లామాబాద్ : పాకిస్థాన్ అంతర్జాతీయ ఉగ్రవాది హపీజ్ సయీద్‌ స్వేచ్ఛనిచ్చి, భారతదేశానికి ఆగ్రహం తెప్పించింది.  గంటలు గడవక ముందే మరో రెచ్చగొట్టే చర్యకు దిగింది. కశ్మీరు అంశంపై అంతర్జాతీయ న్యాయస్థానాన్ని ఆశ్రయిస్తామని పాకిస్థాన్ ప్రకటించింది. కశ్మీరులో నిత్యం మానవ హక్కుల ఉల్లంఘన జరుగుతోందని ఆరోపించింది. తమ నిఘా వర్గాల కనుసన్నల్లోనే ఉగ్రవాదులను తయారు చేసి భారతదేశంలోకి పంపిస్తున్న పాకిస్థాన్ తీవ్రమైన ఆరోపణలతో  భారతదేశంపై విరుచుకుపడటం చాలా దారుణం. మరోవైపు హఫీజ్ సయీద్ భారత వ్యతిరేక బహిరంగ సభలో త్వరలోనే మాట్లాడబోతున్నట్లు సమాచారం. ■\n",
            "\n",
            "÷ మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్ ■\n",
            "÷ స్టార్‌ హీరోగా వరుస సినిమాలతో బిజీగా ఉన్నప్పటికీ కుటుంబంతో గడిపే అవకాశాన్ని ఏ మాత్రం వదులుకోవడం లేదు ఇప్పటి సినిమా హీరోలు. ఖాళీగా ఉన్నప్పుడు కుటుంబంతో గడపడం స్టైలిష్‌స్టార్‌ అల్లు అర్జున్‌కు అలవాటు. వృతిపరమైన విషయాలనే కాకుండా వ్యక్తిగత విషయాలను కూడా సోషల్‌ మీడియా ద్వారా అభిమానులతో పంచుకోవడం కూడా బన్నీకి అలవాటు. ■\n",
            "\n",
            "÷ గోవాలో కొడుకుతో కలిసి అల్లు అర్జున్ స్విమ్మింగ్! ■\n",
            "÷ న్యూఢిల్లీ: బధిర యువతి గీతను తల్లిదండ్రుల చెంతకు చేర్చిన వారికి రూ.లక్ష నగదు అందజేస్తామని విదేశాంగ మంత్రి సుష్మాస్వరాజ్‌ ప్రకటించారు. భారత్‌కు చెందిన గీతను పదిహేనేళ్ల క్రితం లాహోర్‌లో ఆగి ఉన్న సంఝౌతా ఎక్స్‌ప్రె్‌సలో పాకిస్తాన్‌ సైనికులు గుర్తించారు. ప్రభుత్వం చొరవతో లో భారత్‌లో అడుగుపెట్టిన గీత ఇప్పటికీ తల్లిదండ్రులను చేరుకోలేకపోయింది. ■\n",
            "\n",
            "÷ గీత తల్లిదండ్రుల ఆచూకీ చెబితే లక్ష: సుష్మా ■\n",
            "÷ న్యూఢిల్లీ : కటక్‌ వన్డేలో శతకంన్నర కొట్టిన యువరాజ్ సింగ్ గురించి మాజీ క్రికెటర్ వీరేంద్ర సెహ్వాగ్ ఉద్వేగభరితమైన ట్వీట్ చేశాడు. ‘అతను క్యాన్సర్‌ను ఓడించాడు. ఇవాళ ఇంగ్లండ్ బౌలర్లను మాత్రమే ఓడించాడు. నిరాశ చెందకూడదని ప్రతి ఒక్కరూ నేర్చుకోవాల’ని వీరూ అన్నాడు. క్యాన్సర్‌తో యువీ ఆస్పత్రిలో చికిత్స పొందుతున్నప్పటి ఫొటో కూడా సెహ్వాగ్ పోస్ట్ చేశాడు.  ప్రపంచ కప్‌లో మ్యాన్ ఆఫ్ ది సిరీస్ అవార్డు అందుకున్న యువరాజ్.. అదే ఏడాది క్యాన్సర్ బారినపడ్డాడు. ఆ వ్యాధితో పోరాడి జయించి.. మళ్లీ మైదానంలో అడుగుపెట్టాడు.  ఏళ్ల యువీకి పలు అవకాశాలు వచ్చినా రాణించలేకపోయాడు. చివరకు రంజీలో తన ఫామ్‌ను, ఫిట్‌నెస్‌ను నిరూపించుకోవడంతో ఐసీసీ ఛాంపియన్స్ ట్రోఫీ ద‌ష్ట్యా చివరిదన్నట్లు ఇంగ్లండ్‌తో సిరీస్‌లో ఓ అవకాశం ఇచ్చారు. కటక్‌లో సింగ్ ఈజ్ కింగ్ అనిపించుకున్నాడు. ■\n",
            "\n",
            "÷ యువీ గురించి సెహ్వాగ్ ఉద్వేగభరిత ట్వీట్ ■\n",
            "÷ \n",
            "తళతళ మెరిసే తెల్ల గడ్డంతో ఉన్న ఈ వ్యక్తి టీమిండియా మాజీ కెప్టెన్‌ ధోనీ. విజయ్‌ హజారే ట్రోఫీలో భాగంగా కోల్‌కతా వేదికగా జార్ఖండ్‌-కర్ణాటక జట్ల మధ్య జరిగే మ్యాచ్‌కు ముందు ప్రాక్టీస్‌ సందర్భంగా మహీ ఇలా పూర్తిగా నెరిసిన గడ్డంతో కనిపించి అందర్నీ ఆశ్చర్యపరిచాడు. ■\n",
            "\n",
            "÷ తెల్ల గడ్డం తళతళ..  ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKkxxrUFr3A2"
      },
      "source": [
        "# sentence = tf.convert_to_tensor([sentence])\n",
        "# sentence = bd_tokenizer.tokenize(sentence)\n",
        "# sentence = bd_tokenizer.string_to_id(sentence)\n",
        "# sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "# encoder_input = sentence"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVJ-W4j_r915"
      },
      "source": [
        "# start  = tf.convert_to_tensor('÷')\n",
        "# start= hd_tokenizer.tokenize(start)\n",
        "# output= hd_tokenizer.string_to_id(start)\n",
        "# end  = tf.convert_to_tensor('■')\n",
        "# end= hd_tokenizer.tokenize(end)\n",
        "# end= hd_tokenizer.string_to_id(end)[1]\n",
        "\n",
        "# output = tf.expand_dims(output, 0)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBtarAoTsE2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d78cdc-c6fc-471f-d544-1c153d86269c"
      },
      "source": [
        "\n",
        "# for i in range(40):\n",
        "#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "#           encoder_input, output)\n",
        "#     predictions, attention_weights = transformer(encoder_input,\n",
        "#                                                 output,\n",
        "#                                                 False,\n",
        "#                                                 enc_padding_mask,\n",
        "#                                                 combined_mask,\n",
        "#                                                 dec_padding_mask)\n",
        "\n",
        "#     # select the last word from the seq_len dimension\n",
        "#     predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "#     predicted_id = tf.argmax(predictions, axis=-1)\n",
        "#     predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "#     # concatentate the predicted_id to the output which is given to the decoder\n",
        "#     # as its input.\n",
        "#     output = tf.concat([output, predicted_id], axis=-1)\n",
        "# print(predicted_id)\n",
        "# #     # return the result if the predicted_id is equal to the end token\n",
        "# print(predictions)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[3]], shape=(1, 1), dtype=int32)\n",
            "tf.Tensor([[[-2.865047  -2.8502512 -2.98355   ... -3.0287418 -2.8735874 -2.9504876]]], shape=(1, 1, 8000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQErqf_09DZ4"
      },
      "source": [
        "# text = hd_tokenizer.detokenize(output)\n",
        "# for x in text.numpy():\n",
        "#   print(x.decode('utf-8'))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_AL9W9qq12"
      },
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  # print(f'{\"Prediction\":15s}: { }')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxP2RGlqw0B"
      },
      "source": [
        "# print_translation(sentence,text, ground_truth)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIoL8wYncpc"
      },
      "source": [
        "def evaluate(sentence, max_length=40):\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  sentence = tf.convert_to_tensor([sentence])\n",
        "  sentence = bd_tokenizer.tokenize(sentence)\n",
        "  sentence = bd_tokenizer.string_to_id(sentence)\n",
        "  sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "  encoder_input = sentence\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  start  = tf.convert_to_tensor('÷')\n",
        "  start= hd_tokenizer.tokenize(start)\n",
        "  output= hd_tokenizer.string_to_id(start)\n",
        "  end  = tf.convert_to_tensor('■')\n",
        "  end= hd_tokenizer.tokenize(end)\n",
        "  end= hd_tokenizer.string_to_id(end)[1]\n",
        "  end = tf.expand_dims(end, 0)\n",
        "  output = tf.expand_dims(output, 0)\n",
        "  for i in range(max_length):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions, axis=-1)\n",
        "    predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == end:\n",
        "      break\n",
        "\n",
        "  # output.shape (1, tokens)\n",
        "  text = hd_tokenizer.detokenize(output)  # shape: ()\n",
        "\n",
        "\n",
        "  return text, attention_weights"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTkU2cv8rUIP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NyvAr-bX1Q0",
        "outputId": "efa06bbb-3f68-40c5-ed64-6b7b4a69a7fa"
      },
      "source": [
        "for x in translated_text.numpy():\n",
        "  print(x.decode('utf-8'))\n",
        "  "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ ధోనీ ఉండడం అదృష్టం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13JVpiD_ZPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6963473-3394-4eda-d880-7444fa6e70fa"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ \n",
            "తళతళ మెరిసే తెల్ల గడ్డంతో ఉన్న ఈ వ్యక్తి టీమిండియా మాజీ కెప్టెన్‌ ధోనీ. విజయ్‌ హజారే ట్రోఫీలో భాగంగా కోల్‌కతా వేదికగా జార్ఖండ్‌-కర్ణాటక జట్ల మధ్య జరిగే మ్యాచ్‌కు ముందు ప్రాక్టీస్‌ సందర్భంగా మహీ ఇలా పూర్తిగా నెరిసిన గడ్డంతో కనిపించి అందర్నీ ఆశ్చర్యపరిచాడు. ■\n",
            "Ground truth   : ÷ తెల్ల గడ్డం తళతళ..  ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIVJYOk3ecaw",
        "outputId": "ff9aaae9-f061-4afc-aefd-a6b829571739"
      },
      "source": [
        "target1 = data1.pop('heading')\n",
        "data1 = data1.pop('body')\n",
        "import tensorflow as tf\n",
        "test = tf.data.Dataset.from_tensor_slices((data1.values, target1.values))\n",
        "len(test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf64hwjefvE",
        "outputId": "4a46dd0c-bcbf-4fe9-9f64-00a5645c260d"
      },
      "source": [
        "for bd_examples, hd_examples in test.batch(1).take(7):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n",
            "÷ హైదరాబాద్: డ్రగ్స్, మందు అని మనం మాత్రమే అనుకుంటామని.... అర్జున్ రెడ్డి సినిమా చూసిన ప్రేక్షకుల మాత్రం చాలా బాగుందని హీరో విజయ్ దేవరకొండ అన్నారు. అర్జున్ రెడ్డి సినిమా వివాదంపై ఏబీఎన్ ఆంధ్రజ్యోతి లైవ్ షో నిర్వహించింది. ఈ కార్యక్రమంలో కాంగ్రెస్ ఎంపీ వీహెచ్‌తో పాటు  అర్జున్ రెడ్డి హీరో, దర్శకుడు పాల్గొన్నారు. సినిమా చూడని వాళ్లు మాత్రమే నిరసనలు  చేస్తున్నారని విజయ్ తెలిపారు. అర్జున్ రెడ్డి సినిమాలో చాలా సిగరెట్లు తాగానని.. బయట మాత్రం అలాంటి పనులు చేయనని చెప్పారు. చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదని అన్నారు. చాలా ప్రేమతో ఎంపీ వీహెచ్‌ను తాతయ్య అని అన్నానని..వాళ్ల మనవళ్లతో తిరుగుతాను కాబట్టే అలా అన్నానని విజయ్ తెలిపారు.తాతాయ్య అనడంలో బ్యాడ్ ఇన్ టెన్షన్ ఏమీ లేదని స్పష్టం చేశారు. ■\n",
            "\n",
            "÷ చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదు: విజయ్ దేవరకొండ ■\n",
            "÷ న్యూఢిల్లీ: షేన్‌ వార్న్‌ తన ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ జట్టుకు ధోనీని సారథిని చేసి గౌరవించాడు. ఈ మేరకు తన కలల ఐపీఎల్‌ జట్టును వార్న్‌ ప్రకటించాడు. విరాట్‌ కోహ్లీ, రోహిత శర్మ, యువరాజ్‌ సింగ్‌, రవీంద్ర జడేజా, హర్భజన్‌ సింగ్‌, ఉమేష్‌ యాదవ్‌లకు తన జట్టులో చోటు కల్పించాడు. విదేశీ ఆటగాళ్లుగా క్రిస్‌ గేల్‌, బ్రెండన్‌ మెకల్లమ్‌, జాక్‌ కలిస్‌, లసిత మలింగలను తీసుకున్నాడు. అలాగే విదేశీ కోటాలో ఒక్క ఆస్ర్టేలియా ఆటగాడిని కూడా వార్న్‌ తన జట్టులో చోటు కల్పించకపోవడం విశేషం. ■\n",
            "\n",
            "÷ వార్న్‌ ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ కెప్టెన్‌ ధోనీ  ■\n",
            "÷ తన ప్రతిష్టాత్మక వందో చిత్రమైన చారిత్రక సినిమా ‘గౌతమిపుత్ర శాతకర్ణి’ తెలుగు ప్రేక్షకులను మెప్పించడంతో బాలయ్య హర్షం వ్యక్తం చేస్తున్నారు. ఈ సందర్భంగా ‘ఏబీఎన్’తో ముచ్చటించిన బాలయ్య.. తన మనవడు దేవాన్ష్ గురించి ఆసక్తికర విషయాలను తెలియజేశారు. తన మనవడు దేవాన్ష్‌ గుర్రమంటే భయపడేవాడని, ఇప్పుడు తన సినిమా ‘శాతకర్ణి’ చూశాక ఆ భయం పోయి.. వాళ్ల అమ్మ కొనిచ్చిన గుర్రం బొమ్మపై ఎక్కి దాన్ని తోలుతున్నట్లు ఫీలయి సంతోషపడుతున్నాడని బాలయ్య చెప్పారు. తామిద్దరం తోడుదొంగలమేనంటూ దేవాన్ష్ గురించి బాలయ్య చెప్పిన మరిన్ని ఆసక్తికర విశేషాలు పై వీడియోలో చూడండి. ■\n",
            "\n",
            "÷ మేమిద్దరం తోడు దొంగలమే: బాలకృష్ణ ■\n",
            "÷ న్యూఢిల్లీ: విదేశీ బ్యాంకుల్లో తన పేర ఉన్న ఖాతాలను మూసివేస్తున్నందునే కేంద్ర మాజీ మంత్రి పి.చిదంబరం తనయుడు కార్తి దేశం విడిచి వెళ్లకుండా లుకవుట్‌ నోటీసు జారీ చేశామని సీబీఐ సుప్రీం కోర్టుకు తెలిపింది. దర్యాప్తునకు సంబంధించిన పత్రాలను సీల్డ్‌ కవర్‌లో న్యాయస్థానానికి సమర్పిస్తామని సీబీఐ కోరింది. ఈ సందర్భంగా అడిషనల్‌ సొలిసిటర్‌ జనరల్‌ (ఏఎ్‌సజీ) తుషార్‌ మెహతా తన వాదన వినిపిస్తూ విదేశాల్లో తనకు ఒక్కటే బ్యాంకు ఖాతా ఉందని విచారణలో చెప్పిన కార్తి... విదేశాలకు వెళ్లినప్పుడు పలు ఖాతాలను మూసివేశాడని తెలిపారు. ■\n",
            "\n",
            "÷ విదేశీ ఖాతాలను మూసేసిన కార్తి ■\n",
            "÷ హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): తెలంగాణ రియల్‌ ఎస్టేట్‌ డెవలపర్స్‌ అసోసియేషన్‌ (ట్రెడా) కొత్త అధ్యక్షుడిగా పి రవీందర్‌ రావు ఎన్నికయ్యారు. శనివారం నాడిక్కడ జరిగిన వ వార్షిక సర్వసభ్య సమావేశంలో ఈ మేరకు కొత్త కార్యవర్గాన్ని ఎన్నుకున్నారు. ఎగ్జిక్యూటివ్‌ ఉపాధ్యక్షులుగా ఆర్‌ చలపతి రావు, విజయ్‌ సాయి, కార్యదర్శిగా సునీల్‌ చంద్రా రెడ్డి, కోశాధికారిగా కె శ్రీధర్‌ రెడ్డి ఎన్నికయ్యారు. రెండేళ్ల పాటు వీరు ఈ పదవిలో కొనసాగనున్నారు. ■\n",
            "\n",
            "÷ ట్రెడా అధ్యక్షుడిగా రవీందర్‌ రావు  ■\n",
            "÷ ప్రస్తుతం స్టైలిష్ స్టార్ అల్లుఅర్జున్.. హరీశ్ శంకర్ డైరెక్షన్‌లో దువ్వాడ జగన్నాథం సినిమా చేస్తున్నాడు. ఇటీవలే సినిమాలో బన్నీ లుక్, టీజర్‌ను విడుదల చేశారు. ఈ టీజర్ ఈ మధ్య ట్రెండింగ్ అయింది. దానికి కారణం వేరే చెప్పాల్సిన అవసరం లేదేమో. అయితే తాజాగా బన్నీపై మరో గాసిప్ వినిపిస్తోంది. డీజే తర్వాత బన్నీ డైరెక్టర్ కావాలనుకుంటున్న రైటర్ వక్కంతం వంశీకి చాన్స్ ఇచ్చాడని తెలిసిందే. ఇప్పుడు వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చే అవకాశాలున్నాయని చెబుతున్నారు. ఎందుకంటే.. మధ్యలోకి ఓ సీనియర్ మాస్ డైరెక్టర్ ఎంట్రీ ఇచ్చాడట. ఆ డైరెక్టర్ ఎవరో కాదు.. అల్లు అర్జున్‌తో బన్నీ, బద్రీనాథ్ వంటి చిత్రాలను తీసిన డైరెక్టర్ వీవీ వినాయక్. ఖైదీ నంబర్  సినిమా తర్వాత ఏ హీరోతోనూ సినిమా కమిట్ అవ్వని వినాయక్.. బన్నీకి ఓ కథను వినిపించాడట. ఆ కథ బన్నీకి తెగ నచ్చేసిందట. దీంతో వినాయక్‌తో సినిమా తీసేందుకు ఓకే చెప్పాడట బన్నీ. కానీ, వక్కంతం వంశీ సినిమాను పక్కనబెట్టేసి వినాయక్ మూవీనే మొదట పట్టాలెక్కించే పనిలో ఉన్నాడట బన్నీ. ఈ లెక్కన చూస్తుంటే వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చినట్టేనా మరి!!! ■\n",
            "\n",
            "÷ వక్కంతం వంశీని బన్నీ పక్కన పెట్టేశాడా? ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgqqMTR9ehrP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJmCqthoemF7",
        "outputId": "76b99b8f-a4e2-45de-87af-8b5fdfad4c01"
      },
      "source": [
        "for x in translated_text.numpy():\n",
        "  print(x.decode('utf-8'))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ సినిమా టైటిల్ తోనే చియాన్ విక్రమ్ కొడుకు సంచలనం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj6k4JYheo4G",
        "outputId": "bb3d417f-f7d0-4e4f-c6c3-f6118132c47c"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ ప్రస్తుతం స్టైలిష్ స్టార్ అల్లుఅర్జున్.. హరీశ్ శంకర్ డైరెక్షన్‌లో దువ్వాడ జగన్నాథం సినిమా చేస్తున్నాడు. ఇటీవలే సినిమాలో బన్నీ లుక్, టీజర్‌ను విడుదల చేశారు. ఈ టీజర్ ఈ మధ్య ట్రెండింగ్ అయింది. దానికి కారణం వేరే చెప్పాల్సిన అవసరం లేదేమో. అయితే తాజాగా బన్నీపై మరో గాసిప్ వినిపిస్తోంది. డీజే తర్వాత బన్నీ డైరెక్టర్ కావాలనుకుంటున్న రైటర్ వక్కంతం వంశీకి చాన్స్ ఇచ్చాడని తెలిసిందే. ఇప్పుడు వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చే అవకాశాలున్నాయని చెబుతున్నారు. ఎందుకంటే.. మధ్యలోకి ఓ సీనియర్ మాస్ డైరెక్టర్ ఎంట్రీ ఇచ్చాడట. ఆ డైరెక్టర్ ఎవరో కాదు.. అల్లు అర్జున్‌తో బన్నీ, బద్రీనాథ్ వంటి చిత్రాలను తీసిన డైరెక్టర్ వీవీ వినాయక్. ఖైదీ నంబర్  సినిమా తర్వాత ఏ హీరోతోనూ సినిమా కమిట్ అవ్వని వినాయక్.. బన్నీకి ఓ కథను వినిపించాడట. ఆ కథ బన్నీకి తెగ నచ్చేసిందట. దీంతో వినాయక్‌తో సినిమా తీసేందుకు ఓకే చెప్పాడట బన్నీ. కానీ, వక్కంతం వంశీ సినిమాను పక్కనబెట్టేసి వినాయక్ మూవీనే మొదట పట్టాలెక్కించే పనిలో ఉన్నాడట బన్నీ. ఈ లెక్కన చూస్తుంటే వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చినట్టేనా మరి!!! ■\n",
            "Ground truth   : ÷ వక్కంతం వంశీని బన్నీ పక్కన పెట్టేశాడా? ■\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}