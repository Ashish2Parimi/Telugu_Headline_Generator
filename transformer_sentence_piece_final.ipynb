{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish2Parimi/Telugu_Headline_Generator/blob/main/transformer_sentence_piece_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lrkhV34tstz"
      },
      "source": [
        "# !pip install tensorflow_text\n",
        "# !pip install sentencepiece\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PqoYuxqvMmy"
      },
      "source": [
        "# import sentencepiece as spm\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=body --vocab_size=8000')\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=heading --vocab_size=2000')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuN0Do6PvMq5"
      },
      "source": [
        "import requests\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "url = 'https://github.com/Ashish2Parimi/Telugu_Headline_Generator/raw/main/data.model'\n",
        "bd_model = requests.get(url).content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGpvHdPt1wx"
      },
      "source": [
        "bd_tokenizer = text.SentencepieceTokenizer(bd_model, out_type=tf.string)\n",
        "hd_tokenizer = bd_tokenizer\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8dORzk1W5M",
        "outputId": "1378ce76-9996-45da-a9f2-439b3eae92f7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# data = data.drop(['SNo','date','topic'],axis = 1)\n",
        "data.dropna(axis = 0,inplace = True)\n",
        "\n",
        "# data = data.applymap(lambda x:x.encode(encoding='UTF-8'))\n",
        "for i,b in enumerate(data['body'].values):\n",
        "    if len(b)>1000:\n",
        "        data.drop(i, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def format_data(data):\n",
        "    START = '÷'\n",
        "    END = '■'  \n",
        "       \n",
        "    data['body'] = START + ' ' + data['body'] + ' ' + END \n",
        "    data['heading'] = START + ' ' + data['heading'] + ' ' + END \n",
        "    \n",
        "    data = data.applymap(lambda x: str(x) if isinstance(x, int) or isinstance(x, float) else x)\n",
        "    data['heading'] = data['heading'].str.replace('\\d+', '')\n",
        "\n",
        "    data['body'] = data['body'].str.replace('\\d+', '')    \n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "data = format_data(data)\n",
        "data1 = data[4000:]\n",
        "\n",
        "data = data[:4000]\n",
        "target = data.pop('heading')\n",
        "data = data.pop('body')\n",
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values))\n",
        "len(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRSrT7Nrfpl5",
        "outputId": "c893a59c-7f07-459b-9bcf-d7dc195ba2c2"
      },
      "source": [
        "val_examples = dataset.take(1000)\n",
        "val_examples\n",
        "train_examples = dataset.skip(1000)\n",
        "train_examples "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SkipDataset shapes: ((), ()), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5AnEFdyRxY",
        "outputId": "c02cccb8-3dc5-427e-ac36-50274b5713b7"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(3).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    print(len(bd.decode('utf-8')))\n",
        "\n",
        "\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "327\n",
            "÷ న్యూఢిల్లీ, జనవరి : అమెరికా కొత్త అధ్యక్షుడుగా బాధ్యతలు చేపట్టిన డోనాల్డ్‌ ట్రంప్‌కు ప్రధాని మోదీ అభినందనలు తెలిపారు. శుక్రవారం రాత్రి ఆయన ట్వీట్‌ చేస్తూ, అమెరికాతో ద్వైపాక్షిక సంబంధాలు మరింత పటిష్ఠం కావాలని, సహకారం ఇంకా విస్తృతం కావాలని ఆకాంక్షించారు. ■\n",
            "256\n",
            "÷ న్యూఢిల్లీ, జూలై  (ఆంధ్రజ్యోతి): కేంద్ర పట్టణాభివృద్ధి శాఖమంత్రిగా రాజీనామ చేసిన ఎన్డీయే ఉప రాష్ట్రపతి అభ్యర్థి ఎం.వెంకయ్యనాయుడికు ఆ శాఖ ఉద్యోగులు సోమవారం ఘనంగా వీడ్కోలు పలికారు. వెంకయ్య మాట్లాడుతూ.. మూడేళ్లలో శాఖలో అందరితో అనుబంధం పెరిగిందని, అందరికీ అభినందనలు తెలిపారు. ■\n",
            "275\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్‌కు మోదీ అభినందనలు  ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEmDuhs0y4sK",
        "outputId": "fa6361d0-3410-4e39-9c5f-ad5976624f37"
      },
      "source": [
        "encoded = hd_tokenizer.tokenize(hd_examples)\n",
        "encoded = hd_tokenizer.string_to_id(encoded)\n",
        "\n",
        "for row in encoded.to_list():\n",
        "  print(row)\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 114, 94, 2064, 3412, 189, 288, 4, 9]\n",
            "[8, 305, 361, 54, 116, 5992, 4, 9]\n",
            "[8, 2629, 14, 1086, 31, 7291, 6, 326, 28, 4, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SvNtpapzNaT",
        "outputId": "67c9ea36-9ac7-4620-96a3-67cec64af4cd"
      },
      "source": [
        "round_trip = hd_tokenizer.detokenize(encoded)\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్ కు మోదీ అభినందనలు ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7u5Oua-5PNw"
      },
      "source": [
        "def tokenize_pairs(bd, hd):\n",
        "    bd = bd_tokenizer.tokenize(bd)\n",
        "    bd = bd_tokenizer.string_to_id(bd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    bd = tf.dtypes.cast(bd.to_tensor(),dtype=tf.int64)\n",
        "\n",
        "    hd = hd_tokenizer.tokenize(hd)\n",
        "    hd = hd_tokenizer.string_to_id(hd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    hd = tf.dtypes.cast(hd.to_tensor(),dtype=tf.int64)\n",
        "    return bd, hd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5to2UKMU5vmS"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRK87iSP52lQ"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i2iAtT54GR"
      },
      "source": [
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8R7m5BvIIUv",
        "outputId": "7d07c5ac-35e0-4176-9d27-c81719f61af5"
      },
      "source": [
        " for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "   print(inp)\n",
        "   print(tar)\n",
        "\n",
        "   break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[   8    4  608 ...    0    0    0]\n",
            " [   8  626   50 ...    0    0    0]\n",
            " [   8 4233   39 ...    0    0    0]\n",
            " ...\n",
            " [   8 1814   24 ...    0    0    0]\n",
            " [   8 1631  862 ...    0    0    0]\n",
            " [   8  241  449 ...    0    0    0]], shape=(64, 273), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   8   87  557 ...    0    0    0]\n",
            " [   8  207 2672 ...    0    0    0]\n",
            " [   8  305  361 ...    0    0    0]\n",
            " ...\n",
            " [   8   17 3606 ...    0    0    0]\n",
            " [   8 1631 1896 ...    0    0    0]\n",
            " [   8 4984   31 ...    0    0    0]], shape=(64, 24), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yNLTjK5_RU"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYuFQeC6KEE"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6JNulI_6LwJ"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAuKabZG6Oqp"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8Inwo16T0G"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print('Attention weights are:')\n",
        "  print(temp_attn)\n",
        "  print('Output is:')\n",
        "  print(temp_out)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IemyYhh6U2p"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxeYaMS6Yfz"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhZU_ZX6cNC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BybZGH6e56"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JAKvw26kaz"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_QxZ4F86m_j"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhnK1ldh6oHU"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1x5WqXz6tYz"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30T6ZjA6zTI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uULQomCC60px"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wTDJszGgBL"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giMDqhjdGidX"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpkBGsTHY_I"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYp4In7HbYk"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=bd_tokenizer.vocab_size(),\n",
        "    target_vocab_size=hd_tokenizer.vocab_size(),\n",
        "    pe_input=1000,\n",
        "    pe_target=100,\n",
        "    rate=dropout_rate)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlHUzTVH9s8"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdfpFpVICa1"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsqBRetsIFQG"
      },
      "source": [
        "EPOCHS = 60"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Y7APmcIGKi"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kou1RjYIOWg",
        "outputId": "ec0727e5-d3bb-4eab-cd9d-cd1d53f02fb8"
      },
      "source": [
        "import time\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.9893 Accuracy 0.0000\n",
            "Epoch 1 Loss 8.9285 Accuracy 0.0283\n",
            "Time taken for 1 epoch: 25.12 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.8383 Accuracy 0.0881\n",
            "Epoch 2 Loss 8.7380 Accuracy 0.0965\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 8.6419 Accuracy 0.0969\n",
            "Epoch 3 Loss 8.5369 Accuracy 0.0966\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 8.4282 Accuracy 0.0907\n",
            "Epoch 4 Loss 8.2594 Accuracy 0.0968\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 8.0903 Accuracy 0.1012\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 7.9120 Accuracy 0.0967\n",
            "Time taken for 1 epoch: 10.97 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 7.7433 Accuracy 0.0930\n",
            "Epoch 6 Loss 7.5162 Accuracy 0.1352\n",
            "Time taken for 1 epoch: 10.33 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 7.3249 Accuracy 0.1739\n",
            "Epoch 7 Loss 7.1207 Accuracy 0.1788\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 6.9555 Accuracy 0.1740\n",
            "Epoch 8 Loss 6.7913 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 6.5520 Accuracy 0.1992\n",
            "Epoch 9 Loss 6.5367 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 6.4085 Accuracy 0.1884\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 6.3547 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 10.72 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 6.3133 Accuracy 0.1873\n",
            "Epoch 11 Loss 6.2088 Accuracy 0.1816\n",
            "Time taken for 1 epoch: 10.48 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 6.1217 Accuracy 0.1727\n",
            "Epoch 12 Loss 6.0759 Accuracy 0.1870\n",
            "Time taken for 1 epoch: 10.58 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.8818 Accuracy 0.1923\n",
            "Epoch 13 Loss 5.9472 Accuracy 0.1939\n",
            "Time taken for 1 epoch: 10.65 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 5.8699 Accuracy 0.1992\n",
            "Epoch 14 Loss 5.8223 Accuracy 0.2020\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 5.6926 Accuracy 0.2060\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 5.6954 Accuracy 0.2122\n",
            "Time taken for 1 epoch: 10.79 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 5.5413 Accuracy 0.2218\n",
            "Epoch 16 Loss 5.5741 Accuracy 0.2199\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 5.5210 Accuracy 0.2145\n",
            "Epoch 17 Loss 5.4482 Accuracy 0.2278\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 5.4324 Accuracy 0.2386\n",
            "Epoch 18 Loss 5.3276 Accuracy 0.2346\n",
            "Time taken for 1 epoch: 10.70 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 5.2414 Accuracy 0.2523\n",
            "Epoch 19 Loss 5.2111 Accuracy 0.2420\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 5.1143 Accuracy 0.2474\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 5.0923 Accuracy 0.2498\n",
            "Time taken for 1 epoch: 10.73 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 4.9390 Accuracy 0.2602\n",
            "Epoch 21 Loss 4.9767 Accuracy 0.2587\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 4.8986 Accuracy 0.2669\n",
            "Epoch 22 Loss 4.8480 Accuracy 0.2685\n",
            "Time taken for 1 epoch: 10.54 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 4.7609 Accuracy 0.2770\n",
            "Epoch 23 Loss 4.7175 Accuracy 0.2812\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 4.5658 Accuracy 0.2958\n",
            "Epoch 24 Loss 4.5892 Accuracy 0.2912\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 4.4979 Accuracy 0.2910\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 4.4650 Accuracy 0.3010\n",
            "Time taken for 1 epoch: 10.92 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 4.3941 Accuracy 0.3127\n",
            "Epoch 26 Loss 4.3278 Accuracy 0.3132\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 4.0732 Accuracy 0.3469\n",
            "Epoch 27 Loss 4.1925 Accuracy 0.3258\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 4.0879 Accuracy 0.3293\n",
            "Epoch 28 Loss 4.0626 Accuracy 0.3376\n",
            "Time taken for 1 epoch: 10.36 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 3.9496 Accuracy 0.3418\n",
            "Epoch 29 Loss 3.9179 Accuracy 0.3512\n",
            "Time taken for 1 epoch: 10.46 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 3.6925 Accuracy 0.3902\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
            "Epoch 30 Loss 3.7824 Accuracy 0.3659\n",
            "Time taken for 1 epoch: 10.77 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 3.7350 Accuracy 0.3585\n",
            "Epoch 31 Loss 3.6557 Accuracy 0.3773\n",
            "Time taken for 1 epoch: 10.63 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 3.5859 Accuracy 0.3892\n",
            "Epoch 32 Loss 3.5079 Accuracy 0.3906\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 3.4197 Accuracy 0.3949\n",
            "Epoch 33 Loss 3.3564 Accuracy 0.4079\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 3.2539 Accuracy 0.4284\n",
            "Epoch 34 Loss 3.2212 Accuracy 0.4223\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 3.1961 Accuracy 0.4407\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-7\n",
            "Epoch 35 Loss 3.0676 Accuracy 0.4409\n",
            "Time taken for 1 epoch: 10.71 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.9529 Accuracy 0.4726\n",
            "Epoch 36 Loss 2.9192 Accuracy 0.4600\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.5930 Accuracy 0.5179\n",
            "Epoch 37 Loss 2.7761 Accuracy 0.4812\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.6745 Accuracy 0.4831\n",
            "Epoch 38 Loss 2.6334 Accuracy 0.4994\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.4713 Accuracy 0.5176\n",
            "Epoch 39 Loss 2.4752 Accuracy 0.5225\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.3462 Accuracy 0.5453\n",
            "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-8\n",
            "Epoch 40 Loss 2.3152 Accuracy 0.5503\n",
            "Time taken for 1 epoch: 10.77 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 2.2100 Accuracy 0.5654\n",
            "Epoch 41 Loss 2.1660 Accuracy 0.5774\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 1.9722 Accuracy 0.6231\n",
            "Epoch 42 Loss 2.0249 Accuracy 0.5996\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 1.8331 Accuracy 0.6495\n",
            "Epoch 43 Loss 1.8676 Accuracy 0.6300\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 1.6479 Accuracy 0.6579\n",
            "Epoch 44 Loss 1.7348 Accuracy 0.6565\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.5777 Accuracy 0.6733\n",
            "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-9\n",
            "Epoch 45 Loss 1.5760 Accuracy 0.6840\n",
            "Time taken for 1 epoch: 10.68 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 1.4317 Accuracy 0.7057\n",
            "Epoch 46 Loss 1.4246 Accuracy 0.7167\n",
            "Time taken for 1 epoch: 10.35 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 1.2887 Accuracy 0.7610\n",
            "Epoch 47 Loss 1.3036 Accuracy 0.7446\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 1.1288 Accuracy 0.7901\n",
            "Epoch 48 Loss 1.1802 Accuracy 0.7647\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 1.0141 Accuracy 0.8074\n",
            "Epoch 49 Loss 1.0469 Accuracy 0.7957\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.8919 Accuracy 0.8234\n",
            "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-10\n",
            "Epoch 50 Loss 0.9253 Accuracy 0.8212\n",
            "Time taken for 1 epoch: 10.89 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.8200 Accuracy 0.8369\n",
            "Epoch 51 Loss 0.8271 Accuracy 0.8377\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.7074 Accuracy 0.8634\n",
            "Epoch 52 Loss 0.7253 Accuracy 0.8586\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.5678 Accuracy 0.9033\n",
            "Epoch 53 Loss 0.6468 Accuracy 0.8742\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.4657 Accuracy 0.9155\n",
            "Epoch 54 Loss 0.5878 Accuracy 0.8816\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.4547 Accuracy 0.9009\n",
            "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-11\n",
            "Epoch 55 Loss 0.5213 Accuracy 0.8937\n",
            "Time taken for 1 epoch: 10.86 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.3834 Accuracy 0.9384\n",
            "Epoch 56 Loss 0.4725 Accuracy 0.9034\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.3795 Accuracy 0.9239\n",
            "Epoch 57 Loss 0.4156 Accuracy 0.9148\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.3934 Accuracy 0.9093\n",
            "Epoch 58 Loss 0.3865 Accuracy 0.9187\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.3323 Accuracy 0.9333\n",
            "Epoch 59 Loss 0.3518 Accuracy 0.9250\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.2941 Accuracy 0.9404\n",
            "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-12\n",
            "Epoch 60 Loss 0.3228 Accuracy 0.9303\n",
            "Time taken for 1 epoch: 10.79 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2yUqMbpSzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb4b247-92b8-4318-ab12-1586cc697137"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(10).take(5):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "÷ న్యూఢిల్లీ, జనవరి : అమెరికా కొత్త అధ్యక్షుడుగా బాధ్యతలు చేపట్టిన డోనాల్డ్‌ ట్రంప్‌కు ప్రధాని మోదీ అభినందనలు తెలిపారు. శుక్రవారం రాత్రి ఆయన ట్వీట్‌ చేస్తూ, అమెరికాతో ద్వైపాక్షిక సంబంధాలు మరింత పటిష్ఠం కావాలని, సహకారం ఇంకా విస్తృతం కావాలని ఆకాంక్షించారు. ■\n",
            "÷ న్యూఢిల్లీ, జూలై  (ఆంధ్రజ్యోతి): కేంద్ర పట్టణాభివృద్ధి శాఖమంత్రిగా రాజీనామ చేసిన ఎన్డీయే ఉప రాష్ట్రపతి అభ్యర్థి ఎం.వెంకయ్యనాయుడికు ఆ శాఖ ఉద్యోగులు సోమవారం ఘనంగా వీడ్కోలు పలికారు. వెంకయ్య మాట్లాడుతూ.. మూడేళ్లలో శాఖలో అందరితో అనుబంధం పెరిగిందని, అందరికీ అభినందనలు తెలిపారు. ■\n",
            "÷ ముంబై, సెప్టెంబరు : విశాల నగరమైన ముంబై జనాభా దాదాపు . కోట్లు కాగా.. రోజూ సగటున  లక్షల మంది సబర్బన్‌ రైళ్లలో ప్రయాణిస్తుంటారు. ఎక్కువ మంది నగరానికి దూరంగా తక్కువ అద్దెలకు ఇళ్లు లభించే చోట ఉంటుంటారు.  కిలోమీటర్ల దూరం నుంచి రోజూ నగరానికి వచ్చి ఉద్యోగాలు చేసుకునేవారు కోకొల్లలు. కార్లు, ద్విచక్ర వాహనాలు, బస్సుల్లో అంత దూరం ప్రయాణించడం ట్రాఫిక్‌ రద్దీ దృష్ట్యా ఎంతో సమయంతో కూడుకున్నది. అందుకే సబర్బన్‌ రైళ్లను ఆశ్రయిస్తారు. ముంబై సబర్బన్‌ రైల్వే రోజూ , ఎలక్ట్రికల్‌ మల్టిపుల్‌ యూనిట్‌ (ఈఎంయూ) సర్వీసులు నడుపుతుండగా.. ఉదయం  గంటల నుంచి  గంటల దాకా, మళ్లీ సాయంత్రం ఐదు గంటల నుంచి  గంటల దాకా ఇవి కిక్కిరిసి ఉంటాయి. రద్దీగా ఉన్నందున తర్వాతి రైలులో వెళ్దామని ఎవరూ అనుకోరు. ఎందుకంటే ప్రతి రైలులోనూ ఇదే పరిస్థితి. ■\n",
            "÷ \n",
            "విక్ర‌మ్ కుమార్ ద‌ర్శక‌త్వంలో అక్కినేని అఖిల్ నటించిన ‘హ‌లో’ మూవీ ప్రీరిలీజ్ వేడుక హైదరాబాద్‌లోని ఎన్‌కన్విన్షన్ సెంటర్‌‌లో జరిగింది. ఈ ఫంక్షన్‌కు ముఖ్య అతిథిగా మెగస్టార్ చిరంజీవి హాజరయ్యారు. ఈ సందర్భంగా ఆయన సినిమా టైటిల్ గురించి మాట్లాడారు. \"‘హలో’ ఐడియా ఎవరిదో కానీ నిజంగా హ్యాట్సాఫ్.. ఈ రోజుల్లో హలో అనేపదం అందరి నోళ్ళలో నాని పోతోంది. అలాంటి ఈ టైటిల్ ఐడియా అనేది నిజంగా గ్రేట్.. అయినా అక్కినేని కుటుంబానికి 'హలో' తో విడదీయరాని బంధం ఉంది\" అని చిరు చెప్పుకొచ్చారు. బహుశా ఈ సినిమాకు హలో అని టైటిల్ పెట్టాలన్న ఆలోచన డైరక్టర్ విక్రమ్‌కు వచ్చిండొచ్చని ఆయన వైపు చేయి చూపించగా కాదు సార్ అని డైరెక్టర్, హీరోయిన్, చిత్ర బృందం మొత్తం నాగ్‌ వైపు వేలు చూపించగా వావ్ నాగ్ అంటూ యువసామ్రాట్‌ను చిరంజీవి అభినందించారు. ■\n",
            "÷ న్యూయార్క్‌ : న్యూయార్క్‌లోని ఓ రద్దీ స్ర్టీట్‌ అది..రివ్వున వీస్తున్న చలిగాలి..నల్లటి టీషర్ట్‌, కొంచెం పైకి మడిచిన జీన్స్‌.. చేతిలో గొడుగు..పక్కన ప్రేయసి అనుష్కతో టీమిండియా కెప్టెన్‌ కోహ్లీ నడుచుకుంటూ వెళుతున్నాడు. వర్షం వస్తే..‘శ్రీ ’ సినిమాలో రాజ్‌కపూర్‌..నర్గీస్‌తో పాడిన ‘ప్యార్‌హువా ఇక్‌రార్‌ హువా’ అన్న పాటను పాడుకోవడానికేమో.. విరాట్‌ చేతిలో ఆ గొడుగు. అవును..సోషల్‌ మీడియాలో హల్‌చేస్తున్న ఈ ఫొటోను చూస్తే అచ్చు అలానే అనిపిస్తోంది. వెస్టిండీస్‌ పర్యటన ముగిసిన వెంటనే విరాట్‌ అమెరికాలో వాలిపోయాడు. ఐఫా అవార్డుల ప్రోగ్రాం కోసం న్యూయార్క్‌ వచ్చిన అనుష్కను అక్కడ కోహ్లీ కలుసుకున్నాడు. ఇంకేం.. దొరికిన కొద్దిపాటి సమయాన్ని ఇద్దరూ బాగా ఎంజాయ్‌ చేస్తున్నారు. ఇక తామిద్దరం కారులో ఉన్న ఓ చిత్రాన్ని తన ఇన్‌స్టాగ్రామ్‌ అకౌంట్‌లో పోస్ట్‌ చేసిన కోహ్లీ..‘ప్రేయసి కోసం..ఎంతో ఎదురుచూసిన సమయం’ అని ఓ కామెంట్‌ దానికి జత చేశాడు. ■\n",
            "÷ అంధుల టీ వరల్డ్‌కప్‌ కొచ్చి: అంధుల టీ వరల్డ్‌కప్‌లో భారత్..  పరుగుల తేడాతో ఆస్ట్రేలియాను చిత్తు చేసింది. ఆదివారం జరిగిన మ్యాచ్‌లో తొలుత బ్యాటింగ్‌ చేసిన భారత  ఓవర్లలో వికెట్‌ నష్టానికి  పరుగులు చేసింది. సునీల్‌ ( నాటౌట్‌) శతకం నమోదు చేయగా.. ఫర్హాన్‌ () హాఫ్‌ సెంచరీతో ఆకట్టుకున్నాడు.  పరుగుల లక్ష్యంతో ఛేదనకు దిగిన ఆసే్ట్రలియా . ఓవర్లలో  రన్స్‌కే కుప్పకూలింది. ఆరుగురు ఆసీస్‌ బ్యాట్స్‌మెన్‌ రనౌట్‌ కావడం విశేషం. ■\n",
            "÷ తెలుగులో ‘అర్జున్‌రెడ్డి’ సినిమాని సొంత సినిమాలాగా దర్శకుడు రామ్‌గోపాల్‌ వర్మ ప్రమోట్ చేసిన విషయం తెలిసిందే. ఒకవైపు వర్మ, మరోవైపు వి. హనుమంతరావులు కలిసి అర్జున్‌రెడ్డికి భారీ విజయాన్ని అందించారు. సినిమాలో కూడా కంటెంట్ ఉండటంతో ‘అర్జున్‌రెడ్డి’ టాక్ ఆఫ్ ద ఇండస్ట్రీ అయింది. తాజాగా ఈ సినిమాని చియాన్ విక్రమ్ తనయుడు ధృవ్‌తో తమిళ్‌లో రీమేక్ చేస్తున్నారు. ఈ చిత్రంతోనే ధృవ్ హీరోగా పరిచయం కాబోతున్నాడు. అయితే తెలుగులో ‘అర్జున్‌రెడ్డి’గా వచ్చిన ఈ చిత్రానికి తమిళ్‌లో ఆసక్తికరమైన పేరు పెట్టి ఇప్పటి నుండే వార్తల్లో ఉండేలా చేశారు. ‘వర్మ’ అనే టైటిల్‌ని ఈ చిత్రానికి కన్ఫర్మ్ చేశారు. ఇప్పటికే ఆ వుడ్, ఈ వుడ్ అనే భేదం లేకుండా రామ్ గోపాల్ వర్మ సంచలనం అవుతున్నారు. మరి ఈ టైటిల్‌తో ఈజీగా ధృవ్ పాపులర్ అయిపోతాడంటూ.. ఈ టైటిల్ అనౌన్స్ చేసిన తర్వాత సెలబ్రిటీల నుండి వస్తున్న ఫీడ్ బ్యాక్. ‘అర్జున్‌రెడ్డి’కి తెలుగులో సందీప్ వంగా దర్శకత్వం వహించగా.. ‘వర్మ’ పేరుతో వస్తున్న ఈ చిత్రానికి బాల దర్శకత్వం వహిస్తున్నారు. ■\n",
            "÷ భటిండా: కామాంధుడైన ఓ కల్నల్‌ తన సబార్డినేట్‌ భార్యతో రాసలీలలు కొనసాగిస్తూ అడ్డంగా దొరికిపోయాడు. పంజాబ్‌లోని భటిండాలో చోటుచేసుకున్న ఈ ఘటన సైన్యంలో చర్చనీయాంశమైంది. అక్టోబరు న లెఫ్టినెంట్‌ కల్నల్‌ ఇంట్లో ఆయన భార్యతో ఉన్న కల్నల్‌ను మిలటరీ పోలీసులు అదుపులోకి తీసుకున్నారు. వారిద్దరినీ వైద్య పరీక్షల నిమిత్తం భటిండాలోని సైనిక ఆసుపత్రికి తరలించినట్లు సమాచారం. లెఫ్టినెంట్‌ కల్నల్‌ ఇచ్చిన సమాచారంతోనే ఆయన ఇంట్లో సోదాలు చేసి వారిద్దరినీ అదుపులోకి తీసుకోవడం గమనార్హం. ■\n",
            "÷ ముంబై: మన హీరోలు నిత్యం బిజీ షెడ్యూల్‌తో సతమతమవుతుంటారు. అసలు కుటుంబంతో కలిసి తిరగడానికి కూడా ఖాళీ లేక బాధపడుతుంటారు. ఎప్పుడైనా ఖాళీ దొరికితే కుటుంబంతో గడపాలనుకుంటారు. ఓ టాప్ హీరో దొరికిన ఖాళీ సమయాన్ని తన కూతురి కోసం కేటాయించాడు. తన గారాలపట్టి ఆడుకుంటుంటే చూస్తూ మురిసిపోయిన సదరు హీరో ఊహించని ఘటనతో షాక్ అయ్యాడు.       బాలీవుడ్‌లో టాప్ హీరోలలో ఒకడిగా వెలుగొందుతున్నాడు అక్షయ్ కుమార్. అందరిలాగే అతడికి కూడా తన పిల్లలంటే ఇష్టం. అయితే కొడుకు విదేశాలలో చదువుతుండడంతో, ఖాళీ దొరికినప్పుడల్లా కూతురితో గడుపుతుంటాడు. అందునా ఆయన భార్య కూడా విదేశీ పర్యటనకు వెళ్లడంతో.. కూతురిని స్వయంగా అతడే చూసుకుంటున్నాడు. ఈ క్రమంలోనే నిటారాను ఉయ్యాల ఎక్కించాడు.. ఆమె ఊగుతుండగా ఎదురుగా నిల్చుని చూస్తూ మురిసిపోతున్నాడు. ఇంతలో ఆమె కాళ్లు అక్షయ్ ముఖానికి తగిలడంతో వెనక్కి పడబోయాడు. దీనికి సంబంధించిన వీడియోను అక్షయ్ ట్విట్టర్‌లో పెట్టాడు. ‘‘డాడీతో డే బెడిసికొట్టింది’’ అనే క్యాప్షన్ ఇచ్చాడు. ఈ వీడియో ఇప్పుడు ఇంటర్నెట్‌లో వైరల్ అయింది. వీడియో కోసం క్లిక్ చేయండి ■\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్‌కు మోదీ అభినందనలు  ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n",
            "÷ ముంబై లైఫంతా లోకల్‌ రైలులోనే! ■\n",
            "÷ ‘హలో’ సినిమాకు టైటిల్ పెట్టిందెవరో తెలుసా! ■\n",
            "÷ ఎంతో ఎదురు చూసిన సమయం ! ■\n",
            "÷ భారత్ భారీ గెలుపు  ■\n",
            "÷ సినిమా టైటిల్‌తోనే చియాన్ విక్రమ్ కొడుకు సంచలనం ■\n",
            "÷ లెఫ్టినెంట్‌ కల్నల్‌ భార్యతో రాసలీలలు.. దొరికిపోయిన కల్నల్‌ ■\n",
            "÷ స్టార్ హీరో వీడియో వైరల్.. కారణం ఆయన కూతురే..! ■\n",
            "÷ బాహుబలి మూవీ సృష్టించిన ప్రభంజనం నుంచి ఇప్పట్లో బయటపడటం కష్టమే అని భావిస్తుంటే.. బాహుబలి- గురించి ఎవ్వరూ ఊహించని విషయాన్ని వెల్లడించారు ఆ సినిమా నిర్మాత శోభు యార్లగడ్డ. తాజాగా 'సీఎన్ఎన్-ఐబీఎన్' ఇండియన్ ఆఫ్ ద ఇయర్ అవార్డును వివిధ రంగాలకు చెందిన వారికి ప్రదానం చేసింది. దీనికి హాజరరైన శోభు యార్లగడ్డ బాహుబలి- గురించి చెప్పి బాంబ్ పేల్చారు. \"బాహుబలి- ఉంటుందా?\" అన్న ప్రశ్నకు సమాధానంగా \"వెంటనే అయితే ఉండదు కానీ భవిష్యత్తులో ఉండవచ్చుష అంటూ తన మనసులో మాటను వెల్లడించారు. ఇంకా ఆయన మాట్లాడుతూ తాను ఇప్పటికీ బాహుబలి సెట్స్‌లోనే ఉన్నట్టు ఫీల్ అవుతున్నానన్నారు. 'బాహుబలి' ప్రయాణం చాలా పెద్దదని.. దాని హ్యాంగోవర్ నుంచి బయటకు రావడం కష్టమన్నారు. ■\n",
            "÷ లఖ్‌నవు, ఫిబ్రవరి : యూపీ ఎన్నికల ప్రచారంలో వ్యాఖ్యలు హద్దులు దాటుతున్నాయి. ప్రధాని నరేంద్ర మోదీ, బీజేపీ సారథి అమిత షాలు ఉగ్రవాదులు అని రాష్ట్ర మంత్రి, ఎస్పీ సీనియర్‌ నేత రాజేంద్ర చౌధరి వివాదాస్పద వ్యాఖ్యలు చేశారు. ‘‘ఓట్ల కోసం వారిద్దరూ రాష్ట్రంలో ప్రశాంత వాతావరణాన్ని ధ్వంసం చేస్తున్నారు. రాష్ట్రంలో భయోత్పాతాన్ని సృష్టిస్తున్నారు’’ అని అన్నారు. సోమవారం ఇక్కడ మీడియాతో మాట్లాడిన చౌధరి.. బీజేపీకి రాష్ట్రంలో స్థానం లేదని, రాష్ర్టానికి అది చేసింది కూడా ఏమీలేదని విమర్శించారు. ■\n",
            "÷ \n",
            "బెంగళూరు : పెద్ద నోట్ల రద్దును విమర్శిస్తున్నవారిపై ప్రధాన మంత్రి నరేంద్ర మోదీ విరుచుకుపడ్డారు. ప్రభుత్వ నిర్ణయం ప్రజా వ్యతిరేక చర్య అంటూ నిరసన వ్యక్తం చేస్తున్నవారిని దుయ్యబట్టారు. వీరంతా నల్లధనాన్ని, అవినీతిని పూజించేవాళ్ళని ఆరోపించారు. నల్లధనం, అవినీతి వల్ల దేశ ఆర్థిక వ్యవస్థ, రాజకీయాలు, సమాజం తీవ్రంగా దెబ్బతింటున్నాయన్నారు. వ ప్రవాసీ భారతీయ దివస్ సందర్భంగా ఆదివారం జరిగిన సమావేశంలో మోదీ మాట్లాడారు. అవినీతికి వ్యతిరేకంగా ప్రభుత్వం అమలు చేస్తున్న చర్యలపై నల్లధనానికి మద్దతిచ్చేవారు బురద జల్లడం బాధాకరమని తెలిపారు. దేశాభివృద్ధిలో ప్రవాస భారతీయులు భాగస్వాములవుతుండటం సంతోషకరమని మోదీ చెప్పారు. ఎన్ఆర్ఐలు  బిలియన్ డాలర్లు పెట్టుబడి పెట్టి, దేశ ఆర్థిక వ్యవస్థకు ఊతమిచ్చారని ప్రశంసించారు. ఈ సందర్భంగా ఎఫ్‌డీఐకి మరో అర్థం చెప్పారు. ఎఫ్‌డీఐ అంటే ఫారిన్ డైరెక్ట్ ఇన్వెస్ట్‌మెంట్ (విదేశీ ప్రత్యక్ష పెట్టుబడులు) అంటారని, అయితే తాను ఫస్ట్ డెవలప్ ఇండియా (మొదట భారతదేశాన్ని అభివృద్ధి చేయండి) అంటానని వివరించారు. బ్రెయిన్ డ్రెయిన్ (మేధోవలస)ను బ్రెయిన్ గెయిన్ (మేధో లాభదాయకత)గా మార్చాలనుకుంటున్నామన్నారు. ■\n",
            "÷ న్యూఢిల్లీ: ఐదు రాష్ట్రాల ఎన్నికల్లో భాగంగా శనివారం ఉదయం రెండు రాష్ట్రాల్లో అసెంబ్లీ ఎన్నికలు ప్రారంభమయ్యాయి. ఉత్తర ప్రదేశ్‌లో ఇప్పటికే  దశల్లో పోలింగ్ పూర్తికాగా నేడు వ దశ పోలింగ్ జరుగుతోంది. మరోవైపు మణిపూర్‌లోనూ మొదటి దశ ఎన్నికలు ప్రారంభమయ్యాయి. ఈ రెండు రాష్ట్రాల్లోనూ ఇంకో దశ పోలింగ్ మాత్రమే మిగిలి ఉంది. ఉత్తరప్రదేశ్‌లోని మావు, గోరఖ్‌పూర్, మహారాజ్ గంజ్, కుషినగర్, ద్యోరియా, అజాంఘర్, బాల్లియా జిల్లాల్లో మొత్తం  స్థానాలకు నేడు పోలింగ్ జరుగుతోంది. గత ఎన్నికల్లో ఈ నియోజకవర్గాల్లో  స్థానాలు బీజేపీకి దక్కగా,  స్థానాలు అధికార పార్టీ సమాజ్‌వాదీ గెలుచుకుంది.ఇక మణిపూర్‌లో మొత్తం  అసెంబ్లీ స్థానాలుండగా నేడు తొలివిడతగా  నియోజకవర్గాల్లో పోలింగ్ జరుగుతోంది. ఇంఫాల్ ఈస్ట్, ఇంఫాల్ వెస్ట్, బిష్ణుపూర్, చూరచంద్ పూర్, కాంగ్‌పోక్పీ జిల్లాల్లో ఓటర్లు తమ ఓటు హక్కు వినియోగించుకుంటున్నారు. ■\n",
            "÷ న్యూఢిల్లీ: స్వీడన్‌లోని భారత దౌత్య కార్యాలయం అధికారులంతా సురక్షితమేనని కేంద్ర విదేశాంగ మంత్రి సుష్మా స్వరాజ్ తెలిపారు. ఆ అధికారులను తాను నిరంతరం సంప్రదిస్తున్నట్లు ఆమె వెల్లడించారు. స్వీడన్‌ స్టాక్‌హోం నగరంలోని ఇండియన్ ఎంబసీ సమీపంలో శుక్రవారం ఓ ట్రక్కు బీభత్సం సృష్టించింది. జన రద్దీ ఎక్కువగా ఉండే మాల్‌లోకి అది దూసుకెళ్ళింది. దీంతో అక్కడ దట్టమైన పొగ కమ్ముకుంది.  ఈ ఘటనలో ముగ్గురు మృతి చెందగా పలువురు గాయపడ్డారు. దీన్ని ఉగ్రదాడిగా అనుమానిస్తున్నట్లు స్వీడన్ ప్రధాని తెలిపారు. ఓ అనుమానితుడ్ని ఆ దేశ పోలీసులు అదుపులోకి తీసుకున్నారు. ■\n",
            "÷ హైదరాబాద్‌: జాతీయ అండర్‌- చెస్‌ చాంపియన్‌షిప్‌లో తెలంగాణకు ప్రాతినిధ్యం వహించిన రాజా రుత్విక్‌ స్వర్ణ పతకం సాధించాడు. ఏఐసీఎఫ్‌ ఆధ్వర్యంలో జలంధర్‌లో శుక్రవారం జరిగిన ఆఖరి, వ రౌండ్‌లో అర్ణవ్‌ తివారిపై టాప్‌సీడ్‌ రుత్విక్‌ నెగ్గాడు. దీంతో రుత్విక్‌  రౌండ్లలో మొత్తం  పాయింట్లుతో అగ్రస్థానంలో నిలిచి పసిడి పతకం కైవసం చేసుకున్నాడు. ఈ టోర్నీలో వివిధ రాష్ర్టాల నుంచి  మంది టాప్‌ ప్లేయర్లు పోటీపడ్డారు. ■\n",
            "÷ \n",
            "న్యూఢిల్లీ : వైవాహిక అత్యాచారాన్ని క్రిమినల్ నేరంగా చేయరాదని కేంద్ర ప్రభుత్వం స్పష్టం చేసింది. దీనిని నేరంగా పరిగణిస్తే వివాహ వ్యవస్థను అస్థిరపరచే అవకాశం ఉంటుందని తెలిపింది. అంతేకాకుండా భర్తలను వేధించేందుకు సులువైన సాధనంగా మారవచ్చునని పేర్కొంది. భార్యకు ఇష్టం లేకుండా, ఆమెపై భర్త లైంగిక దాడికి పాల్పడినపుడు, ఆ చర్యను నేరంగా పరిగణించాలంటూ దాఖలైన పిటిషన్లపై స్పందిస్తూ ఢిల్లీ హైకోర్టుకు కేంద్ర ప్రభుత్వం అఫిడవిట్‌ను సమర్పించింది. ఐపీసీ సెక్షన్ ఏ దుర్వినియోగం పెరుగుతుండటంపై సుప్రీంకోర్టు, హైకోర్టులు పరిశీలించాయని పేర్కొంది. భర్తలను వేధించేందుకు, వివాహ వ్యవస్థను అస్థిరపరచేందుకు సులువైన సాధనంగా వైవాహిక అత్యాచారం అనే అంశం మారకుండా తగిన హామీ అవసరమని తెలిపింది. ఐపీసీ సెక్షన్  వివాహితల పట్ల వివక్ష చూపుతోందని పిటిషనర్లు ఆరోపించారు. ఇదే కారణంతో ఈ సెక్షన్‌ను రాజ్యాంగ విరుద్ధమైనదిగా ప్రకటించాలని హైకోర్టును కోరారు. ■\n",
            "÷ హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): ప్రీమియం కేటగిరీలో టిఫిన్‌ బాక్స్‌లను తయారు చేస్తున్న వయా లైఫ్‌ కంపెనీ భారత్‌లో ప్లాంట్‌ను ఏర్పాటు చేయాలనుకుంటోంది. ఇందుకు సంబంధించి ఆంధ్రప్రదేశ్‌ తదితర రాష్ర్టాలను పరిశీలిస్తున్నట్టు కంపెనీ వ్యవస్థాపక సిఇఒ వశిష్ట్‌ తెలిపారు. వయా టిఫిన్‌- గోల్డ్‌ వేరియంట్‌ (ధర రూ.,)ను హైదరాబాద్‌ మార్కెట్లోకి విడుదల చేసిన సందర్భంగా ఆయన విలేకరులతో మాట్లాడారు. బెంగళూరు తర్వాత హైదరాబాద్‌లో తమ కంపెనీ టిఫిన్‌ బాక్సులకు ఎక్కువ డిమాండ్‌ ఉందని చెప్పారు. తమ టిఫిన్ల డిజైన్లకు సంబంధించి పలు పేటెంట్లను పొందినట్టు ఆయన తెలిపారు. చైనాలోని ప్లాంట్‌ నుంచి విడిభాగాలను తెచ్చి భారత్‌లో అసెంబుల్‌ చేస్తున్నామని, ఇక్కడి నుంచి పలు దేశాలకు ఎగుమతి కూడా చేస్తున్నామని చెప్పారు. కంపెనీ అమ్మకాల్లో ఎగుమతుల వాటా  శాతంగా ఉందని తెలిపారు. వయా లైఫ్‌ టిఫిన్‌ బాక్స్‌ల ధర శ్రేణి , రూపాయల నుంచి , రూపాయల వరకు ఉందని చెప్పారు. ఆన్‌లైన్‌లోనేకాకుండా రిటైల్‌ స్టోర్లలోనూ వయా టిఫిన్‌ బాక్స్‌లు అందుబాటులో ఉన్నాయని తెలిపారు. ■\n",
            "÷ ముంబై: సినీనటులకు భాష అంతగా రాకపోయినా వివిధ బాషా చిత్రాల్లో నటిస్తుంటారు. ఈ నేపధ్యంలో ఆయా భాషలను నేర్చుకునే ప్రయత్నం కూడా చేస్తుంటారు. చాలామంది హీరోయిన్లు బాలీవుడ్‌లో రాజ్యమేలాలని కలలుకంటారు. ఇందుకోసం వారు హిందీ నేర్చుకుంటారు. వారిలో బాహుబలి హీరోయిన్ తమన్నా ఒకరు. నటీనటులకు హిందీ నేర్పడంతో వినయ్ శుక్లా ఎంతో పేరు గడించారు. వినయ్ దగ్గర తమన్నా హిందీ నేర్చుకుంటోంది. ఐసీఎస్‌సీ, సీబీఎస్‌సీ విద్యార్థులకు హిందీ బోధించే వినయ్ ఈ భాషను అత్యంత సులభంగా నేర్పుతారు. బాలీవుడ్‌లో ప్రముఖ నటులకు ఈయనే హిందీ పాఠాలు చెబుతున్నారు. ఈయన హిందీ అధ్యాపకుడే కాకుండా శివసేన నేతగా పలు కార్యక్రమాల్లో క్రియాశీలకంగా పాల్గొంటున్నారు. ప్రభుత్వం హిందీ భాషాభివృద్ధికి తోడ్పాటునివ్వాలని వినయ్ కోరుతున్నారు. ■\n",
            "÷ న్యూఢిల్లీ : టాక్స్‌ కన్సల్టెన్సీ సంస్థ ఇవై.. చిన్న వ్యాపార సంస్థల కోసం జిఎస్‌టి హెల్ప్‌ డెస్క్‌ను ప్రారంభించింది. ఈ మేరకు చిన్న కంపెనలు తమ సందేహాలను ఆన్‌లైన్‌ ద్వారా పంపించి సమాధానాలు పొందడానికి అవకాశం ఉంటుంది. పరోక్ష పన్ను ప్రొఫెషనల్స్‌, కు పైగా జిఎస్‌టి ప్రాక్టీషనర్ల ద్వారా ఈ సర్వీసులు అందిస్తున్నట్టు తెలిపింది. ఇవై ఇండియా టాక్స్‌ ఇన్‌సైట్స్‌ యాప్‌, డిజిజిఎస్‌టి వెబ్‌సైట్‌, ఇవై ఇండియా ట్విటర్‌ల ద్వారా చిన్న వ్యాపార సంస్థళు, ట్రేడర్లు, ఎంటర్‌ప్రెన్యూర్లు తమ సందేహాలను పోస్ట్‌ చేయవచ్చని తెలిపింది. మరోవైపు జిఎస్‌టి వల్ల ప్రకటనల కంపెనీల వ్యాపారం మరింతగా పెరగనుంది. జిఎస్‌టితో ప్రయోజనం పొందే కంపెనీలు ప్రచారం కోసం ఎక్కువగా ఖర్చు చేయడానికి అవకాశం ఉందని పరిశ్రమవర్గాలు అంటున్నాయి. జిఎస్‌టితో ఎఫ్‌ఎంసిజి రంగంపై పన్ను భారం తగ్గింది. దీంతో ఈ కంపెనీలు తమ ఉత్పత్తులకు విక్రయించుకునేందుకు పెద్ద ఎత్తున ప్రకటనలు చేయనున్నాయి. ■\n",
            "\n",
            "÷ 'బాహుబలి' గురించి ఊహించని విషయాన్ని వెల్లడించిన నిర్మాత ■\n",
            "÷ మోదీ, షా ఉగ్రవాదులు: ఎస్పీ మంత్రి ■\n",
            "÷ వాళ్ళు పూజించేది అవినీతినే : మోదీ ■\n",
            "÷ ఉత్తర ప్రదేశ్, మణిపూర్‌లలో కొనసాగుతున్న పోలింగ్ ■\n",
            "÷ స్వీడన్‌లో భారత దౌత్య కార్యాలయం అధికారులు సురక్షితం: సుష్మా స్వరాజ్ ■\n",
            "÷ జాతీయ చెస్‌లో రుత్విక్‌కు స్వర్ణం ■\n",
            "÷ భర్త అత్యాచారం చేస్తే కేసు పెట్టవచ్చునా? ■\n",
            "÷ భారత్‌లో వయా లైఫ్‌ ప్లాంట్‌ ■\n",
            "÷ తమన్నాకు హిందీ నేర్పుతున్న శివసేన నేత ■\n",
            "÷ చిన్న వ్యాపార సంస్థలకు జిఎస్‌టి హెల్ప్‌డెస్క్‌ : ఇవై ■\n",
            "÷ హీరోయిన్‌‌కి ఉండాల్సిన అన్ని లక్షణాలు పుష్కలంగా ఉన్నాయి. అయినా తెలుగులో హీరోయిన్‌గా నిలబడలేకపోయింది. హీరోయిన్‌గా కొన్ని సినిమాలు చేసిన హిట్ అనేది రాకపోవడంతో హీరోయిన్‌ రాయ్ లక్ష్మీని టాలీవుడ్ ఇండస్ట్రీ పక్కన పెట్టేసింది. మళ్లీ ‘కాటమరాయుడు, ఖైదీ నెంబర్’  చిత్రాలలోని స్పెషల్ సాంగ్స్ కోసం అమ్మడి పిలుపు రావడంతో మళ్లీ టాలీవుడ్‌లో బిజీ హీరోయిన్‌గా మారుతుందని ఆశపడింది కానీ అలాంటిదేమీ జరగలేదు. కానీ బాలీవుడ్ మాత్రం రాయ్ లక్ష్మీకి బంపర్ ఆఫర్ తగిలింది. ‘జూలీ ’ రూపంలో కొన్ని రోజులుగా బాలీవుడ్‌ని షేక్ చేస్తున్న రాయ్ లక్ష్మీ... సినిమా విడుదల విషయంలో మాత్రం ఆ అదృష్టం కలిసిరాలేదు. ఇక ఎట్టకేలకు ఈ చిత్రానికి నవంబర్ న మోక్షం లభించబోతోంది. విడుదల దగ్గర పడుతుండటంతో ప్రమోషన్ విషయంలో రాయ్ లక్ష్మీ రెచ్చిపోతోంది. హాట్ హాట్ ఫోటోలను సోషల్ మీడియాలో షేర్ చేసి ఈ సినిమాపై విపరీతమైన అంచనాలను పెంచేస్తుంది. తాజాగా ఆమె పోస్ట్ చేసిన ఈ బైక్‌తో ఉన్న ఫొటో సోషల్ మీడియాలో హల్‌చల్ చేస్తోంది. ■\n",
            "÷ రిలయన్స్ జియో నుంచి ఎదురవుతున్న పోటీని తట్టుకోవడానికి వొడాఫోన్ ఓ సంచలన నిర్ణయం తీసుకుంది. జియోను బీట్ చేసేలా ఓ సరికొత్త ఆఫర్‌ను ప్రకటించాలని భావిస్తోంది. వొడాఫోన్ యూజర్లు  రూపాయలతో రీచార్జ్ చేసుకుంటే జీబీ జీ డేటాతో పాటు అన్‌లిమిటెడ్ కాల్స్‌  రోజుల పాటు పొందొచ్చని తెలిసింది. రిలయన్స్ జియో  రూపాయల ప్యాక్‌‌కు,  రూపాయల ప్యాక్ ప్రత్యామ్నయంగా విడుదల చేయాలని వొడాఫోన్ భావిస్తోంది. అయితే ఒక్క విషయంలో జియో కంటే వొడాఫోన్ ఓ ముందడుగు వేసింది.   రూపాయల ప్యాక్ కేవలం జియో ప్రైమ్ మెంబర్‌షిప్ పొందిన వారికి మాత్రమే వర్తిస్తుందని ముఖేష్ అంబానీ తెలిపారు. వొడాఫోన్ ప్రకటించాలని భావిస్తున్న  రూపాయల ప్యాక్‌పై ఎటువంటి నిబంధనలు లేవు. వొడాఫోన్ కస్టమర్లందరికీ ఈ ప్యాక్ వర్తిస్తుంది. అంతేకాదు,  రూపాయలతో మొదటి సారి రీచార్జ్ చేయించుకునే కస్టమర్లకు మరో బంపర్ ఆఫర్ కూడా వరించనుంది. డబుల్ డేటా విత్ డబుల్ వ్యాలిడిటీ బెన్‌ఫిట్స్‌ను వినియోగదారులు పొందొచ్చు. మొదటిసారి రీచార్జ్ చేసుకుంటే  రూపాయలకు  జీబీ,  రోజుల వ్యాలిడిటీతో లభిస్తుందని సమాచారం. అయితే ఈ ఆఫర్‌పై వొడాఫోన్ అధికారికంగా ప్రకటించలేదు. ■\n",
            "÷ \n",
            "అబుదాబి: వరుసగా రెండు విజయాలతో దూసుకెళ్తున్న భారత గ్రాండ్‌ మాస్టర్‌ ద్రోణ వల్లి హారికను బెలారస్‌ గ్రాండ్‌ మాస్టర్‌ నిలువరించాడు. అబుదాబి అంతర్జాతీయ చెస్‌ ఫెస్టివల్లో మూడో రౌండ్‌ గేమ్‌లో కిరిల్‌ స్థుపక్‌ (బెలారస్‌)తో హారిక పాయింట్‌ పంచుకుంది. నల్లపావులతో ఆడిన హారిక  ఎత్తుల అనం తరం కిరిల్‌తో డ్రాకు అంగీకరించింది. ■\n",
            "÷ \n",
            "న్యూఢిల్లీ : చైనా అక్రమ చొరబాట్లకు అడ్డుకట్ట వేసేందుకు భారత సైన్యం సరికొత్త ప్రయోగం చేయబోతోంది. లడఖ్‌లోని వాస్తవాధీన రేఖ వెంబడి చొరబాట్లను నిరోధించేందుకు ఒంటెల సేవలను వినియోగించుకోవాలని భారత సైన్యం నిర్ణయించింది. సరిహద్దుల్లో గస్తీ తిరగడంతోపాటు, పెద్ద ఎత్తున ఆయుధాలు, ఇతర వస్తువులను రవాణా చేసేందుకు ఒంటెలను ఉపయోగించుకోబోతోంది. రెండు మూపురాలు ఉన్న ఒంటెలు సుమారు  నుంచి  కేజీల బరువును మోయగలవు. ఈ ఒంటెలు రెండు గంటల సమయంలో సుమారు  కి.మీ.లు ప్రయాణించగలవు. ప్రస్తుతం మన సైన్యం కంచరగాడిదలు, గుర్రాలను ఉపయోగించుకుంటోంది. రెండు మూపురాలు ఉండే ఒంటెలు లడఖ్‌లోని నూబ్రా లోయలో మాత్రమే కనిపిస్తాయి. ప్రయోగాత్మక ప్రాజెక్టు సఫలమైతే ఒకే మూపురంగల ఒంటెలకు కూడా  శిక్షణ ఇస్తారని తెలుస్తోంది. ■\n",
            "÷ పాట్నా: ఓ విమానానికి తృటిలో ప్రమాదం తప్పింది. టేకాఫ్‌ అవుతుండగా ఇంజన్ నుంచి పొగలు వచ్చాయి. గుర్తించిన పైలట్ అత్యవసరంగా ఆ విమానాన్ని నిలిపివేశారు. దీంతో అందులోని  మంది ప్రయాణికులు క్షేమంగా బయటపడ్డారు. బీహార్‌లోని పాట్నా ఎయిర్‌పోర్టులో శుక్రవారం సాయంత్రం ఈ ఘటన జరిగింది. పాట్నా నుంచి ఢిల్లీ వెళ్తున్న ఇండిగో విమానం టేకాఫ్ అవుతుండగా ఇంజన్ నుంచి పొగలు రావడాన్ని పైలట్ గుర్తించారు. ఆ వెంటనే రన్‌వే పై దాన్ని అత్యవసరంగా నిలిపివేశారు. అందులోని  మంది ప్రయాణికులను ఎమర్జెన్సీ డోర్ల సహాయంతో బయటకు తీశారు. పెద్ద ప్రమాదం తప్పడంతో వారంతా ఊపిరి పీల్చుకున్నారు. విమానం ఇంజన్ రెక్క బయటకు రావడంతో పొగలు వచ్చినట్లు ఎయిర్ పోర్ట్ అధికారులు చెబుతున్నారు. ఈ ఘటనతో పలు విమాన సర్వీసులకు అంతరాయం ఏర్పడింది. దీంతో ఢిల్లీలో శుక్రవారం అర్థరాత్రి జరగనున్న జీఎస్టీపై పార్లమెంట్ ప్రత్యేక సమావేశంలో పాల్గొనేందుకు బయలు దేరిన బీజేపీ రాష్ట్ర అధ్యక్షుడు సుశీల్ కుమార్ మోదీతో పాటు పలువురు పార్టీ నేతలు విమానాశ్రయంలో నిలిచిపోయారు. ■\n",
            "÷ న్యూఢిల్లీ : కాంగ్రెస్ అధ్యక్షురాలు సోనియా గాంధీ ఆసుపత్రి నుంచి డిశ్చార్జ్ అయ్యారు. ఆమెకు శ్వాస సంబంధ అస్వస్థత తలెత్తడంతో ఆదవారం రాత్రి . గంటలకు సర్ గంగారామ్ ఆసుపత్రికి తరలించారు. నిపుణులైన వైద్యులు ఓ రోజంతా పరిశీలించిన మీదట సోమవారం సాయంత్రం డిశ్చార్జ్ చేసినట్లు వైద్యులు మంగళవారం తెలిపారు. డాక్టర్ డీఎస్ రాణా మాట్లాడుతూ సోనియా గాంధీకి ఆస్త్మా ఉందని, వాతావరణం మారినపుడు ఆమె శ్వాసపై ప్రభావం చూపుతుందని తెలిపారు. ప్రస్తుతం ఆమె ఆరోగ్యం నిలకడగా ఉన్నట్లు తెలిపారు. ■\n",
            "÷ హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌) : డిసెంబరుతో ముగిసిన త్రైమాసికంలో ఎన్‌ఎండిసి అద్భుతమైన ఫలితాలను ప్రకటించింది. అక్టోబరు-డిసెంబరు త్రైమాసికంలో రాబడులు గణనీయంగా పెరగటంతో నికర లాభం ఏకంగా . శాతం వృద్ధి చెంది . కోట్ల రూపాయలుగా నమోదైంది. అంతకుముందు ఏడాది ఇదే కాలంలో కంపెనీ లాభం . కోట్ల రూపాయలుగా ఉంది. కాగా త్రైమాసిక సమీక్షా కాలంలో మొత్తం రాబడులు కూడా . శాతం వృద్ధితో ,. కోట్ల రూపాయల నుంచి ,. కోట్ల రూపాయలకు పెరిగాయి. మరోవైపు మొత్తం వ్యయాలు కూడా ,. కోట్ల రూపాయల నుంచి ,. కోట్ల రూపాయలకు దూసుకుపోయాయి. కాగా ఈ కాలంలో ముడి ఇనుప ఖనిజం విక్రయాలు ,. కోట్ల రూపాయల నుంచి ,. కోట్ల రూపాయలకు పెరిగాయి. బైలదిల్లా గనుల్లో ముడి ఇనుప ఖనిజ ఉత్పత్తి సామర్థ్యాన్ని పెంచేందుకు గాను కిరండోల్‌, జగదల్‌పూర్‌ మధ్య రైల్వే లైన్‌ డబ్లింగ్‌ పనులను చేపట్టేందుకు గాను రైల్వే శాఖతో అవగాహనా ఒప్పందం కుదుర్చుకున్నట్లు ఎన్‌ఎండిసి తెలిపింది. సోమవారం బిఎ్‌సఇలో ఎన్‌ఎండిసి షేరు స్వల్ప నష్టంతో . రూపాయల వద్ద క్లోజైంది. ■\n",
            "÷  ఈ సినిమాకు ఇద్దరు హీరోయిన్లు కావాలని టాక్‌. ఒక్క హీరోయిన్‌ను వెతకడానికే చాలా పాట్లు పడ్డారు. ఇప్పుడు ఇద్దరు హీరోయిన్లను వెతికే పనిలో పడిందట చిత్ర బృందం. మరోసారి కాజల్‌ను తీసుకునే ఆలోచనలో కూడా ఉన్నారట. పనిలోపనిగా బాలీవుడ్‌ హీరోయిన్లను కూడా సంప్రదిస్తున్నారట. ■\n",
            "÷ \n",
            "నవ్యాంధ్ర రాజధాని అమరావతికి సంబంధించిన సమాచార దర్శిని(డైరీ)ని విడుదల చేసేందుకు రాష్ట్ర ప్రభుత్వం చర్యలు తీసుకోవాలి. డైరీని విడుదల చేయకపోవడం వల్ల ఏ కార్యాలయం ఎక్కడ ఉందో తెలియని అనిశ్చిత పరిస్థితి కొనసాగుతుంది. అన్ని కార్యాలయాల చిరునామాలతో పాటు ఫోన్‌నెంబర్లను ప్రచురించి సమాచార దర్శినిని విడుదల చేయాలి. రైల్వే, బస్‌స్టేషన్ల నుంచి ఆయా కార్యాలయ ప్రాంతాలకు వెళ్లే సిటీ బస్సుల నెంబర్లను సైతం పొందుపరచాలి. ప్రజల సౌకర్యార్థం ప్రభుత్వం వెంటనే ఈ పనిని పూర్తి చేయించి అమరావతి డైరీని ప్రచురించి విడుదల చేయాలి. ఈ డైరీని ఉచితంగా లేదా నామమాత్రపు ధరకు విక్రయించాలి. సమాచార, పౌర సంబంధాల శాఖ (ఐఅండ్‌పీఆర్‌) ద్వారా ప్రజలను అందజేయవచ్చు. ప్రభుత్వం ఈ సూచనను పరిశీలించి తగు చర్యలు తీసుకోవాలి.- వాండ్రంగి కొండలరావు, పొందూరు, శ్రీకాకుళం ■\n",
            "÷ ఆశ్చర్యపోయారా..? అయినా ఇది అక్షరాల నిజం. చిత్ర నిర్మాణ ప్రపంచంతో అనుబంధం ఉన్నవారందరికీ ఈ విషయం తెలిసిందే. దీని వెనుక ఓ నేపథ్యం ఉంది. గొప్ప అనుభవ స్ఫూర్తి ఉంది. ఓ మహాభవన నిర్మాణంలో ఎన్నో రాళ్లు ఉన్నా అవి పైకి కనిపించవు. కొందరి మహోన్నత విజయాల వెనుక ఉండే నేపథ్యమూ ఇంతే. బేసిగ్గా రాజమౌళిది ఫాంటసీ వరల్డ్. అద్భుత ఊహా ప్రపంచం.. దీనికి ఆయన తీసిన చిత్రాలే ఉదాహరణ. వీటిలో యమదొంగ గొప్పది. జనాన్ని ఉర్రూతలూపింది. ఈ చిత్రం తర్వాత జానపద జిమ్మిక్కులతో వడ్డించిన వినోద భోజనం మగదీర. ఈ చిత్రం నిర్మాణ సమయంలో మెగాస్టార్ చిరంజీవి, దర్శకుడు రాజమౌళికి ఎన్నో సూచనలు ఇచ్చారు. మరెన్నో మార్గదర్శకాలు చూపారు. ఈ కారణాలతో మగధీర చిత్రంలో విడుదలకు ముందు రాజమౌళి కొన్ని మార్పులు చేశారు. ఈ చిత్రం సంచలనం సృష్టించిన విషయం అందరికీ తెలిసిందే. మగధీర సమయంలో చిరంజీవి చేసిన సూచనలు, మార్గదర్శకాలు, ప్రేక్షకుల నాడి పట్టుకునే టెక్నిక్ ఆయన దగ్గరే అభ్యసించారు. ఈ మార్గదర్శకమే బాహుబలి చిత్ర కథా రచన నుంచి నిర్మాణం వరకు రాజమౌళికి ఎంతో పనికొచ్చింది. మరిన్ని వివరాల కోసం ఈ వీడియో క్లిక్ చేయండి. ■\n",
            "\n",
            "÷ ఈ జూలీ యమా హాట్ గురూ.. ■\n",
            "÷ జియోకు సవాల్ విసురుతూ వొడాఫోన్ సంచలన ఆఫర్! ■\n",
            "÷ హారికకు తొలి డ్రా ■\n",
            "÷ ఒంటెలకు సైనిక శిక్షణ! ■\n",
            "÷ ఈ విమానానికి.. ఏమైంది? ■\n",
            "÷ నిలకడగా సోనియా ఆరోగ్యం ■\n",
            "÷ ఎన్‌ఎండిసి లాభం రూ.  కోట్లు ■\n",
            "÷ చిరంజీవికి హీరోయిన్‌ ఇబ్బందులు?  ■\n",
            "÷ అమరావతి సమాచార దర్శిని ■\n",
            "÷ బాహుబలి విజయం వెనుక చిరంజీవి... ■\n",
            "÷ అర్జున్ రెడ్డి సూపర్ సక్సెస్ డైరెక్టర్ సందీప్ రెడ్డి వంగాని ఓవర్ నైట్ స్టార్‌ని చేసింది. అతడితో కలసి పనిచేయడానికి స్టార్స్ ఆసక్తి చూపిస్తున్నారట. టాలీవుడ్ ప్రిన్స్ సైతం ఓపెన్ ఆఫర్ ఇచ్చాడట…?అర్జున్ రెడ్డి భారీ విజయం హీరో విజయ్ దేవరకొండకే కాదు దర్శకుడు సందీప్ రెడ్డి వంగకి కూడా మంచి పేరు తెచ్చిపెట్టింది. ఈ సినిమాతో సందీప్ అందరి దృష్టిని ఆకర్షించాడు. సందీప్ ఈ సినిమాని మలిచిన విధానాన్ని టాలీవుడ్ ప్రముఖ దర్శకులేకాదు స్టార్స్ సైతం ప్రశంసించారు. ఇక ప్రిన్స్ మహేశ్ అయితే సినిమాను మెచ్చుకోడమే కాదు దర్శకుడికి బంపర్ ఆఫర్ కూడా ఇచ్చాడట.అర్జున్ రెడ్డి సినిమా చూసిన మహేశ్ బాబు కలమన్నారని ఇటీవల  ఓ ఇంటర్వ్యూలో చెప్పాడు సందీప్ రెడ్డి. ఇప్పటికే మహేశ్ భార్య నమ్రతతో చర్చలు పూర్తయ్యాయట.మహేశ్‌ను మెప్పించేలా కథను రెడీ చేసి కలుస్తానని అంటున్నాడు. మహేశ్ నటించిన తాజా చిత్రం ‘స్పైడర్’ తెలుగు తమిళ ఆడియోలు చెన్నైలో విడుదలయ్యాయి. సినిమా ఈ నెల న విడుదల కానుంది. మరి సందీప్ రెడ్డి  కథ మహేశ్‌ను ఏ మేరకు ఆకట్టుకుంటుందో చూడాలి. ■\n",
            "÷ న్యూఢిల్లీ : హెచ్బీ వీసాల గురించి అమెరికా అధ్యక్షుడు డొనాల్డ్ ట్రంప్‌తో ప్రధాన మంత్రి నరేంద్ర మోదీ సవివరంగా చర్చించారని విదేశాంగ మంత్రి సుష్మా స్వరాజ్ చెప్పారు. ఆమె గురువారం రాజ్యసభకు ఈ వివరాలను తెలిపారు. మోదీ ఇటీవల అమెరికాలో పర్యటించినపుడు అత్యంత కీలకమైన హెచ్బీ వీసాల గురించి ట్రంప్‌తో ప్రస్తావించలేదని ప్రతిపక్షాలు చేసిన ఆరోపణలను సుష్మా స్వరాజ్ తోసిపుచ్చారు. కాంగ్రెస్ ఎంపీ ఆనంద్ శర్మ రాజ్యసభలో లేవనెత్తిన ఈ అంశంపై సుష్మా స్వరాజ్ మాట్లాడుతూ ‘‘హెచ్బీ వీసా అనే పదాన్ని ఉపయోగించకుండా, దాని ఆత్మ గురించి మోదీ, ట్రంప్ మధ్య సవివరమైన చర్చ జరిగింది. అమెరికా ఆర్థిక వ్యవస్థకు ఇండియన్ స్కిల్డ్ ప్రొఫెషనల్స్ మహోన్నత సేవలందిస్తున్నట్లు ట్రంప్‌ అంగీకరించేలా మోదీ చేయగలిగారని చెప్పడానికి గర్విస్తున్నాను’’ అని తెలిపారు. ■\n",
            "÷ రాష్ట్రపతి అభ్యర్థి విషయంలో ఎన్డీయే భాగస్వామి అయిన శివసేన తన మద్దతు విషయాన్ని సస్పెన్స్‌లో పెట్టింది. కోవింద్‌కు మద్దతు తెలపాలా.. వద్దా అనే విషయాన్ని నిర్ణయించడానికి పార్టీ అగ్రనేతలతో ఉద్ధవ్‌ ఠాక్రే ఓ సమావేశం నిర్వహిస్తారని శివసేన ఎంపీ సంజయ్‌ రౌత చెప్పారు.  శివసేన మద్దతు విషయాన్ని మంగళవారం వెల్లడిస్తామని ఉద్ధవ్‌ ఠాక్రే సాయంత్రం తెలిపారు.  మహారాష్ట్రలో మధ్యంతర ఎన్నికలు పెట్టి గెలవాలని బీజేపీ చూస్తోందని, ఎన్నికల్లో వాళ్లు గెలవచ్చు గానీ కశ్మీర్‌ను గెలవలేరని  సామ్నా సంపాదకీయంలో విమర్శించారు. ■\n",
            "÷ \n",
            "మెల్‌బోర్న్‌: ఆస్ర్టేలియన్‌ ఓపెన్‌ మిక్స్‌డ్‌ ఫైనల్లో భారత ఏస్‌ క్రీడాకారిణి సానియా మీర్జాకు చుక్కెదురైంది. కెరీర్‌లో ఏడో గ్రాండ్‌స్లామ్‌ టైటిల్‌ సాధించాలని భావించిన సానియాకు తీవ్ర నిరాశే ఎదురైంది. ఫైనల్లో మీర్జా-డోడిగ్‌ జంట అన్‌సీడెడ్‌ స్పియర్స్‌-కాబల్‌ జోడీ చేతిలో ఓడి రన్నరప్‌ ట్రోఫీతో సరిపెట్టుకుంది. ఆదివారం జరిగిన టైటిల్‌ ఫైట్‌లో రెండో సీడ్‌ సానియా-ఇవాన్‌ డోడిగ్‌ (క్రొయేషియా) జోడీ -, -తో వరుస సెట్లలో అబిగైల్‌ స్పియర్స్‌ (అమెరికా)-జువాన్‌ సెబాస్టియన్‌ కాబల్‌ (కొలంబియా) ద్వయం చేతిలో పరాజయం పాలైంది.  నిమిషాల పోరులో ఇండో-క్రొయేషియా ద్వయం స్థాయికి తగ్గ ప్రదర్శన చేయలేకపోయింది. మీర్జా జోడీ ఐదు డబుల్‌ ఫాల్ట్స్‌తో పాటు  అనవసర తప్పిదాలు చేసి మూల్యం చెల్లించుకుంది. ఇక స్పియర్స్‌ జంట రెండు ఏస్‌లు,  విన్నర్లు కొట్టింది. సానియా ద్వయం మాత్రం కేవలం ఒక్క ఏస్‌కే పరిమితమైంది. గ్రాండ్‌ స్లామ్‌ ఫైనల్లో ఓడడం మీర్జా-డోడిగ్‌ జోడీకి ఇది రెండోసారి. గతేడాది ఫ్రెంచ్‌ ఓపెన్‌ ఫైనల్లో లియాండర్‌ పేస్‌-మార్టినా హింగిస్‌ ద్వయం చేతిలో మీర్జా జంట ఓటమిపాలైంది. ■\n",
            "÷ అహ్మదాబాద్‌, మార్చి : బీజేపీని నిలువరించేందుకు భావసారూప్యం కలిగిన పార్టీలన్నీ కలిసి మహా కూటమిగా ఏర్పాటు కావాల్సిన అవసరం ఉందని ఎన్సీపీ అధినేత శరద్‌పవార్‌ అన్నారు. ఆదివారం అహ్మదాబాద్‌లో ఎన్సీపీ కొత్త కార్యాలయాన్ని ప్రారంభించేందుకు వచ్చిన సందర్భంగా ఆయన మాట్లాడారు. ■\n",
            "÷ న్యూఢిల్లీ: ఆస్తుల వ్యవహారంలో ప్రభుత్వం నుంచి తప్పించుకోలేక తలలు పట్టుకుంటున్న కొందరు రాజకీయ నేతలకు కేంద్రం త్వరలో మరో షాక్ ఇవ్వనుంది. ఇక నుంచి ఎన్నికల సందర్భంగా అభ్యర్థులు తమ జీవిత భాగస్వామి ఆస్తుల వివరాలు కూడా సమర్పించాల్సి ఉంటుంది. ఈ మేరకు కేంద్ర ప్రత్యక్ష పన్నుల మండలి (సీబీడీటీ) సుప్రీంకోర్టుకు వివరించింది. ఎన్నికల్లో నామినేషన్ వేస్తున్న సందర్భంగా ఆయా అభ్యర్థులు తమ జీవిత భాగస్వామి ఆస్తులు వెల్లడించాల్సి ఉంటుందని తెలిపింది. దీనికి ఎన్నికల సంఘం కూడా సూత్రప్రాయంగా అంగీకరించినట్టు పేర్కొంది.  మంది ఎంపీలు, ఎమ్మెల్యేల ఆస్తులు గణనీయంగా పెరిగినట్టు ఇటీవల కేంద్ర ప్రభుత్వం సుప్రీంకోర్టుకు విన్నవించిన సంగతి తెలిసిందే. ఈ నేపథ్యంలోనే రాజకీయ నేతల ఆస్తులపై సీబీడీటీ ఇలా వ్యాఖ్యానించడం గమనార్హం. ■\n",
            "÷ చెన్నై: ప్రైవేటు రంగంలోని కరూర్‌ వైశ్యా బ్యాంకు చీఫ్‌ ఎగ్జిక్యూటివ్‌ ఆఫీసర్‌, ఎండిగా పిఆర్‌ శేషాద్రి సోమవారం బాధ్యతలు స్వీకరించారు. ఆరేళ్లుగా ఈ పదవిలో ఉన్న కె వెంకట్రామన్‌ స్థానంలో ఆయన నియమితులయ్యారు. సోమవారం ఉదయం శేషాద్రి సిఇఒగా బాధ్యతలు చేపట్టారని బ్యాంకు తెలిపింది. బ్యాంకింగ్‌ వ్యవహారాల్లో  సంవత్సరాలకు పైబడి అనుభవం గల ఆయన వివిధ ఆర్థిక సంస్థల్లో పలు బాధ్యతలు నిర్వహించారు. ■\n",
            "÷ న్యూఢిల్లీ: ప్రభుత్వ రంగంలోని ఎన్‌ఎండిసి సెప్టెంబరు వ తేదీతో ముగిసిన త్రైమాసికంలో రికార్డు స్థాయిలో . లక్షల టన్నుల ఉత్పత్తిని సాధించింది. గత ఏడాది ఇదే త్రైమాసికంలో ఉత్పత్తి చేసిన ఇనుప ఖనిజంతో పోల్చితే ఈ త్రైమాసికం ఉత్పత్తి  శాతం అధికమని కంపెనీ తెలిపింది. అంతర్జాతీయ ఇనుము, ఉక్కు మార్కెట్లో ఆటుపోట్లు తీవ్రంగా ఉన్న వాతావరణంలో కూడా తాము ఈ రికార్డును సాధించగలిగామని తెలిపింది. ఇదే త్రైమాసికంలో ఇనుప ఖనిజం అమ్మకాలు . శాతం పెరిగి . లక్షల టన్నుల నుంచి  లక్షల టన్నులకు చేరాయి.  సెప్టెంబరు వ తేదీతోనే ముగిసిన ఆర్థిక సంవత్సరం ప్రథమార్ధంలో సంస్థ . కోట్ల టన్నుల ఇనుప ఖనిజాన్ని ఉత్పత్తి చేయగా . కోట్ల టన్నుల ఇనుప ఖనిజాన్ని విక్రయించింది. రికార్డు స్థాయి ఉత్పత్తిని సాధించినందుకు ఉక్కు శాఖ మంత్రి బీరేందర్‌ సింగ్‌  ట్విట్టర్‌ సందేశంలో తమను అభినందించారని ఎన్‌ఎండిసి తెలిపింది. సెప్టెంబరు  తో ముగిసిన రెండో త్రైవసిఇకంలో ఎన్‌ఎండిసి . శాతం వృద్ధితో . కోట్ల రూపాయల నికరలాభాన్ని ఆర్జించిన విషయం విదితమే. ■\n",
            "÷ మెగా హీరో సాయిధరమ్‌ తేజ్‌.. దర్శకుడు కృష్ణవంశీ తెరకెక్కిస్తున్న ‘నక్షత్రం’ సినిమాలో ఓ ప్రత్యేక పాత్రలో మెరిశాడు. అలెగ్జాండర్‌ అనే పాత్రలో తేజూ నటించాడు. ఈ పాత్ర చేసినందుకుగానూ తేజూ పారితోషికం ఏమీ తీసుకోలేదట. కృష్ణవంశీ మీద అభిమానంతోనే ఈ రోల్‌ చేశాడట. ‘గోవిందుడు అందరివాడేలే’ సినిమా సెట్స్‌లో కృష్ణవంశీని కలిసి ఏదైనా మంచి రోల్‌ ఇవ్వమని అడిగాడట సాయిధరమ్‌. అది గుర్తుపెట్టుకుని ‘నక్షత్రం’ సినిమాలో తేజూకు మంచి రోల్‌ ఆఫర్‌ చేశాడట కృష్ణవంశీ. ఈ పాత్రను తన జీవితంలోనే మరిచిపోలేను అంటున్నాడు తేజు. చిరంజీవి, పవన్‌ కల్యాణ్‌లను కలిసి కృష్ణవంశీతో పనిచేయబోతున్నట్టు తేజూ చెప్పాడట. ఇద్దరూ తనను అభినందించారని తెలిపాడు. కృష్ణవంశీతో పనిచేస్తే ఎంతో నేర్చుకోవచ్చని చిరంజీవి చెప్పారట. ‘వెరీగుడ్‌.. ఆల్‌ ది బెస్ట్‌’ అని పవన్‌ అన్నారట. ఈ విషయాలను సాయిధరమ్‌ వెల్లడించాడు. ■\n",
            "÷  కేరళ నటిపై అత్యాచారం కేసులో ప్రధాన నిందితుడు పల్సర్‌ సుని వెల్లడితిరువనంతపురం, ఆగస్టు : కేరళ నటిపై అత్యాచారం కేసులో నిందితుడైన పల్సర్‌ సుని పోలీసు విచారణలో సంచలన విషయాన్ని బయటపెట్టాడు. ఈ ఘోరాన్ని చేయడానికి తనకు ‘మేడం’ డబ్బులిచ్చారని తెలిపాడు. సదరు ‘మేడం’ పేరు చెప్పడానికి అతడు నిరాకరించాడు. ఆమె పేరు తర్వాత చెబుతానన్నాడు. అతడు చెబుతున్న ‘మేడం’ అనే వ్యక్తి.. హీరో దిలీప్‌ రెండో భార్య కావ్యామాధవనే అని పోలీసులు అనుమానిస్తున్నారు. అయితే, పల్సర్‌  సుని ఎవరో తనకు తెలియదని కావ్యామాధవన్‌ గతంలో పోలీసు విచారణలో పేర్కొన్న సంగతి తెలిసిందే. దీనిపైనా సుని స్పందించాడు. ఆమె చెబుతోంది పచ్చిఅబద్ధమని.. కావ్యకు తానెవరో తెలుసునని అతడు స్పష్టం చేశాడు. ■\n",
            "\n",
            "÷ మహేశ్ బాబుతో అర్జున్ రెడ్డి దర్శకుడు ■\n",
            "÷ మోదీ, ట్రంప్ హెచ్బీ వీసాలపై చర్చించారు : సుష్మా స్వరాజ్ ■\n",
            "÷ సస్పెన్స్‌లో పెట్టిన శివసేన ■\n",
            "÷ రన్నరప్‌ సానియా జోడీ  ■\n",
            "÷ బీజేపీని ఆపేందుకు మహా కూటమి: పవార్‌ ■\n",
            "÷ నేతల భార్యలకూ సెగ! ■\n",
            "÷ కెవిబి ఎండిగా శేషాద్రి ■\n",
            "÷ ఎన్‌ఎండిసిలో రికార్డు ఉత్పత్తి ■\n",
            "÷ ఆ సినిమా కోసం చిరు, పవన్‌ల పర్మిషన్‌ తీసుకున్నాడట! ■\n",
            "÷ ఆ ఘోరానికి డబ్బులిచ్చింది మేడమే ■\n",
            "÷ బీసీసీఐని కోరిన రాహుల్‌ ద్రావిడ్‌న్యూఢిల్లీ: పరస్పర విరుద్ధ ప్రయోజనాల వ్యవహారం వివాదాస్పదం అవుతున్న నేపథ్యంలో దానిపై స్పష్టత ఇవ్వాలని భారత మాజీ కెప్టెన రాహుల్‌ ద్రావిడ్‌ బీసీసీఐని కోరాడు. ద్రావిడ్‌ భారత జూనియర్‌ జట్లకు కోచగా పనిచేస్తూ ఐపీఎల్‌లో ఢిల్లీ డేర్‌డెవిల్స్‌కు కూడా మెంటార్‌గా వ్యవహరిస్తున్నాడు. దీంతో జస్టిస్‌ లోధా కమిటీ సిఫార్సుల ప్రకారం అతడు బోర్డు నుంచి పరస్పర విరుద్ధ ప్రయోజనాలు పొందుతున్నాడనే విమర్శలు ఎదురైన సంగతి తెలిసిందే. ప్రస్తుతం బీసీసీఐ రోజువారీ వ్యవహారాలు పర్యవేక్షిస్తున్న క్రికెట్‌ అడ్వయిజరీ కమిటీ (సీవోఏ)కి ఇటీవలే రాజీనామా చేసిన రామచంద్ర గుహ కూడా బీసీసీఐలో యథేచ్ఛగా సాగుతున్న విరుద్ధ ప్రయోజన వ్యవహారంపై ఆగ్రహం వ్యక్తం చేశాడు. ఈ నేపథ్యంలో ద్రావిడ్‌ తన పాత్ర ఏమిటో స్పష్టంగా తెలియజేయాలంటూ బీసీసీఐకి లేఖ రాశాడు. ■\n",
            "÷ పవర్ స్టార్ పవన్ కల్యాణ్ నటించిన ‘అత్తారింటికి దారేది’ చిత్రంలో పవన్‌కి అత్తగా నదియ నటించిన విషయం తెలిసిందే. అందులో ఆమె కూతుళ్లుగా.. పవన్ కల్యాణ్‌కి మరదళ్లుగా సమంత, ప్రణీతలు నటించారు. సినిమాలో పవన్ కల్యాణ్‌ని బావా.. బావా.. అంటూ సమంత ముద్దాడే సన్నివేశం సినిమాకి చాలా కీలకమే కాకుండా.. ఆ సీన్ అందరికీ మంచి రొమాంటిక్ ఫీల్‌ని కూడా తెప్పిస్తుంది. అయితే ఇప్పుడు పవన్ కల్యాణ్‌కి మరో కొత్త మరదలు రాబోతుంది. అదెలా అనుకుంటున్నారా? పవన్ కల్యాణ్, త్రివిక్రమ్ కాంబినేషన్‌లో తెరకెక్కిన చిత్రం ‘అజ్ఞాతవాసి’. ఈ చిత్రంలో హీరోయిన్‌లుగా కీర్తి సురేష్, అను ఇమ్మానుయేల్‌లు నటిస్తున్నారు. ఈ చిత్రంలో పవన్ కల్యాణ్‌కి మరదలుగా కీర్తి సురేష్ నటించనుందని చిత్ర వర్గాల ద్వారా తెలిసింది. ఇప్పటి వరకు కీర్తి సురేష్ ఇటువంటి పాత్రలో చేయలేదని, ముఖ్యంగా పవన్, కీర్తి సురేష్‌ల  మధ్య వచ్చే సన్నివేశాలు ఎంతో అద్భుతంగా ఉంటాయని, అందరినీ నవ్విస్తాయని చిత్ర వర్గాలు వెల్లడిస్తున్నాయి. ఇక ఈ చిత్రం సంక్రాంతి కానుకగా జనవరి వ తేదీని విడుదల కాబోతున్న విషయం తెలిసిందే. ■\n",
            "÷ \n",
            "ఆరు దశాబ్దాలుగా తన పాటలతో అలరించిన గానకోకిల ఎస్‌.జానకి ఇక విశ్రాంతి తీసుకుంటానని ప్రకటించారు.  ఏళ్ల కిందట మైసూరులో పాటలు పాడడం ప్రారంభించానని.. తన చివరి కచేరీ కూడా అక్కడే ఇచ్చి గాయనిగా రిటైరవుతానని వెల్లడించారు. ఈ నెల వ తేదీన మానసగంగోత్రి మైదానంలో చివరి కచేరీ చేయనున్నట్లు జానకి ప్రకటించారు. ఆదివారం మైసూరులో ఆమె మాట్లాడుతూ.. వయసు పైబడుతున్నందున పాడడం కష్టంగా ఉండటంతో ఈ నిర్ణయం తీసుకున్నట్లు వెల్లడించారు.- ఆంధ్రజ్యోతి, బెంగళూరు ■\n",
            "÷ 'జై లవకుశ' హీరోయిన్లు రాశిఖన్నా, నివేద థామస్ 'బిగ్ బాస్' షోలో సందడి చేశారు. చిత్ర ప్రమోషన్స్ లో భాగంగా ఈ షోలో పాల్గొంది చిత్రయూనిట్. ఈ సందర్బంగా అక్కడ ఎన్టీఆర్ తో రాశిఖన్నా, నివేద థామస్ ఫోటోలు దిగారు. తాజాగా ఈ ఫోటోలను రాశిఖన్నా సోషల్ మీడియా ద్వారా అభిమానులతో పంచుకుంది. 'బిగ్ బాస్' హౌస్ కి వెళ్లడం చక్కని అనుభవం అని టాగ్ చేసింది. లైకులు, షేర్ లతో ఈ ఫోటోలు చూసి ముచ్చటపడుతున్నారు నందమూరి అభిమానులు. నందమూరి కళ్యాణ్ రామ్ నిర్మాణంలో వస్తున్న 'జై లవకుశ' సెప్టెంబర్ న ప్రేక్షకుల ముందుకు రాబోతుంది. ఇప్పటికే విడుదలైన చిత్ర మూడు టీజర్లు, ట్రైలర్, ప్రమోషన్ సాంగ్స్ సోషల్ మీడియాను షేక్ చేస్తున్నాయి. దేవి శ్రీ సంగీతం బాగా ఆకట్టుకుంటోంది. ■\n",
            "÷ ఏసీఏ కార్యదర్శి పదవికి గుడ్‌ బై జూ అధ్యక్షుడిగా ఎంపికైన రంగ రాజు విజయవాడ (ఆంధ్రజ్యోతి): జస్టిస్‌ ఆర్‌ఎం లోధా కమిటీ సిఫారసుల నేపథ్యంలో ఆంధ్ర క్రికెట్‌ సంఘం (ఏసీఏ)లో భారీ మార్పులు చోటుచేసుకున్నాయి. బోర్డులో తొమ్మిదేళ్ల కాలం ముగియడంతో ఏసీఏ కార్యదర్శి పదవి నుంచి గోకరాజు గంగరాజు తప్పుకొన్నారు. అధ్యక్షుడిగా డీవీఎ్‌సఎస్‌ సోమయాజులు స్థానంలో గంగరాజు కుమారుడు జీవీకే రంగరాజు అధ్యక్షుడిగా ఎన్నికయ్యారు. సోమవారమిక్కడ ఏర్పాటు చేసిన ఏసీఏ ఎగ్జిక్యూటివ్‌ కమిటీ సమావేశంలో రంగరాజును అధ్యక్షుడిగా ఎన్నుకున్నారు. గంగరాజు వైదొలిగిన నేపథ్యంలో అరుణ్‌ కుమార్‌ కార్యదర్శిగా, దుర్గా ప్రసాద్‌ సంయుక్త కార్యదర్శిగా ఎన్నికయ్యారు. పీవీ దేవవర్మను ఉపాధ్యక్షుడిగా, కేఎస్‌ రామచంద్రరావును కోశాధికారిగా నియమించారు. గంగరాజుకు ఏసీఏ, బీసీసీఐల్లో తొమ్మిదేళ్ల పదవీకాలం పూర్తయింది. లోధా కమిటీ సిఫారసుల ప్రకారం తొమ్మిదేళ్ల పదవీకాలం పూర్తయిన వారు రాష్ట్ర, జాతీయ సంఘాల్లో ఉండకూడదు. దీంతో గంగరాజు దిగిపోక తప్పలేదు. ■\n",
            "÷ భోపాల్: కొత్తదనానికి మారు పేరైన మధ్యప్రదేశ్ ముఖ్యమంత్రి శివరాజ్ సింగ్ చౌహాన్ మరోసారి తనదైన స్టైల్ చాటుకున్నారు. మంగళవారం వినూత్నంగా కేబినెట్ భేటీ నిర్వహించారు. ఉదయం నుంచి సాయంత్రం వరకు జరిగే సమావేశానికి ఎవరి భోజనాలను వారే తెచ్చుకోవాలని ముందుగానే మంత్రులకు సూచించారు. దీంతో మంత్రులంతా తమ తమ క్యారేజీలతో కేబినెట్ సమావేశానికి హాజరయ్యారు. మంత్రివర్గ సమావేశంలోనే అంతా కలిసి సామూహిక భోజనాలు చేశారు. సీఎం శివరాజ్ సింగ్ చౌహాన్ తాను తెచ్చిన ప్రత్యేక వంటకాలను మంత్రులకు స్వయంగా వడ్డించారు. మంత్రులు కూడా తమ ఆహార పదార్థాలను సహచరులతో పంచుకున్నారు. ■\n",
            "÷ \n",
            "పెండ్యాల మోహనాచారి – సరితలు చేసిన పాపం ఏమిటీ? అనే నినాదంతో నేడు మధ్యాహ్నం  గంటలకు సుందరయ్య విజ్ఞాన కేంద్రంలో రైతు సంస్మరణ సభ జరుగుతుంది. స్పీకర్ సిరికొండ మధుసూదనాచారి, జస్టిస్‌ బి. చంద్రకుమార్‌, జయధీర్‌ తిరుమలరావు, కోదండరాం, తమ్మినేని వీరభద్రం, విమలక్క తదితరులు వక్తలు.- ఎరుక (సాహితీ సాంస్కృతిక సామాజిక వేదిక) ■\n",
            "÷  ట్రేడింగ్‌ వ్యూహం... ■\n",
            "÷ పాలకొల్లు, మే  (ఆంధ్రజ్యోతి): చలన చిత్రాన్ని సంచలన చిత్రం చేసిన దర్శకరత్న దాసరి నారాయణరావుకు సొంతూరు పాలకొల్లు అంటే ఎంతో మమకారం. పంచారామ క్షేత్రాల్లో ఒకటైన ఆ ఊరి పెదగోపురం సాక్షిగా తన ప్రస్థానం ప్రారంభించిన దాసరి.. క్షీరపురి మురిసేలా ఎంతో ఎత్తుకు ఎదిగారు. ఉద్యోగాల వేటలో హైదరాబాద్‌ చేరినా ఆయన మనసంతా సొంతగడ్డపైనే ఉండేది. పాలకొల్లు పేరు వింటే హుషారు వచ్చేసేది. సినీ, రాజకీయ రంగాల్లో తనదైన ముద్ర వేసిన దాసరి సొంత ఊరి అభివృద్ధికీ పాటుపడ్డారు. ప్రభుత్వ మహిళా కళాశాల నిర్మాణానికి, దళితవాడలో ప్రాథమిక పాఠశాల నిర్మాణానికి విరాళాలిచ్చారు. పాలకొల్లు ప్రధాన కాలువపై వంతెన (దాసరి వారధి) నిర్మాణానికి కృషి చేశారు. ప్రతి ఏటా మే న తన పుట్టిన రోజు సందర్భంగా పేద విద్యార్థులకు ఉపకార వేతనాలు అందజేస్తున్నారు. పాలకొల్లు నుంచి ఎందరో యువకులకు సినీ రంగంలో అవకాశాలు కల్పించారు. తన శిష్యులలో కోడి రామకృష్ణ దర్శకుడిగా మంచి పేరు సంపాదించి, గురువుకు తగ్గ శిష్యునిగా తనకు ఆనందాన్ని మిగిల్చారని ఒక సందర్భంలో దాసరి చెప్పారు. ■\n",
            "÷ న్యూఢిల్లీ: సమాజ్‌వాదీ పార్టీలో చోటుచేసుకున్న రాజకీయ డ్రామాకు ఇంకా తెరపడినట్టు లేదు. సమాజ్‌వాదీ పార్టీ  నుంచి బషిష్కరణకు గురైన ఆ పార్టీ రాజ్యసభ ఎంపీ అమర్ సింగ్ ఆదివారంనాడు సంచలన వ్యాఖ్యలు చేశారు. ముఖ్యమంత్రి అఖిలేష్ యాదవ్ బాబాయ్ రామ్‌గోపాల్ యాదవ్ తనను చంపేస్తానని బెదరించినట్టు అమర్ సింగ్ ఆరోపించారు. 'రామ్‌గోపాల్ యాదవ్ టార్గెట్ నేనే. ఆయన బహిరంగంగానే నన్ను చంపుతానని బెదిరించారు' అని తెలిపారు. అమర్‌సింగ్ ఉత్తరప్రదేశ్ వస్తే క్షేమంగా తిరిగి వెళ్లలేరని కూడా రామ్‌గోపాల్ తనను హెచ్చరించినట్టు చెప్పారు. పార్టీ నుంచి బహిష్కరణకు గురైన తర్వాత తనను ఓడిపోయిన పోట్లగిత్తలా రామ్‌గోపాల్ యాదవ్ చూస్తున్నారని అన్నారు.  సమాజ్‌వాదీ పార్టీ గుర్తు సైకిల్‌ను అఖిలేష్‌కు కేటాయించిన సందర్భంలో ఆయనను ప్రశంసిస్తూ తాను చేసిన వ్యాఖ్యలను కూడా అమర్‌సింగ్ సమర్ధించుకున్నారు. సమాజ్‌వాదీ పార్టీలో పునరాగమనం కోసం తాను అఖిలేష్‌ను పొగడలేదని అన్నారు. యుద్ధం అన్న తర్వాత గెలుపుఓటములు సహజమని, తాను మాత్రం అన్ని సందర్భాల్లోనూ  మూలాయంతోనే ఉన్నానని అమర్ సింగ్ వివరణ ఇచ్చారు. ■\n",
            "\n",
            "÷ ‘విరుద్ధ ప్రయోజనం’పై స్పష్టత ఇవ్వండి ■\n",
            "÷ పవన్ కల్యాణ్ కొత్త మరదలు ■\n",
            "÷ గానకోకిల ఎస్. జానకి సంచలన నిర్ణయం ■\n",
            "÷ 'బిగ్ బాస్' షోలో మెరిసిన 'జై లవకుశ' టీమ్.. ■\n",
            "÷ వైదొలిగిన గంగరాజు  ■\n",
            "÷ వినూత్నంగా.. కేబినెట్ సమావేశం నిర్వహించిన సీఎం ■\n",
            "÷ రైతు సంస్మరణ సభ ■\n",
            "÷ సాధారణంగా మెరుగు  ■\n",
            "÷ పాలకొల్లు అంటే ఎంతో మమకారం ■\n",
            "÷ నన్ను చంపుతానని ఆయన బెదిరించారు... ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_AL9W9qq12"
      },
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIoL8wYncpc"
      },
      "source": [
        "def evaluate(sentence, max_length=40):\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  sentence = tf.convert_to_tensor([sentence])\n",
        "  sentence = bd_tokenizer.tokenize(sentence)\n",
        "  sentence = bd_tokenizer.string_to_id(sentence)\n",
        "  sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "  encoder_input = sentence\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  start  = tf.convert_to_tensor('÷')\n",
        "  start= hd_tokenizer.tokenize(start)\n",
        "  output= hd_tokenizer.string_to_id(start)\n",
        "  end  = tf.convert_to_tensor('■')\n",
        "  end= hd_tokenizer.tokenize(end)\n",
        "  end= hd_tokenizer.string_to_id(end)[1]\n",
        "  end = tf.expand_dims(end, 0)\n",
        "  output = tf.expand_dims(output, 0)\n",
        "  for i in range(max_length):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions, axis=-1)\n",
        "    predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == end:\n",
        "      break\n",
        "\n",
        "  # output.shape (1, tokens)\n",
        "  trans = hd_tokenizer.detokenize(output)# shape: ()\n",
        "  text = []\n",
        "  for x in trans.numpy():\n",
        "    text.append(x.decode('utf-8'))\n",
        "\n",
        "  return text, attention_weights"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTkU2cv8rUIP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13JVpiD_ZPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2560a4d-91b9-4935-819c-a770303b8561"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ న్యూఢిల్లీ: సమాజ్‌వాదీ పార్టీలో చోటుచేసుకున్న రాజకీయ డ్రామాకు ఇంకా తెరపడినట్టు లేదు. సమాజ్‌వాదీ పార్టీ  నుంచి బషిష్కరణకు గురైన ఆ పార్టీ రాజ్యసభ ఎంపీ అమర్ సింగ్ ఆదివారంనాడు సంచలన వ్యాఖ్యలు చేశారు. ముఖ్యమంత్రి అఖిలేష్ యాదవ్ బాబాయ్ రామ్‌గోపాల్ యాదవ్ తనను చంపేస్తానని బెదరించినట్టు అమర్ సింగ్ ఆరోపించారు. 'రామ్‌గోపాల్ యాదవ్ టార్గెట్ నేనే. ఆయన బహిరంగంగానే నన్ను చంపుతానని బెదిరించారు' అని తెలిపారు. అమర్‌సింగ్ ఉత్తరప్రదేశ్ వస్తే క్షేమంగా తిరిగి వెళ్లలేరని కూడా రామ్‌గోపాల్ తనను హెచ్చరించినట్టు చెప్పారు. పార్టీ నుంచి బహిష్కరణకు గురైన తర్వాత తనను ఓడిపోయిన పోట్లగిత్తలా రామ్‌గోపాల్ యాదవ్ చూస్తున్నారని అన్నారు.  సమాజ్‌వాదీ పార్టీ గుర్తు సైకిల్‌ను అఖిలేష్‌కు కేటాయించిన సందర్భంలో ఆయనను ప్రశంసిస్తూ తాను చేసిన వ్యాఖ్యలను కూడా అమర్‌సింగ్ సమర్ధించుకున్నారు. సమాజ్‌వాదీ పార్టీలో పునరాగమనం కోసం తాను అఖిలేష్‌ను పొగడలేదని అన్నారు. యుద్ధం అన్న తర్వాత గెలుపుఓటములు సహజమని, తాను మాత్రం అన్ని సందర్భాల్లోనూ  మూలాయంతోనే ఉన్నానని అమర్ సింగ్ వివరణ ఇచ్చారు. ■\n",
            "Prediction     : ['÷ నన్ను చంపుతానని ఆయన బెదిరించారు.. నన్ను సీజ్ ■']\n",
            "Ground truth   : ÷ నన్ను చంపుతానని ఆయన బెదిరించారు... ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIVJYOk3ecaw",
        "outputId": "bf25a8c3-d6c2-4da5-aee4-30ef038b5f07"
      },
      "source": [
        "target1 = data1.pop('heading')\n",
        "data1 = data1.pop('body')\n",
        "import tensorflow as tf\n",
        "test = tf.data.Dataset.from_tensor_slices((data1.values, target1.values))\n",
        "len(test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf64hwjefvE",
        "outputId": "6698bc91-5038-442d-9af3-5b444bbf9736"
      },
      "source": [
        "for bd_examples, hd_examples in test.batch(1).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgqqMTR9ehrP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj6k4JYheo4G",
        "outputId": "da53abab-e3d6-456e-baff-4c6040d4442f"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "Prediction     : ['÷ రేపటిరీ మరో యాంకర్ల ఆహ్వానం ■']\n",
            "Ground truth   : ÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}