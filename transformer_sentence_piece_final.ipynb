{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish2Parimi/Telugu_Headline_Generator/blob/main/transformer_sentence_piece_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lrkhV34tstz"
      },
      "source": [
        "# !pip install tensorflow_text\n",
        "# !pip install sentencepiece\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PqoYuxqvMmy"
      },
      "source": [
        "# import sentencepiece as spm\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=body --vocab_size=8000')\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=heading --vocab_size=2000')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuN0Do6PvMq5"
      },
      "source": [
        "import requests\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "url = 'https://github.com/Ashish2Parimi/Telugu_Headline_Generator/raw/main/data.model'\n",
        "bd_model = requests.get(url).content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGpvHdPt1wx"
      },
      "source": [
        "bd_tokenizer = text.SentencepieceTokenizer(bd_model, out_type=tf.string)\n",
        "hd_tokenizer = bd_tokenizer\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8dORzk1W5M",
        "outputId": "1378ce76-9996-45da-a9f2-439b3eae92f7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# data = data.drop(['SNo','date','topic'],axis = 1)\n",
        "data.dropna(axis = 0,inplace = True)\n",
        "\n",
        "# data = data.applymap(lambda x:x.encode(encoding='UTF-8'))\n",
        "for i,b in enumerate(data['body'].values):\n",
        "    if len(b)>1000:\n",
        "        data.drop(i, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def format_data(data):\n",
        "    START = '÷'\n",
        "    END = '■'  \n",
        "       \n",
        "    data['body'] = START + ' ' + data['body'] + ' ' + END \n",
        "    data['heading'] = START + ' ' + data['heading'] + ' ' + END \n",
        "    \n",
        "    data = data.applymap(lambda x: str(x) if isinstance(x, int) or isinstance(x, float) else x)\n",
        "    data['heading'] = data['heading'].str.replace('\\d+', '')\n",
        "\n",
        "    data['body'] = data['body'].str.replace('\\d+', '')    \n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "data = format_data(data)\n",
        "data1 = data[4000:]\n",
        "\n",
        "data = data[:4000]\n",
        "target = data.pop('heading')\n",
        "data = data.pop('body')\n",
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values))\n",
        "len(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRSrT7Nrfpl5",
        "outputId": "c893a59c-7f07-459b-9bcf-d7dc195ba2c2"
      },
      "source": [
        "val_examples = dataset.take(1000)\n",
        "val_examples\n",
        "train_examples = dataset.skip(1000)\n",
        "train_examples "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SkipDataset shapes: ((), ()), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5AnEFdyRxY",
        "outputId": "c02cccb8-3dc5-427e-ac36-50274b5713b7"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(3).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    print(len(bd.decode('utf-8')))\n",
        "\n",
        "\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "327\n",
            "÷ న్యూఢిల్లీ, జనవరి : అమెరికా కొత్త అధ్యక్షుడుగా బాధ్యతలు చేపట్టిన డోనాల్డ్‌ ట్రంప్‌కు ప్రధాని మోదీ అభినందనలు తెలిపారు. శుక్రవారం రాత్రి ఆయన ట్వీట్‌ చేస్తూ, అమెరికాతో ద్వైపాక్షిక సంబంధాలు మరింత పటిష్ఠం కావాలని, సహకారం ఇంకా విస్తృతం కావాలని ఆకాంక్షించారు. ■\n",
            "256\n",
            "÷ న్యూఢిల్లీ, జూలై  (ఆంధ్రజ్యోతి): కేంద్ర పట్టణాభివృద్ధి శాఖమంత్రిగా రాజీనామ చేసిన ఎన్డీయే ఉప రాష్ట్రపతి అభ్యర్థి ఎం.వెంకయ్యనాయుడికు ఆ శాఖ ఉద్యోగులు సోమవారం ఘనంగా వీడ్కోలు పలికారు. వెంకయ్య మాట్లాడుతూ.. మూడేళ్లలో శాఖలో అందరితో అనుబంధం పెరిగిందని, అందరికీ అభినందనలు తెలిపారు. ■\n",
            "275\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్‌కు మోదీ అభినందనలు  ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEmDuhs0y4sK",
        "outputId": "fa6361d0-3410-4e39-9c5f-ad5976624f37"
      },
      "source": [
        "encoded = hd_tokenizer.tokenize(hd_examples)\n",
        "encoded = hd_tokenizer.string_to_id(encoded)\n",
        "\n",
        "for row in encoded.to_list():\n",
        "  print(row)\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 114, 94, 2064, 3412, 189, 288, 4, 9]\n",
            "[8, 305, 361, 54, 116, 5992, 4, 9]\n",
            "[8, 2629, 14, 1086, 31, 7291, 6, 326, 28, 4, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SvNtpapzNaT",
        "outputId": "67c9ea36-9ac7-4620-96a3-67cec64af4cd"
      },
      "source": [
        "round_trip = hd_tokenizer.detokenize(encoded)\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్ కు మోదీ అభినందనలు ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7u5Oua-5PNw"
      },
      "source": [
        "def tokenize_pairs(bd, hd):\n",
        "    bd = bd_tokenizer.tokenize(bd)\n",
        "    bd = bd_tokenizer.string_to_id(bd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    bd = tf.dtypes.cast(bd.to_tensor(),dtype=tf.int64)\n",
        "\n",
        "    hd = hd_tokenizer.tokenize(hd)\n",
        "    hd = hd_tokenizer.string_to_id(hd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    hd = tf.dtypes.cast(hd.to_tensor(),dtype=tf.int64)\n",
        "    return bd, hd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5to2UKMU5vmS"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRK87iSP52lQ"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i2iAtT54GR"
      },
      "source": [
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8R7m5BvIIUv",
        "outputId": "7d07c5ac-35e0-4176-9d27-c81719f61af5"
      },
      "source": [
        " for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "   print(inp)\n",
        "   print(tar)\n",
        "\n",
        "   break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[   8    4  608 ...    0    0    0]\n",
            " [   8  626   50 ...    0    0    0]\n",
            " [   8 4233   39 ...    0    0    0]\n",
            " ...\n",
            " [   8 1814   24 ...    0    0    0]\n",
            " [   8 1631  862 ...    0    0    0]\n",
            " [   8  241  449 ...    0    0    0]], shape=(64, 273), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   8   87  557 ...    0    0    0]\n",
            " [   8  207 2672 ...    0    0    0]\n",
            " [   8  305  361 ...    0    0    0]\n",
            " ...\n",
            " [   8   17 3606 ...    0    0    0]\n",
            " [   8 1631 1896 ...    0    0    0]\n",
            " [   8 4984   31 ...    0    0    0]], shape=(64, 24), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yNLTjK5_RU"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYuFQeC6KEE"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6JNulI_6LwJ"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAuKabZG6Oqp"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8Inwo16T0G"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print('Attention weights are:')\n",
        "  print(temp_attn)\n",
        "  print('Output is:')\n",
        "  print(temp_out)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IemyYhh6U2p"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxeYaMS6Yfz"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhZU_ZX6cNC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BybZGH6e56"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JAKvw26kaz"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_QxZ4F86m_j"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhnK1ldh6oHU"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1x5WqXz6tYz"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30T6ZjA6zTI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uULQomCC60px"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wTDJszGgBL"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giMDqhjdGidX"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpkBGsTHY_I"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYp4In7HbYk"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=bd_tokenizer.vocab_size(),\n",
        "    target_vocab_size=hd_tokenizer.vocab_size(),\n",
        "    pe_input=1000,\n",
        "    pe_target=100,\n",
        "    rate=dropout_rate)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlHUzTVH9s8"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdfpFpVICa1"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsqBRetsIFQG"
      },
      "source": [
        "EPOCHS = 60"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Y7APmcIGKi"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kou1RjYIOWg",
        "outputId": "ec0727e5-d3bb-4eab-cd9d-cd1d53f02fb8"
      },
      "source": [
        "import time\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.9893 Accuracy 0.0000\n",
            "Epoch 1 Loss 8.9285 Accuracy 0.0283\n",
            "Time taken for 1 epoch: 25.12 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.8383 Accuracy 0.0881\n",
            "Epoch 2 Loss 8.7380 Accuracy 0.0965\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 8.6419 Accuracy 0.0969\n",
            "Epoch 3 Loss 8.5369 Accuracy 0.0966\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 8.4282 Accuracy 0.0907\n",
            "Epoch 4 Loss 8.2594 Accuracy 0.0968\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 8.0903 Accuracy 0.1012\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 7.9120 Accuracy 0.0967\n",
            "Time taken for 1 epoch: 10.97 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 7.7433 Accuracy 0.0930\n",
            "Epoch 6 Loss 7.5162 Accuracy 0.1352\n",
            "Time taken for 1 epoch: 10.33 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 7.3249 Accuracy 0.1739\n",
            "Epoch 7 Loss 7.1207 Accuracy 0.1788\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 6.9555 Accuracy 0.1740\n",
            "Epoch 8 Loss 6.7913 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 6.5520 Accuracy 0.1992\n",
            "Epoch 9 Loss 6.5367 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 6.4085 Accuracy 0.1884\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 6.3547 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 10.72 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 6.3133 Accuracy 0.1873\n",
            "Epoch 11 Loss 6.2088 Accuracy 0.1816\n",
            "Time taken for 1 epoch: 10.48 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 6.1217 Accuracy 0.1727\n",
            "Epoch 12 Loss 6.0759 Accuracy 0.1870\n",
            "Time taken for 1 epoch: 10.58 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.8818 Accuracy 0.1923\n",
            "Epoch 13 Loss 5.9472 Accuracy 0.1939\n",
            "Time taken for 1 epoch: 10.65 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 5.8699 Accuracy 0.1992\n",
            "Epoch 14 Loss 5.8223 Accuracy 0.2020\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 5.6926 Accuracy 0.2060\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 5.6954 Accuracy 0.2122\n",
            "Time taken for 1 epoch: 10.79 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 5.5413 Accuracy 0.2218\n",
            "Epoch 16 Loss 5.5741 Accuracy 0.2199\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 5.5210 Accuracy 0.2145\n",
            "Epoch 17 Loss 5.4482 Accuracy 0.2278\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 5.4324 Accuracy 0.2386\n",
            "Epoch 18 Loss 5.3276 Accuracy 0.2346\n",
            "Time taken for 1 epoch: 10.70 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 5.2414 Accuracy 0.2523\n",
            "Epoch 19 Loss 5.2111 Accuracy 0.2420\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 5.1143 Accuracy 0.2474\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 5.0923 Accuracy 0.2498\n",
            "Time taken for 1 epoch: 10.73 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 4.9390 Accuracy 0.2602\n",
            "Epoch 21 Loss 4.9767 Accuracy 0.2587\n",
            "Time taken for 1 epoch: 10.57 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 4.8986 Accuracy 0.2669\n",
            "Epoch 22 Loss 4.8480 Accuracy 0.2685\n",
            "Time taken for 1 epoch: 10.54 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 4.7609 Accuracy 0.2770\n",
            "Epoch 23 Loss 4.7175 Accuracy 0.2812\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 4.5658 Accuracy 0.2958\n",
            "Epoch 24 Loss 4.5892 Accuracy 0.2912\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 4.4979 Accuracy 0.2910\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 4.4650 Accuracy 0.3010\n",
            "Time taken for 1 epoch: 10.92 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 4.3941 Accuracy 0.3127\n",
            "Epoch 26 Loss 4.3278 Accuracy 0.3132\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 4.0732 Accuracy 0.3469\n",
            "Epoch 27 Loss 4.1925 Accuracy 0.3258\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 4.0879 Accuracy 0.3293\n",
            "Epoch 28 Loss 4.0626 Accuracy 0.3376\n",
            "Time taken for 1 epoch: 10.36 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 3.9496 Accuracy 0.3418\n",
            "Epoch 29 Loss 3.9179 Accuracy 0.3512\n",
            "Time taken for 1 epoch: 10.46 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 3.6925 Accuracy 0.3902\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
            "Epoch 30 Loss 3.7824 Accuracy 0.3659\n",
            "Time taken for 1 epoch: 10.77 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 3.7350 Accuracy 0.3585\n",
            "Epoch 31 Loss 3.6557 Accuracy 0.3773\n",
            "Time taken for 1 epoch: 10.63 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 3.5859 Accuracy 0.3892\n",
            "Epoch 32 Loss 3.5079 Accuracy 0.3906\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 3.4197 Accuracy 0.3949\n",
            "Epoch 33 Loss 3.3564 Accuracy 0.4079\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 3.2539 Accuracy 0.4284\n",
            "Epoch 34 Loss 3.2212 Accuracy 0.4223\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 3.1961 Accuracy 0.4407\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-7\n",
            "Epoch 35 Loss 3.0676 Accuracy 0.4409\n",
            "Time taken for 1 epoch: 10.71 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.9529 Accuracy 0.4726\n",
            "Epoch 36 Loss 2.9192 Accuracy 0.4600\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.5930 Accuracy 0.5179\n",
            "Epoch 37 Loss 2.7761 Accuracy 0.4812\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.6745 Accuracy 0.4831\n",
            "Epoch 38 Loss 2.6334 Accuracy 0.4994\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.4713 Accuracy 0.5176\n",
            "Epoch 39 Loss 2.4752 Accuracy 0.5225\n",
            "Time taken for 1 epoch: 10.62 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.3462 Accuracy 0.5453\n",
            "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-8\n",
            "Epoch 40 Loss 2.3152 Accuracy 0.5503\n",
            "Time taken for 1 epoch: 10.77 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 2.2100 Accuracy 0.5654\n",
            "Epoch 41 Loss 2.1660 Accuracy 0.5774\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 1.9722 Accuracy 0.6231\n",
            "Epoch 42 Loss 2.0249 Accuracy 0.5996\n",
            "Time taken for 1 epoch: 10.47 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 1.8331 Accuracy 0.6495\n",
            "Epoch 43 Loss 1.8676 Accuracy 0.6300\n",
            "Time taken for 1 epoch: 10.49 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 1.6479 Accuracy 0.6579\n",
            "Epoch 44 Loss 1.7348 Accuracy 0.6565\n",
            "Time taken for 1 epoch: 10.56 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.5777 Accuracy 0.6733\n",
            "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-9\n",
            "Epoch 45 Loss 1.5760 Accuracy 0.6840\n",
            "Time taken for 1 epoch: 10.68 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 1.4317 Accuracy 0.7057\n",
            "Epoch 46 Loss 1.4246 Accuracy 0.7167\n",
            "Time taken for 1 epoch: 10.35 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 1.2887 Accuracy 0.7610\n",
            "Epoch 47 Loss 1.3036 Accuracy 0.7446\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 1.1288 Accuracy 0.7901\n",
            "Epoch 48 Loss 1.1802 Accuracy 0.7647\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 1.0141 Accuracy 0.8074\n",
            "Epoch 49 Loss 1.0469 Accuracy 0.7957\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.8919 Accuracy 0.8234\n",
            "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-10\n",
            "Epoch 50 Loss 0.9253 Accuracy 0.8212\n",
            "Time taken for 1 epoch: 10.89 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.8200 Accuracy 0.8369\n",
            "Epoch 51 Loss 0.8271 Accuracy 0.8377\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.7074 Accuracy 0.8634\n",
            "Epoch 52 Loss 0.7253 Accuracy 0.8586\n",
            "Time taken for 1 epoch: 10.44 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.5678 Accuracy 0.9033\n",
            "Epoch 53 Loss 0.6468 Accuracy 0.8742\n",
            "Time taken for 1 epoch: 10.45 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.4657 Accuracy 0.9155\n",
            "Epoch 54 Loss 0.5878 Accuracy 0.8816\n",
            "Time taken for 1 epoch: 10.53 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.4547 Accuracy 0.9009\n",
            "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-11\n",
            "Epoch 55 Loss 0.5213 Accuracy 0.8937\n",
            "Time taken for 1 epoch: 10.86 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.3834 Accuracy 0.9384\n",
            "Epoch 56 Loss 0.4725 Accuracy 0.9034\n",
            "Time taken for 1 epoch: 10.51 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.3795 Accuracy 0.9239\n",
            "Epoch 57 Loss 0.4156 Accuracy 0.9148\n",
            "Time taken for 1 epoch: 10.50 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.3934 Accuracy 0.9093\n",
            "Epoch 58 Loss 0.3865 Accuracy 0.9187\n",
            "Time taken for 1 epoch: 10.59 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.3323 Accuracy 0.9333\n",
            "Epoch 59 Loss 0.3518 Accuracy 0.9250\n",
            "Time taken for 1 epoch: 10.55 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.2941 Accuracy 0.9404\n",
            "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-12\n",
            "Epoch 60 Loss 0.3228 Accuracy 0.9303\n",
            "Time taken for 1 epoch: 10.79 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2yUqMbpSzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bd336f-ea54-4c92-a636-258425653783"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(1).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKkxxrUFr3A2"
      },
      "source": [
        "# sentence = tf.convert_to_tensor([sentence])\n",
        "# sentence = bd_tokenizer.tokenize(sentence)\n",
        "# sentence = bd_tokenizer.string_to_id(sentence)\n",
        "# sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "# encoder_input = sentence"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVJ-W4j_r915"
      },
      "source": [
        "# start  = tf.convert_to_tensor('÷')\n",
        "# start= hd_tokenizer.tokenize(start)\n",
        "# output= hd_tokenizer.string_to_id(start)\n",
        "# end  = tf.convert_to_tensor('■')\n",
        "# end= hd_tokenizer.tokenize(end)\n",
        "# end= hd_tokenizer.string_to_id(end)[1]\n",
        "\n",
        "# output = tf.expand_dims(output, 0)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBtarAoTsE2e"
      },
      "source": [
        "\n",
        "# for i in range(40):\n",
        "#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "#           encoder_input, output)\n",
        "#     predictions, attention_weights = transformer(encoder_input,\n",
        "#                                                 output,\n",
        "#                                                 False,\n",
        "#                                                 enc_padding_mask,\n",
        "#                                                 combined_mask,\n",
        "#                                                 dec_padding_mask)\n",
        "\n",
        "#     # select the last word from the seq_len dimension\n",
        "#     predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "#     predicted_id = tf.argmax(predictions, axis=-1)\n",
        "#     predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "#     # concatentate the predicted_id to the output which is given to the decoder\n",
        "#     # as its input.\n",
        "#     output = tf.concat([output, predicted_id], axis=-1)\n",
        "# print(predicted_id)\n",
        "# #     # return the result if the predicted_id is equal to the end token\n",
        "# print(predictions)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQErqf_09DZ4"
      },
      "source": [
        "# text = hd_tokenizer.detokenize(output)\n",
        "# for x in text.numpy():\n",
        "#   print(x.decode('utf-8'))\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_AL9W9qq12"
      },
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxP2RGlqw0B"
      },
      "source": [
        "# print_translation(sentence,text, ground_truth)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIoL8wYncpc"
      },
      "source": [
        "def evaluate(sentence, max_length=40):\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  sentence = tf.convert_to_tensor([sentence])\n",
        "  sentence = bd_tokenizer.tokenize(sentence)\n",
        "  sentence = bd_tokenizer.string_to_id(sentence)\n",
        "  sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "  encoder_input = sentence\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  start  = tf.convert_to_tensor('÷')\n",
        "  start= hd_tokenizer.tokenize(start)\n",
        "  output= hd_tokenizer.string_to_id(start)\n",
        "  end  = tf.convert_to_tensor('■')\n",
        "  end= hd_tokenizer.tokenize(end)\n",
        "  end= hd_tokenizer.string_to_id(end)[1]\n",
        "  end = tf.expand_dims(end, 0)\n",
        "  output = tf.expand_dims(output, 0)\n",
        "  for i in range(max_length):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions, axis=-1)\n",
        "    predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == end:\n",
        "      break\n",
        "\n",
        "  # output.shape (1, tokens)\n",
        "  trans = hd_tokenizer.detokenize(output)# shape: ()\n",
        "  text = []\n",
        "  for x in trans.numpy():\n",
        "    text.append(x.decode('utf-8'))\n",
        "\n",
        "  return text, attention_weights"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTkU2cv8rUIP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NyvAr-bX1Q0",
        "outputId": "d3de569c-1ce3-4431-b925-80cbc3b3c18a"
      },
      "source": [
        "for x in translated_text.numpy():\n",
        "  print(x.decode('utf-8'))\n",
        "  "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ త్రివిక్రమ్ కు మ్ సోల్టే సినిమా ఇదే చర్చ ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13JVpiD_ZPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d15bdd2-2ec7-4dd8-a778-e06fccaf2433"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "Prediction     : ['÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■']\n",
            "Ground truth   : ÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIVJYOk3ecaw",
        "outputId": "bf25a8c3-d6c2-4da5-aee4-30ef038b5f07"
      },
      "source": [
        "target1 = data1.pop('heading')\n",
        "data1 = data1.pop('body')\n",
        "import tensorflow as tf\n",
        "test = tf.data.Dataset.from_tensor_slices((data1.values, target1.values))\n",
        "len(test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf64hwjefvE",
        "outputId": "6698bc91-5038-442d-9af3-5b444bbf9736"
      },
      "source": [
        "for bd_examples, hd_examples in test.batch(1).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgqqMTR9ehrP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj6k4JYheo4G",
        "outputId": "da53abab-e3d6-456e-baff-4c6040d4442f"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "Prediction     : ['÷ రేపటిరీ మరో యాంకర్ల ఆహ్వానం ■']\n",
            "Ground truth   : ÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}