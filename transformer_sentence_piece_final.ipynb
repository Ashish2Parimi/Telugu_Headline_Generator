{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish2Parimi/Telugu_Headline_Generator/blob/main/transformer_sentence_piece_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lrkhV34tstz"
      },
      "source": [
        "# !pip install tensorflow_text\n",
        "# !pip install sentencepiece\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PqoYuxqvMmy"
      },
      "source": [
        "# import sentencepiece as spm\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=body --vocab_size=8000')\n",
        "# spm.SentencePieceTrainer.train('--input=body.txt --model_prefix=heading --vocab_size=2000')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuN0Do6PvMq5"
      },
      "source": [
        "import requests\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "url = 'https://github.com/Ashish2Parimi/Telugu_Headline_Generator/raw/main/data.model'\n",
        "bd_model = requests.get(url).content"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGpvHdPt1wx"
      },
      "source": [
        "bd_tokenizer = text.SentencepieceTokenizer(bd_model, out_type=tf.string)\n",
        "hd_tokenizer = bd_tokenizer\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8dORzk1W5M",
        "outputId": "6b035572-7ee6-44b1-b2f2-1c88dff8bafc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# data = data.drop(['SNo','date','topic'],axis = 1)\n",
        "data.dropna(axis = 0,inplace = True)\n",
        "\n",
        "# data = data.applymap(lambda x:x.encode(encoding='UTF-8'))\n",
        "for i,b in enumerate(data['body'].values):\n",
        "    if len(b)>1000:\n",
        "        data.drop(i, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def format_data(data):\n",
        "    START = '÷'\n",
        "    END = '■'  \n",
        "       \n",
        "    data['body'] = START + ' ' + data['body'] + ' ' + END \n",
        "    data['heading'] = START + ' ' + data['heading'] + ' ' + END \n",
        "    \n",
        "    data = data.applymap(lambda x: str(x) if isinstance(x, int) or isinstance(x, float) else x)\n",
        "    data['heading'] = data['heading'].str.replace('\\d+', '')\n",
        "\n",
        "    data['body'] = data['body'].str.replace('\\d+', '')    \n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "data = format_data(data)\n",
        "data1 = data[4000:]\n",
        "\n",
        "data = data[:4000]\n",
        "target = data.pop('heading')\n",
        "data = data.pop('body')\n",
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data.values, target.values))\n",
        "len(dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRSrT7Nrfpl5",
        "outputId": "2461677b-8ae9-4e20-a013-a49fa92eac21"
      },
      "source": [
        "val_examples = dataset.take(1000)\n",
        "val_examples\n",
        "train_examples = dataset.skip(1000)\n",
        "train_examples "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SkipDataset shapes: ((), ()), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm5AnEFdyRxY",
        "outputId": "bfe4f84f-d3f7-40a0-8c67-1b78ed40a814"
      },
      "source": [
        "for bd_examples, hd_examples in train_examples.batch(3).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    print(len(bd.decode('utf-8')))\n",
        "\n",
        "\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న్యూఢిల్లీ, మే : ఏడవ వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలను పెంచాలన్న డిమాండ్‌తో ఈ నెల న తలపెట్టిన ఒక రోజు సమ్మెను కేంద్ర ప్రభుత్వ ఉద్యోగ సంఘాలు వాయిదా వేశాయి. వేతన సంఘం సిఫారసు చేసిన మేరకు భత్యాలు పెంచేందుకు ప్రభుత్వం హామీ ఇచ్చిందని, ఈ నేపథ్యంలో సమ్మెను వాయిదా వేశామని కేంద్ర ప్రభుత్వ ఉద్యోగుల సమాఖ్య ఓ ప్రకటనలో తెలిపింది. ■\n",
            "327\n",
            "÷ న్యూఢిల్లీ, జనవరి : అమెరికా కొత్త అధ్యక్షుడుగా బాధ్యతలు చేపట్టిన డోనాల్డ్‌ ట్రంప్‌కు ప్రధాని మోదీ అభినందనలు తెలిపారు. శుక్రవారం రాత్రి ఆయన ట్వీట్‌ చేస్తూ, అమెరికాతో ద్వైపాక్షిక సంబంధాలు మరింత పటిష్ఠం కావాలని, సహకారం ఇంకా విస్తృతం కావాలని ఆకాంక్షించారు. ■\n",
            "256\n",
            "÷ న్యూఢిల్లీ, జూలై  (ఆంధ్రజ్యోతి): కేంద్ర పట్టణాభివృద్ధి శాఖమంత్రిగా రాజీనామ చేసిన ఎన్డీయే ఉప రాష్ట్రపతి అభ్యర్థి ఎం.వెంకయ్యనాయుడికు ఆ శాఖ ఉద్యోగులు సోమవారం ఘనంగా వీడ్కోలు పలికారు. వెంకయ్య మాట్లాడుతూ.. మూడేళ్లలో శాఖలో అందరితో అనుబంధం పెరిగిందని, అందరికీ అభినందనలు తెలిపారు. ■\n",
            "275\n",
            "\n",
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్‌కు మోదీ అభినందనలు  ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEmDuhs0y4sK",
        "outputId": "f5490482-d1c1-43bf-a95b-2ce7f2c1afac"
      },
      "source": [
        "encoded = hd_tokenizer.tokenize(hd_examples)\n",
        "encoded = hd_tokenizer.string_to_id(encoded)\n",
        "\n",
        "for row in encoded.to_list():\n",
        "  print(row)\n",
        "  \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 114, 94, 2064, 3412, 189, 288, 4, 9]\n",
            "[8, 305, 361, 54, 116, 5992, 4, 9]\n",
            "[8, 2629, 14, 1086, 31, 7291, 6, 326, 28, 4, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SvNtpapzNaT",
        "outputId": "050ab8c8-1faa-450c-e667-5a2e66c9620e"
      },
      "source": [
        "round_trip = hd_tokenizer.detokenize(encoded)\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ న కేంద్ర ఉద్యోగుల సమ్మె లేదు ■\n",
            "÷ ట్రంప్ కు మోదీ అభినందనలు ■\n",
            "÷ వెంకయ్యకు ఘనంగా వీడ్కోలు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7u5Oua-5PNw"
      },
      "source": [
        "def tokenize_pairs(bd, hd):\n",
        "    bd = bd_tokenizer.tokenize(bd)\n",
        "    bd = bd_tokenizer.string_to_id(bd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    bd = tf.dtypes.cast(bd.to_tensor(),dtype=tf.int64)\n",
        "\n",
        "    hd = hd_tokenizer.tokenize(hd)\n",
        "    hd = hd_tokenizer.string_to_id(hd)\n",
        "\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    hd = tf.dtypes.cast(hd.to_tensor(),dtype=tf.int64)\n",
        "    return bd, hd"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5to2UKMU5vmS"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRK87iSP52lQ"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i2iAtT54GR"
      },
      "source": [
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8R7m5BvIIUv",
        "outputId": "65cdf110-adf2-4b35-81ef-7f5e376f0597"
      },
      "source": [
        " for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "   print(inp)\n",
        "   print(tar)\n",
        "\n",
        "   break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  8 117 114 ...   0   0   0]\n",
            " [  8  75  50 ...   0   0   0]\n",
            " [  8 291 318 ...   0   0   0]\n",
            " ...\n",
            " [  8 616 387 ...   0   0   0]\n",
            " [  8 143 486 ...   0   0   0]\n",
            " [  8 339  39 ...   0   0   0]], shape=(64, 256), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   8  117  114 ...    0    0    0]\n",
            " [   8 2720 1769 ...   41    4    9]\n",
            " [   8  251 6403 ...    0    0    0]\n",
            " ...\n",
            " [   8 2085   14 ...    0    0    0]\n",
            " [   8   82  128 ...    0    0    0]\n",
            " [   8  496 1327 ...    0    0    0]], shape=(64, 23), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yNLTjK5_RU"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYuFQeC6KEE"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6JNulI_6LwJ"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAuKabZG6Oqp"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8Inwo16T0G"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print('Attention weights are:')\n",
        "  print(temp_attn)\n",
        "  print('Output is:')\n",
        "  print(temp_out)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IemyYhh6U2p"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlxeYaMS6Yfz"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhZU_ZX6cNC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BybZGH6e56"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JAKvw26kaz"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_QxZ4F86m_j"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhnK1ldh6oHU"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1x5WqXz6tYz"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30T6ZjA6zTI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uULQomCC60px"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wTDJszGgBL"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giMDqhjdGidX"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpkBGsTHY_I"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYp4In7HbYk"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=bd_tokenizer.vocab_size(),\n",
        "    target_vocab_size=hd_tokenizer.vocab_size(),\n",
        "    pe_input=1000,\n",
        "    pe_target=100,\n",
        "    rate=dropout_rate)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlHUzTVH9s8"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdfpFpVICa1"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsqBRetsIFQG"
      },
      "source": [
        "EPOCHS = 60"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Y7APmcIGKi"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kou1RjYIOWg",
        "outputId": "ec93fe3c-cc32-44ff-bcdd-8eddf839bc79"
      },
      "source": [
        "import time\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 9.0017 Accuracy 0.0000\n",
            "Epoch 1 Loss 8.9329 Accuracy 0.0174\n",
            "Time taken for 1 epoch: 22.53 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.8011 Accuracy 0.0930\n",
            "Epoch 2 Loss 8.7011 Accuracy 0.0906\n",
            "Time taken for 1 epoch: 8.14 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 8.5868 Accuracy 0.1064\n",
            "Epoch 3 Loss 8.4878 Accuracy 0.0990\n",
            "Time taken for 1 epoch: 8.15 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 8.3577 Accuracy 0.0930\n",
            "Epoch 4 Loss 8.2111 Accuracy 0.0974\n",
            "Time taken for 1 epoch: 8.17 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 8.0452 Accuracy 0.0964\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 7.8630 Accuracy 0.1039\n",
            "Time taken for 1 epoch: 8.46 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 7.6475 Accuracy 0.1487\n",
            "Epoch 6 Loss 7.4617 Accuracy 0.1726\n",
            "Time taken for 1 epoch: 8.05 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 7.3004 Accuracy 0.1667\n",
            "Epoch 7 Loss 7.0723 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 8.18 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 6.9477 Accuracy 0.1697\n",
            "Epoch 8 Loss 6.7477 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 8.07 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 6.5522 Accuracy 0.1896\n",
            "Epoch 9 Loss 6.5045 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 8.05 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 6.3470 Accuracy 0.1746\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 6.3312 Accuracy 0.1790\n",
            "Time taken for 1 epoch: 8.40 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 6.2936 Accuracy 0.1863\n",
            "Epoch 11 Loss 6.1940 Accuracy 0.1791\n",
            "Time taken for 1 epoch: 8.15 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 6.1580 Accuracy 0.1864\n",
            "Epoch 12 Loss 6.0644 Accuracy 0.1822\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 5.9598 Accuracy 0.1838\n",
            "Epoch 13 Loss 5.9357 Accuracy 0.1908\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 5.8391 Accuracy 0.1954\n",
            "Epoch 14 Loss 5.8107 Accuracy 0.1990\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 5.6741 Accuracy 0.2132\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
            "Epoch 15 Loss 5.6856 Accuracy 0.2084\n",
            "Time taken for 1 epoch: 8.36 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 5.6410 Accuracy 0.2072\n",
            "Epoch 16 Loss 5.5630 Accuracy 0.2170\n",
            "Time taken for 1 epoch: 8.12 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 5.5213 Accuracy 0.2179\n",
            "Epoch 17 Loss 5.4444 Accuracy 0.2235\n",
            "Time taken for 1 epoch: 8.11 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 5.3446 Accuracy 0.2371\n",
            "Epoch 18 Loss 5.3272 Accuracy 0.2321\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 5.2361 Accuracy 0.2414\n",
            "Epoch 19 Loss 5.2159 Accuracy 0.2392\n",
            "Time taken for 1 epoch: 8.20 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 5.0669 Accuracy 0.2627\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
            "Epoch 20 Loss 5.0971 Accuracy 0.2500\n",
            "Time taken for 1 epoch: 8.32 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 4.9907 Accuracy 0.2557\n",
            "Epoch 21 Loss 4.9816 Accuracy 0.2580\n",
            "Time taken for 1 epoch: 8.16 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 4.8706 Accuracy 0.2836\n",
            "Epoch 22 Loss 4.8678 Accuracy 0.2655\n",
            "Time taken for 1 epoch: 8.18 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 4.8087 Accuracy 0.2664\n",
            "Epoch 23 Loss 4.7417 Accuracy 0.2760\n",
            "Time taken for 1 epoch: 8.07 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 4.6473 Accuracy 0.2762\n",
            "Epoch 24 Loss 4.6162 Accuracy 0.2870\n",
            "Time taken for 1 epoch: 8.07 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 4.4818 Accuracy 0.2852\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
            "Epoch 25 Loss 4.4897 Accuracy 0.2979\n",
            "Time taken for 1 epoch: 8.37 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 4.3480 Accuracy 0.3113\n",
            "Epoch 26 Loss 4.3629 Accuracy 0.3082\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 4.3311 Accuracy 0.3182\n",
            "Epoch 27 Loss 4.2299 Accuracy 0.3191\n",
            "Time taken for 1 epoch: 8.05 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 4.0339 Accuracy 0.3247\n",
            "Epoch 28 Loss 4.0947 Accuracy 0.3323\n",
            "Time taken for 1 epoch: 8.07 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 3.8811 Accuracy 0.3509\n",
            "Epoch 29 Loss 3.9578 Accuracy 0.3447\n",
            "Time taken for 1 epoch: 7.92 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 3.7238 Accuracy 0.3635\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
            "Epoch 30 Loss 3.8324 Accuracy 0.3578\n",
            "Time taken for 1 epoch: 8.31 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 3.7285 Accuracy 0.3641\n",
            "Epoch 31 Loss 3.6845 Accuracy 0.3722\n",
            "Time taken for 1 epoch: 8.17 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 3.5501 Accuracy 0.3854\n",
            "Epoch 32 Loss 3.5422 Accuracy 0.3845\n",
            "Time taken for 1 epoch: 8.19 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 3.4753 Accuracy 0.3871\n",
            "Epoch 33 Loss 3.4043 Accuracy 0.4018\n",
            "Time taken for 1 epoch: 8.05 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 3.1518 Accuracy 0.4219\n",
            "Epoch 34 Loss 3.2551 Accuracy 0.4190\n",
            "Time taken for 1 epoch: 8.12 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 3.0967 Accuracy 0.4443\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-7\n",
            "Epoch 35 Loss 3.1096 Accuracy 0.4350\n",
            "Time taken for 1 epoch: 8.49 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.9007 Accuracy 0.4658\n",
            "Epoch 36 Loss 2.9593 Accuracy 0.4558\n",
            "Time taken for 1 epoch: 8.04 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.7610 Accuracy 0.4927\n",
            "Epoch 37 Loss 2.8078 Accuracy 0.4751\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.6589 Accuracy 0.4800\n",
            "Epoch 38 Loss 2.6625 Accuracy 0.4953\n",
            "Time taken for 1 epoch: 8.14 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.4530 Accuracy 0.5191\n",
            "Epoch 39 Loss 2.5035 Accuracy 0.5211\n",
            "Time taken for 1 epoch: 8.14 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.3675 Accuracy 0.5491\n",
            "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-8\n",
            "Epoch 40 Loss 2.3420 Accuracy 0.5472\n",
            "Time taken for 1 epoch: 8.39 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 2.2326 Accuracy 0.5692\n",
            "Epoch 41 Loss 2.1927 Accuracy 0.5744\n",
            "Time taken for 1 epoch: 8.18 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 2.1221 Accuracy 0.5854\n",
            "Epoch 42 Loss 2.0388 Accuracy 0.5993\n",
            "Time taken for 1 epoch: 8.16 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 1.8511 Accuracy 0.6242\n",
            "Epoch 43 Loss 1.8905 Accuracy 0.6272\n",
            "Time taken for 1 epoch: 8.07 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 1.7629 Accuracy 0.6563\n",
            "Epoch 44 Loss 1.7380 Accuracy 0.6567\n",
            "Time taken for 1 epoch: 8.14 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.4958 Accuracy 0.6954\n",
            "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-9\n",
            "Epoch 45 Loss 1.5957 Accuracy 0.6849\n",
            "Time taken for 1 epoch: 8.35 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 1.3995 Accuracy 0.7315\n",
            "Epoch 46 Loss 1.4448 Accuracy 0.7147\n",
            "Time taken for 1 epoch: 8.17 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 1.2932 Accuracy 0.7716\n",
            "Epoch 47 Loss 1.3118 Accuracy 0.7393\n",
            "Time taken for 1 epoch: 8.01 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 1.1704 Accuracy 0.7699\n",
            "Epoch 48 Loss 1.1855 Accuracy 0.7655\n",
            "Time taken for 1 epoch: 8.13 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 1.0294 Accuracy 0.8123\n",
            "Epoch 49 Loss 1.0674 Accuracy 0.7862\n",
            "Time taken for 1 epoch: 8.09 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.8319 Accuracy 0.8588\n",
            "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-10\n",
            "Epoch 50 Loss 0.9439 Accuracy 0.8164\n",
            "Time taken for 1 epoch: 8.34 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.7686 Accuracy 0.8536\n",
            "Epoch 51 Loss 0.8189 Accuracy 0.8418\n",
            "Time taken for 1 epoch: 8.09 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.7209 Accuracy 0.8615\n",
            "Epoch 52 Loss 0.7408 Accuracy 0.8562\n",
            "Time taken for 1 epoch: 8.19 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.5503 Accuracy 0.9058\n",
            "Epoch 53 Loss 0.6589 Accuracy 0.8717\n",
            "Time taken for 1 epoch: 8.11 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.5237 Accuracy 0.8969\n",
            "Epoch 54 Loss 0.5851 Accuracy 0.8846\n",
            "Time taken for 1 epoch: 8.16 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.4391 Accuracy 0.9156\n",
            "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-11\n",
            "Epoch 55 Loss 0.5064 Accuracy 0.8985\n",
            "Time taken for 1 epoch: 8.42 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.4545 Accuracy 0.9049\n",
            "Epoch 56 Loss 0.4676 Accuracy 0.9044\n",
            "Time taken for 1 epoch: 8.18 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.3891 Accuracy 0.9267\n",
            "Epoch 57 Loss 0.4285 Accuracy 0.9136\n",
            "Time taken for 1 epoch: 8.18 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.3782 Accuracy 0.9186\n",
            "Epoch 58 Loss 0.3866 Accuracy 0.9199\n",
            "Time taken for 1 epoch: 8.10 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.3064 Accuracy 0.9310\n",
            "Epoch 59 Loss 0.3608 Accuracy 0.9223\n",
            "Time taken for 1 epoch: 8.04 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.2872 Accuracy 0.9328\n",
            "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-12\n",
            "Epoch 60 Loss 0.3204 Accuracy 0.9295\n",
            "Time taken for 1 epoch: 8.36 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olPMkpdbjrVt"
      },
      "source": [
        "target = data1.pop('heading')\n",
        "data = data1.pop('body')\n",
        "test = tf.data.Dataset.from_tensor_slices((data.values, target.values))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2yUqMbpSzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551b6e19-1216-4626-9046-c980d9c70fa7"
      },
      "source": [
        "for bd_examples, hd_examples in test.batch(20).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "÷ హైదరాబాద్: డ్రగ్స్, మందు అని మనం మాత్రమే అనుకుంటామని.... అర్జున్ రెడ్డి సినిమా చూసిన ప్రేక్షకుల మాత్రం చాలా బాగుందని హీరో విజయ్ దేవరకొండ అన్నారు. అర్జున్ రెడ్డి సినిమా వివాదంపై ఏబీఎన్ ఆంధ్రజ్యోతి లైవ్ షో నిర్వహించింది. ఈ కార్యక్రమంలో కాంగ్రెస్ ఎంపీ వీహెచ్‌తో పాటు  అర్జున్ రెడ్డి హీరో, దర్శకుడు పాల్గొన్నారు. సినిమా చూడని వాళ్లు మాత్రమే నిరసనలు  చేస్తున్నారని విజయ్ తెలిపారు. అర్జున్ రెడ్డి సినిమాలో చాలా సిగరెట్లు తాగానని.. బయట మాత్రం అలాంటి పనులు చేయనని చెప్పారు. చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదని అన్నారు. చాలా ప్రేమతో ఎంపీ వీహెచ్‌ను తాతయ్య అని అన్నానని..వాళ్ల మనవళ్లతో తిరుగుతాను కాబట్టే అలా అన్నానని విజయ్ తెలిపారు.తాతాయ్య అనడంలో బ్యాడ్ ఇన్ టెన్షన్ ఏమీ లేదని స్పష్టం చేశారు. ■\n",
            "÷ న్యూఢిల్లీ: షేన్‌ వార్న్‌ తన ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ జట్టుకు ధోనీని సారథిని చేసి గౌరవించాడు. ఈ మేరకు తన కలల ఐపీఎల్‌ జట్టును వార్న్‌ ప్రకటించాడు. విరాట్‌ కోహ్లీ, రోహిత శర్మ, యువరాజ్‌ సింగ్‌, రవీంద్ర జడేజా, హర్భజన్‌ సింగ్‌, ఉమేష్‌ యాదవ్‌లకు తన జట్టులో చోటు కల్పించాడు. విదేశీ ఆటగాళ్లుగా క్రిస్‌ గేల్‌, బ్రెండన్‌ మెకల్లమ్‌, జాక్‌ కలిస్‌, లసిత మలింగలను తీసుకున్నాడు. అలాగే విదేశీ కోటాలో ఒక్క ఆస్ర్టేలియా ఆటగాడిని కూడా వార్న్‌ తన జట్టులో చోటు కల్పించకపోవడం విశేషం. ■\n",
            "÷ తన ప్రతిష్టాత్మక వందో చిత్రమైన చారిత్రక సినిమా ‘గౌతమిపుత్ర శాతకర్ణి’ తెలుగు ప్రేక్షకులను మెప్పించడంతో బాలయ్య హర్షం వ్యక్తం చేస్తున్నారు. ఈ సందర్భంగా ‘ఏబీఎన్’తో ముచ్చటించిన బాలయ్య.. తన మనవడు దేవాన్ష్ గురించి ఆసక్తికర విషయాలను తెలియజేశారు. తన మనవడు దేవాన్ష్‌ గుర్రమంటే భయపడేవాడని, ఇప్పుడు తన సినిమా ‘శాతకర్ణి’ చూశాక ఆ భయం పోయి.. వాళ్ల అమ్మ కొనిచ్చిన గుర్రం బొమ్మపై ఎక్కి దాన్ని తోలుతున్నట్లు ఫీలయి సంతోషపడుతున్నాడని బాలయ్య చెప్పారు. తామిద్దరం తోడుదొంగలమేనంటూ దేవాన్ష్ గురించి బాలయ్య చెప్పిన మరిన్ని ఆసక్తికర విశేషాలు పై వీడియోలో చూడండి. ■\n",
            "÷ న్యూఢిల్లీ: విదేశీ బ్యాంకుల్లో తన పేర ఉన్న ఖాతాలను మూసివేస్తున్నందునే కేంద్ర మాజీ మంత్రి పి.చిదంబరం తనయుడు కార్తి దేశం విడిచి వెళ్లకుండా లుకవుట్‌ నోటీసు జారీ చేశామని సీబీఐ సుప్రీం కోర్టుకు తెలిపింది. దర్యాప్తునకు సంబంధించిన పత్రాలను సీల్డ్‌ కవర్‌లో న్యాయస్థానానికి సమర్పిస్తామని సీబీఐ కోరింది. ఈ సందర్భంగా అడిషనల్‌ సొలిసిటర్‌ జనరల్‌ (ఏఎ్‌సజీ) తుషార్‌ మెహతా తన వాదన వినిపిస్తూ విదేశాల్లో తనకు ఒక్కటే బ్యాంకు ఖాతా ఉందని విచారణలో చెప్పిన కార్తి... విదేశాలకు వెళ్లినప్పుడు పలు ఖాతాలను మూసివేశాడని తెలిపారు. ■\n",
            "÷ హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): తెలంగాణ రియల్‌ ఎస్టేట్‌ డెవలపర్స్‌ అసోసియేషన్‌ (ట్రెడా) కొత్త అధ్యక్షుడిగా పి రవీందర్‌ రావు ఎన్నికయ్యారు. శనివారం నాడిక్కడ జరిగిన వ వార్షిక సర్వసభ్య సమావేశంలో ఈ మేరకు కొత్త కార్యవర్గాన్ని ఎన్నుకున్నారు. ఎగ్జిక్యూటివ్‌ ఉపాధ్యక్షులుగా ఆర్‌ చలపతి రావు, విజయ్‌ సాయి, కార్యదర్శిగా సునీల్‌ చంద్రా రెడ్డి, కోశాధికారిగా కె శ్రీధర్‌ రెడ్డి ఎన్నికయ్యారు. రెండేళ్ల పాటు వీరు ఈ పదవిలో కొనసాగనున్నారు. ■\n",
            "÷ ప్రస్తుతం స్టైలిష్ స్టార్ అల్లుఅర్జున్.. హరీశ్ శంకర్ డైరెక్షన్‌లో దువ్వాడ జగన్నాథం సినిమా చేస్తున్నాడు. ఇటీవలే సినిమాలో బన్నీ లుక్, టీజర్‌ను విడుదల చేశారు. ఈ టీజర్ ఈ మధ్య ట్రెండింగ్ అయింది. దానికి కారణం వేరే చెప్పాల్సిన అవసరం లేదేమో. అయితే తాజాగా బన్నీపై మరో గాసిప్ వినిపిస్తోంది. డీజే తర్వాత బన్నీ డైరెక్టర్ కావాలనుకుంటున్న రైటర్ వక్కంతం వంశీకి చాన్స్ ఇచ్చాడని తెలిసిందే. ఇప్పుడు వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చే అవకాశాలున్నాయని చెబుతున్నారు. ఎందుకంటే.. మధ్యలోకి ఓ సీనియర్ మాస్ డైరెక్టర్ ఎంట్రీ ఇచ్చాడట. ఆ డైరెక్టర్ ఎవరో కాదు.. అల్లు అర్జున్‌తో బన్నీ, బద్రీనాథ్ వంటి చిత్రాలను తీసిన డైరెక్టర్ వీవీ వినాయక్. ఖైదీ నంబర్  సినిమా తర్వాత ఏ హీరోతోనూ సినిమా కమిట్ అవ్వని వినాయక్.. బన్నీకి ఓ కథను వినిపించాడట. ఆ కథ బన్నీకి తెగ నచ్చేసిందట. దీంతో వినాయక్‌తో సినిమా తీసేందుకు ఓకే చెప్పాడట బన్నీ. కానీ, వక్కంతం వంశీ సినిమాను పక్కనబెట్టేసి వినాయక్ మూవీనే మొదట పట్టాలెక్కించే పనిలో ఉన్నాడట బన్నీ. ఈ లెక్కన చూస్తుంటే వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చినట్టేనా మరి!!! ■\n",
            "÷ ప్రిన్స్ మహేశ్‌బాబు హీరోగా మురుగదాస్ దర్శకత్వంలో వస్తున్న సినిమా 'స్పైడర్'. తెలుగు, తమిళ భాషల్లో ఏక కాలంలో తెరక్కుతోంది ఈ సినిమా. మహేశ్ సరసన రకుల్‌ప్రీత్ సింగ్ నటిస్తున్న ఈ మూవీ కోసం టాలీవుడ్ మాత్రమే కాదు.. కోలీవుడ్ కూడా ఆసక్తిగా ఎదురు చూస్తోంది. సినిమా ప్రస్తుతం షూటింగ్ పూర్తిచేసుకొని నిర్మాణాంతర పనులు జరుపుకుంటోంది. స్పైడర్ మూవీ ప్రీ రిలీజ్ ఈవెంట్ ఈ నెల న హైదరాబాద్‌లోని శిల్పకళా వేదికలో నిర్వహించనున్నారు.  కాగా ఈసినిమాకు సంబంధించిన ఓ తాజా సమాచారం ప్రస్తుతం సోషల్‌మీడియాలో చక్కర్లు కొడుతోంది. చిత్రం యొక్క తమిళ శాటిలైట్ హక్కులను సన్ టీవీ వారు భారీమొత్తం చెల్లించి కొనుగోలు చేశారని టాక్ వినిపిస్తోంది. ఈ సినిమా కోసం ప్రేక్షకలోకం వేయికళ్లతో ఎదురుచూస్తోంది. సెప్టెంబర్ న చిత్రం ప్రేక్షకులముందుకు రానుంది. ■\n",
            "÷ న్యూఢిల్లీ  (ఆంధ్రజ్యోతి): దేశంలోనే అత్యంత వేగంగా అభివృద్ధి చెందుతున్న పారిశ్రామిక పార్కుగా శ్రీసిటీ గుర్తింపుపొందింది. వైబ్రంట్‌ అండ్‌ ఫాస్టెస్ట్‌ గ్రోయింగ్‌ ఇండస్ట్రియల్‌ పార్క్‌ ఇన్‌ ఇండియా పేరిట అసోచామ్‌.. శ్రీసిటీకి అవార్డును ప్రకటించింది. బుధవారం నాడిక్కడ సెజ్‌లు, పారిశ్రామిక పార్కులపై జరిగిన వ అంతర్జాతీయ సదస్సులో కేంద్ర చిన్న మధ్య తరహా పరిశ్రమల శాఖ మంత్రి హరిభాయ్‌ ప్రతీభాయ్‌ చౌదరి చేతుల మీదుగా శ్రీ సిటీ ఫౌండేషన్‌ అధ్యక్షుడు రమేశ్‌ సుబ్రమణ్యం ఈ అవార్డును అందుకున్నారు. ఈ సందర్భంగా శ్రీసిటీ  మేనేజింగ్‌ డైరెక్టర్‌ రవీంద్ర సన్నారెడ్డి మాట్లాడుతూ.. ప్రతిష్టాత్మక అసోచామ్‌ అవార్డును అందుకోవడం చాలా సంతోషంగా ఉందని, ఉన్నత స్థాయి విలువలతో దేశంలో అతిపెద్ద బిజినెస్‌ సిటీగా తీర్చిదిద్దుతున్నామని తెలిపారు. ■\n",
            "÷ చెన్నై, డిసెంబరు (ఆంధ్రజ్యోతి): ఆర్‌కే నగర్‌ నియోజకవర్గ నామినేషన్ల వ్యవహారంలో ఎన్నికల అధికారులు తనకు అన్యాయం చేశారని, ఇది ప్రజాస్వామ్యానికి దుర్దినమని సినీ నటుడు విశాల్‌ అన్నారు. ఈ విషయమై రాష్ట్ర ఎన్నికల ప్రధానాధికారి రాజేశ్‌ లఖానీకి బుధవారం ఫిర్యాదు చేశారు. త్వరలో రాష్ట్ర గవర్నర్‌ భన్వరీలాల్‌ పురోహిత్‌కు కూడా ఫిర్యాదు చేస్తానని, తన వద్ద ఉన్న ఆధారాలతో కోర్టులోనూ సవాలు చేస్తానని విశాల్‌ ప్రకటించారు. ఎన్నికల అధికారుల తీరుపై అసంతృప్తి వ్యక్తం చేస్తూ ప్రధానికి, రాష్ట్రపతి కార్యాలయానికి కూడా ట్విటర్‌లో ఫిర్యాదు చేశారు. ■\n",
            "÷ న్యూఢిల్లీ: స్టేట్ బ్యాంక్ ఆఫ్ ఇండియాలో మరో బ్యాంక్ విలీనం కానుంది. భారతీయ మహిళా బ్యాంక్‌ను కూడా అందులో కలపాలని కేంద్ర ప్రభుత్వం సోమవారం నిర్ణయించింది. త్వరలో జరగనున్న అనుబంధ బ్యాంకుల విలీనంతో అతిపెద్ద జాతీయ బ్యాంకుగా ఎస్‌బిఐ అవతరించనుంది. మహిళల కోసం ప్రత్యేకంగా ఏర్పాటు చేసిన బ్యాంకును కూడా ఎస్‌బిఐతో అనుసంధానం చేయడంతో వారికి మరిన్ని సేవలు అందుబాటులోకి వస్తాయని కేంద్రం భావిస్తోంది. ■\n",
            "÷ లంచం ఇవ్వలేదన్న కారణంగా సె్ట్రచర్‌ ఇచ్చేది లేదంటూ కర్ణాటక రాష్ట్రం శివమొగ్గలోని మెగ్గాన ప్రభుత్వ ఆస్పత్రి సిబ్బంది మొండికేశారు. రెండు రోజులు కాళ్లా వేళ్లా పడి బతిమిలాడినా కనికరించలేదు. దీంతో ఆస్తమాతో బాధపడుతున్న భర్తకు ఎక్స్‌రే తీయించేందుకు నేలపై ఈడ్చుకుంటూ తీసుకెళ్లిందా వృద్ధురాలు. ఆస్తమాతో బాధపడుతున్న అమీర్‌()ను స్థానిక ప్రభుత్వ ఆస్పత్రిలో చేర్పించారు. ఎక్స్‌రే తీయించాలని, స్ర్టెచర్‌ లేదా వీల్‌చెయిర్‌ ఇవ్వాలని సిబ్బందిని అమీర్‌ భార్య ఫామిదా() కోరారు. ఇందుకు వారు లంచం అడిగారు. డబ్బు ఇచ్చుకోలే మంటూ రెండు రోజులు బతిమిలాడినా దయచూపలేదు. దీంతో ఫామిదా.. ఆయన కాళ్లు పట్టుకుని నేలపై ఈడ్చుకుంటూ తీసుకెళ్లింది. దీనికి సంబంఽధించిన వీడియో సోషల్‌మీడియాలో వైరల్‌లా పాకింది. విషయం తెలుసుకున్న రాష్ట్ర ఆరోగ్య మంత్రి రమేశకుమార్‌ నలుగురు ఉద్యోగులను సస్పెండ్‌ చేశారు.- బెంగళూరు (ఆంధ్రజ్యోతి) ■\n",
            "÷ ఆంధ్రజ్యోతి గల్ఫ్‌ ప్రతినిధి: ప్రపంచంలోనే భారీగా విద్యుత్‌ సంస్కరణలతో భారత్ ముందుకు వెళ్తోందని కేంద్ర విద్యుత్‌ మంత్రి పియూ ష్‌ గోయల్‌ పేర్కొన్నారు. ఇంధన రంగంలో మరిన్ని పునరుత్పాదక వనరులను గుర్తించే దిశగా ప్రపంచ దేశాలు కృషి చేయవల్సిన అవసరం ఉందన్నారు. ‘ఉజాల’ పథకం కింద రూ.. కోట్ల ఎల్‌ఈడీ విద్యుత్‌ బల్బులను వినియోగదారులకు అందించడం ద్వారా ఏటా రూ. వేల కోట్లు ఆదా చేయగలుగుతున్నామని చెప్పారు. ఆదివారం అబుధాబిలో జరిగిన ఒక అంతర్జాతీయ సదస్సులో మాట్లాడారు. ■\n",
            "÷ ఆధ్యాత్మిక భజన్లతో సంస్కార్‌ టీవీ ‘ఓం శాంతి ఓం’ రియాలిటీ షో అంతిమ దశకు చేరుకుంది. ఈ నెల ,  తేదీల్లో ప్రసారమవుతున్న చివరి ఎపిసోడ్‌ షూటింగ్‌ గత వారమే పూర్తయింది. అయితే ఈ ఎపిసోడ్‌ రాకముందే నలుగురు ఫైనలిస్టుల పేర్లు బయటకు వచ్చేశాయి. రియా భట్టాచార్య (),ప్రియా మాలిక్‌ (), ఆర్ఫిన్‌ రాణా మీర్‌ (), జైద్‌ అలీ () వీరిలో ఉన్నారు. బాలీవుడ్‌ తార సోనాక్షీ సిన్హా, ఆధ్యాత్మిక గురువు బాబా రామ్‌దేవ్‌ షోకు న్యాయనిర్ణేతలుగా వ్యవహరించారు. ■\n",
            "÷ బుల్లితెరపై కన్నడనాట ప్రేక్షకులకు కట్టిపడేస్తున్న బిగ్‌బాస్‌ వ ఎడిషన్‌ ప్రారంభమైంది. ఈసారి వ ఎడిషన్‌లో నటీనటులు, సెలెబ్రిటీలతోపాటు ముగ్గురు సామాన్య ప్రేక్షకులకు తమ ప్రతిభను ప్రదర్శించే అవకాశం కల్పించేందుకు నిర్వాహకులు నిర్ణయించారు. బిగ్‌బాస్‌ రియాలిటీ టైటిల్‌కోసం మొత్తం మంది పోటీపడతారు. ఇదే మొదటిసారి వీరిలో ముగ్గురు సామాన్య ప్రేక్షకులకు కూడా చోటు లభించనుంది.  బిగ్‌బాస్‌లో పాల్గొనదలిచే ప్రేక్షకులు ఓట్‌డాట్‌కామ్‌ ద్వారా నిముషాల తమ ప్రతిభతో కూడిన వీడియోను పంపుకోవాల్సి ఉంటుంది. బిగ్‌బాస్‌లో పాల్గొనేందుకు నాకున్న అర్హత అంటూ ప్రేక్షకులు తమను తాము అత్యంత భిన్నంగా ఈ వీడియోద్వారా పంపుకోవాల్సి ఉంటుంది. ఉత్తమమైన ముగ్గురిని ఎంపిక చేసి పోటీలో తలపడే అవకాశం కల్పిస్తారు. ■\n",
            "÷ న్యూఢిల్లీ: శ్రీలంక సీనియర్‌ స్పిన్నర్‌ రంగన హెరాత్‌ వెన్నునొప్పి కారణంగా చివరిదైన మూడో టెస్టుకు దూరం కానున్నాడు. అతడి స్థానంలో లెగ్‌ స్పిన్నర్‌ జెఫ్రీ వాండర్సేను జట్టులోకి తీసుకున్నారు. వచ్చే నెల  నుంచి ఫిరోజ్‌ షా కోట్ల మైదానంలో చివరి టెస్టు ప్రారంభం కానుంది. లెఫ్టార్మ్‌ స్పిన్నర్‌ మలింద పుష్పకుమారకు మొదట అవకాశం దక్కినా అతను ఫిట్‌నెస్‌ నిరూపించుకోలేకపోయాడు. పేస ర్లకు అనుకూలించిన తొలి టెస్టులో హెరాత్‌కు ఒక్క వికెట్‌ కూడా దక్కకపోగా రెండో టెస్టులో భారత స్పిన్నర్‌ అశ్విన్‌ విజృంభించిన చోట అతను మాత్రం  ఓవర్లలో  పరుగులకు ఒక్క వికెట్‌ మాత్రమే తీయగలిగాడు. ఇక వాండర్సే ఇప్పటిదాకా ఒక్క టెస్టు కూడా ఆడకపోగా,  వన్డేల్లో  వికెట్లు,  టీల్లో నాలుగు వికెట్లు తీశాడు. ■\n",
            "÷ బిల్లుకు పార్లమెంటు ఆమోదం న్యూఢిల్లీ, మార్చి : మానసిక అనారోగ్యంతో బాధపడుతున్నవారు ఆత్మహత్యాయత్నం చేస్తే వారిపై క్రిమినల్‌ కేసు లేకుండా చేసే ‘ద మెంటల్‌ హెల్త్‌కేర్‌’ బిల్లును లోక్‌సభ సోమవారం ఆమోదించింది. మానసిక రోగ పీడితుల హక్కులు, గౌరవానికి భంగం కలగకుండా మెరుగైన వైద్యసంరక్షణను హక్కుగా కల్పించే బిల్లు ఇది. రాజ్యసభలో ఈ బిల్లు గత ఏడాది ఆగస్టులో  సవరణలతో ఆమోదం పొందింది. దీని ప్రకారం.. మానసిక రోగపీడితులు ఆత్మహత్యా యత్నం చేస్తే వారిపై ఐపీసీ సెక్షన్ల కింద కేసు పెట్టడానికి ఉండదు. కాగా.. ఈ బిల్లుపై జరిగిన చర్చలో రవీంద్రబాబు(టీడీపీ), విశ్వేశ్వర రెడ్డి(టీఆర్‌ఎస్‌), బుట్టా రేణుక (వైసీపీ), అసదుద్దీన్‌ ఒవైసీ(ఎంఐఎం) సహా  మంది సభ్యులు పాల్గొన్నారు. ■\n",
            "÷ యువకులే మన దేశ సంపదమహారాష్ట్ర సిఎం ఫడ్నవీస్‌హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): నవి ముంబై ఎయిర్‌పోర్ట్‌ తొలి దశ  డిసెంబర్‌నాటికి ప్రారంభమవుతుందని మహారాష్ట్ర ముఖ్యమంత్రి దేవేంద్ర ఫడ్నవీస్‌ ప్రకటించారు. ఐఎస్‌బి నిర్వహించిన లీడర్‌షిప్‌ సదస్సులో ఫడ్నవీస్‌ ఈ విషయం తెలిపారు. భూమి, నిధుల సమీకరణలో ఎదురవుతున్న సమస్యల కారణంగా మార్చి,  వరకు ఈ ఎయిర్‌పోర్ట్‌ ప్రారంభమయ్యే అవకాశం లేదని వార్తలు వస్తున్న నేపధ్యంలో ఫడ్నవిస్‌ ఈ విషయం ప్రకటించడం విశేషం. ముంబై ఎయిర్‌పోర్ట్‌పై ఒత్తిడి తగ్గించేందుకు ప్రభుత్వం లోనే ఈ ప్రాజెక్టును ప్రతిపాదించింది. అయితే వివిధ కారణాలతో లో గానీ ప్రాజెక్టుకు ఆమోద ముద్ర పడలేదు. గత ఏడాది జరిగిన బిడ్డింగ్‌లో రూ., కోట్లకు జివికె గ్రూపు ఈ ప్రాజెక్టును దక్కించుకుంది. వచ్చే ఏడాది కల్లా ఈ ప్రాజెక్టుకు సంబంధించి భూమి చదును వంటి పనులు పూర్తి చేసి జివికె గ్రూపునకు అప్పగిస్తామని ఫడ్నవీస్‌ చెప్పారు. ■\n",
            "÷ హిందూమక్కల్‌ కట్చి వెల్లడిచెన్నై, జూన్ (ఆంధ్రజ్యోతి): తమిళ సూపర్‌స్టార్‌ రజనీకాంత రాజకీయాల్లోకి రావడం ఖాయమనే సంకేతాలు రోజురోజుకు బలపడుతున్నాయి. సోమవారం తనను కలిసిన హిందూమక్కల్‌ కట్చి నేతల వద్ద తను రాజకీయాల్లోకి రానున్నట్లు రజనీ పరోక్షంగా సంకేతాలిచ్చారు. అర్జునసంపత నేతృత్వంలోని పలువురు నేతలు సోమవారం రజనీ నివాసానికి వెళ్లి ఆయన్ని మర్యాద పూర్వకంగా కలుసుకున్నారు. అనంతరం వెలుపలికి వచ్చిన అర్జున మీడియాతో మాట్లాడుతూ.. సింహం సింగిల్‌గానే వస్తుందని వ్యాఖ్యానించారు. ‘రాషా్ట్రనికి, దేశానికి ఏదైనా చేయాలని ఉందని రజనీ అన్నారు. రాజకీయాల్లో చేరే అంశాన్ని పరిశీలిస్తున్నట్లు చెప్పారు’ అన్నారు. రజనీ రాజకీయాల్లోకి వస్తారని తాము గట్టిగా భావిస్తున్నట్లు ఆయన పేర్కొన్నారు. ■\n",
            "÷ రోజుకు  ఎంఎల్‌ మించి తాగొద్దు: ఐఎంఏన్యూఢిల్లీ, జూన్‌ : వైద్యులు ఇతరులతో కలిసి మద్యం తాగొద్దని ఇండియన్‌ మెడికల్‌ అసోసియేషన్‌ సూచించింది. సమాజం ముందు ‘ఆరోగ్యానికి బ్రాండ్‌ అంబాసిడర్‌’ లాగా ఉండాలని పిలుపునిచ్చింది. ‘జూలై  డాక్టర్స్‌ డే’ సందర్భంగా ఐఎంఏ సభ్యులైన వైద్యులకు లేఖలు రాసింది. ఒక మోతాదు మించి మద్యం తాగొద్దని వైద్యులకు సూచించింది. ఒక రోజులో పురుష డాక్టర్లు  ఎంఎల్‌, మహిళా డాక్టర్లు  ఎంఎల్‌ మించి మద్యం తాగరాదని కోరింది. ఐఎంఏ సమావేశాల్లో మద్యం సరఫరా చేయరాదని చెప్పింది. తమ దగ్గరకొచ్చే పేషంట్లకు ఇస్తున్న ఆరోగ్య సలహాలను వైద్యులు కూడా పాటించాలని, అది వారి బాధ్యతని తేల్చిచెప్పింది. రోగులతో మర్యాదగా వ్యవహరించాలని, వృత్తి గౌరవాన్ని కాపాడాలని కోరింది. రోగి డాక్టరును పూర్తిగా నమ్మే పరిస్థితి ఉండాలని చెప్పింది. ఒక్క డాక్టర్‌ తప్పుడు ప్రవర్తన మొత్తం వృత్తికే కళంకం తెస్తుందని హెచ్చరించింది. పొగాకురంగ పరిశ్రమలు నిర్వహించే కార్యక్రమాల్లో రాష్ట్ర ప్రభుత్వ అధికారులు పాల్గొనరాదని హిమాచల్‌ ప్రదేశ్‌ ప్రభుత్వం ఆదేశించింది. ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n",
            "÷ చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదు: విజయ్ దేవరకొండ ■\n",
            "÷ వార్న్‌ ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ కెప్టెన్‌ ధోనీ  ■\n",
            "÷ మేమిద్దరం తోడు దొంగలమే: బాలకృష్ణ ■\n",
            "÷ విదేశీ ఖాతాలను మూసేసిన కార్తి ■\n",
            "÷ ట్రెడా అధ్యక్షుడిగా రవీందర్‌ రావు  ■\n",
            "÷ వక్కంతం వంశీని బన్నీ పక్కన పెట్టేశాడా? ■\n",
            "÷ 'స్పైడర్' శాటిలైట్ హక్కులు చేజిక్కించుకున్న సన్ టీవీ ! ■\n",
            "÷ శ్రీసిటీకి అసోచామ్‌ అవార్డు ■\n",
            "÷ నామినేషన్‌ తిరస్కారం అన్యాయం: విశాల్‌ ■\n",
            "÷ ఎస్‌బిఐలో.. భారతీయ మహిళా బ్యాంక్ విలీనం ■\n",
            "÷ స్ట్రె‌చర్‌ లేక నేలపై ఈడ్చుకెళ్లి.. ■\n",
            "÷  ‘ఉజాల’తో  వేల కోట్ల ఆదా: గోయల్‌  ■\n",
            "÷ ‘ఓం శాంతి ఓం’ విజేతలు..?  ■\n",
            "÷ బిగ్‌బాస్‌ షోలో పాల్గొనాలనుకుంటున్నారా..! ■\n",
            "÷ చివరి టెస్టుకు హెరాత్‌ దూరం ■\n",
            "÷ మానసిక రోగుల ఆత్మహత్యాయత్నంపై కేసులుండవు  ■\n",
            "÷  నాటికి నవీ ముంబై ఎయిర్‌పోర్ట్‌ ■\n",
            "÷ రజనీ రాజకీయ ప్రవేశం ఖాయం! ■\n",
            "÷ డాక్టర్లూ... ఇతరులతో మందు కొట్టొద్దు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_AL9W9qq12"
      },
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIoL8wYncpc"
      },
      "source": [
        "def evaluate(sentence, max_length=40):\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  sentence = tf.convert_to_tensor([sentence])\n",
        "  sentence = bd_tokenizer.tokenize(sentence)\n",
        "  sentence = bd_tokenizer.string_to_id(sentence)\n",
        "  sentence = tf.dtypes.cast(sentence.to_tensor(),dtype=tf.int64)\n",
        "  encoder_input = sentence\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  start  = tf.convert_to_tensor('÷')\n",
        "  start= hd_tokenizer.tokenize(start)\n",
        "  output= hd_tokenizer.string_to_id(start)\n",
        "  end  = tf.convert_to_tensor('■')\n",
        "  end= hd_tokenizer.tokenize(end)\n",
        "  end= hd_tokenizer.string_to_id(end)[1]\n",
        "  end = tf.expand_dims(end, 0)\n",
        "  output = tf.expand_dims(output, 0)\n",
        "  for i in range(max_length):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions, axis=-1)\n",
        "    predicted_id = tf.dtypes.cast(predicted_id,dtype=tf.int32)\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == end:\n",
        "      break\n",
        "\n",
        "  # output.shape (1, tokens)\n",
        "  trans = hd_tokenizer.detokenize(output)# shape: ()\n",
        "  text = []\n",
        "  for x in trans.numpy():\n",
        "    text.append(x.decode('utf-8'))\n",
        "\n",
        "  return text, attention_weights"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTkU2cv8rUIP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13JVpiD_ZPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38b5600-0543-428d-ea69-a68e0955fe34"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ రోజుకు  ఎంఎల్‌ మించి తాగొద్దు: ఐఎంఏన్యూఢిల్లీ, జూన్‌ : వైద్యులు ఇతరులతో కలిసి మద్యం తాగొద్దని ఇండియన్‌ మెడికల్‌ అసోసియేషన్‌ సూచించింది. సమాజం ముందు ‘ఆరోగ్యానికి బ్రాండ్‌ అంబాసిడర్‌’ లాగా ఉండాలని పిలుపునిచ్చింది. ‘జూలై  డాక్టర్స్‌ డే’ సందర్భంగా ఐఎంఏ సభ్యులైన వైద్యులకు లేఖలు రాసింది. ఒక మోతాదు మించి మద్యం తాగొద్దని వైద్యులకు సూచించింది. ఒక రోజులో పురుష డాక్టర్లు  ఎంఎల్‌, మహిళా డాక్టర్లు  ఎంఎల్‌ మించి మద్యం తాగరాదని కోరింది. ఐఎంఏ సమావేశాల్లో మద్యం సరఫరా చేయరాదని చెప్పింది. తమ దగ్గరకొచ్చే పేషంట్లకు ఇస్తున్న ఆరోగ్య సలహాలను వైద్యులు కూడా పాటించాలని, అది వారి బాధ్యతని తేల్చిచెప్పింది. రోగులతో మర్యాదగా వ్యవహరించాలని, వృత్తి గౌరవాన్ని కాపాడాలని కోరింది. రోగి డాక్టరును పూర్తిగా నమ్మే పరిస్థితి ఉండాలని చెప్పింది. ఒక్క డాక్టర్‌ తప్పుడు ప్రవర్తన మొత్తం వృత్తికే కళంకం తెస్తుందని హెచ్చరించింది. పొగాకురంగ పరిశ్రమలు నిర్వహించే కార్యక్రమాల్లో రాష్ట్ర ప్రభుత్వ అధికారులు పాల్గొనరాదని హిమాచల్‌ ప్రదేశ్‌ ప్రభుత్వం ఆదేశించింది. ■\n",
            "Prediction     : ['÷ నేడు తేల్చిన నేనుందాడి హీరోయిన్... ■']\n",
            "Ground truth   : ÷ డాక్టర్లూ... ఇతరులతో మందు కొట్టొద్దు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf64hwjefvE",
        "outputId": "c86edc19-0a49-4c02-d634-a8d9c3d6f4d5"
      },
      "source": [
        "for bd_examples, hd_examples in test.batch(1).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgqqMTR9ehrP"
      },
      "source": [
        "translated_text, attention_weights = evaluate(sentence)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj6k4JYheo4G",
        "outputId": "c9c26950-5669-449b-bed7-76f04df57535"
      },
      "source": [
        "print_translation(sentence,translated_text,ground_truth)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "Prediction     : ['÷ దేశం విడిచి వెళ్లొద్దు : దినకరన్ ■']\n",
            "Ground truth   : ÷ బంజారా కథలకు ఆహ్వానం ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJrdnPVTh-k2",
        "outputId": "60ab12ec-373c-4032-8cc2-73877d7299d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s= []\n",
        "g = []\n",
        "\n",
        "for bd_examples, hd_examples in test.batch(20).take(1):\n",
        "  for bd in bd_examples.numpy():\n",
        "    print(bd.decode('utf-8'))\n",
        "    sentence = bd.decode('utf-8')\n",
        "    s.append(sentence)\n",
        "  print()\n",
        "\n",
        "  for hd in hd_examples.numpy():\n",
        "    print(hd.decode('utf-8'))\n",
        "    ground_truth = hd.decode('utf-8')\n",
        "    g.append(ground_truth)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "÷ \n",
            "బంజారాలు/ లంబాడీల జీవితాల గురించి కథల సంకల నాన్ని వెలువరిస్తున్నాం. ఆధునిక కాలంలో లంబాడీల జీవన విధానం, వేషధారణం, ఆహారం, భాష మొదలైనవి కనుమ రుగయ్యే పరిస్థితి ఏర్పడింది. వాటిని రికార్డు చేసే విధంగా వారికి సంబంధించిన ఏ ఇతివృత్తం తోనైనా వారి జీవితం గురించి, జీవన పోరాటాల గురించి కథలను డిసెంబర్‌ లోపు ఈమెయిల్‌ barasaa@gmail.com కు పంపాలి. వివరాలకు ఫోన్‌:  .- బంజారా రచయితల సంఘం ■\n",
            "÷ హైదరాబాద్: డ్రగ్స్, మందు అని మనం మాత్రమే అనుకుంటామని.... అర్జున్ రెడ్డి సినిమా చూసిన ప్రేక్షకుల మాత్రం చాలా బాగుందని హీరో విజయ్ దేవరకొండ అన్నారు. అర్జున్ రెడ్డి సినిమా వివాదంపై ఏబీఎన్ ఆంధ్రజ్యోతి లైవ్ షో నిర్వహించింది. ఈ కార్యక్రమంలో కాంగ్రెస్ ఎంపీ వీహెచ్‌తో పాటు  అర్జున్ రెడ్డి హీరో, దర్శకుడు పాల్గొన్నారు. సినిమా చూడని వాళ్లు మాత్రమే నిరసనలు  చేస్తున్నారని విజయ్ తెలిపారు. అర్జున్ రెడ్డి సినిమాలో చాలా సిగరెట్లు తాగానని.. బయట మాత్రం అలాంటి పనులు చేయనని చెప్పారు. చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదని అన్నారు. చాలా ప్రేమతో ఎంపీ వీహెచ్‌ను తాతయ్య అని అన్నానని..వాళ్ల మనవళ్లతో తిరుగుతాను కాబట్టే అలా అన్నానని విజయ్ తెలిపారు.తాతాయ్య అనడంలో బ్యాడ్ ఇన్ టెన్షన్ ఏమీ లేదని స్పష్టం చేశారు. ■\n",
            "÷ న్యూఢిల్లీ: షేన్‌ వార్న్‌ తన ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ జట్టుకు ధోనీని సారథిని చేసి గౌరవించాడు. ఈ మేరకు తన కలల ఐపీఎల్‌ జట్టును వార్న్‌ ప్రకటించాడు. విరాట్‌ కోహ్లీ, రోహిత శర్మ, యువరాజ్‌ సింగ్‌, రవీంద్ర జడేజా, హర్భజన్‌ సింగ్‌, ఉమేష్‌ యాదవ్‌లకు తన జట్టులో చోటు కల్పించాడు. విదేశీ ఆటగాళ్లుగా క్రిస్‌ గేల్‌, బ్రెండన్‌ మెకల్లమ్‌, జాక్‌ కలిస్‌, లసిత మలింగలను తీసుకున్నాడు. అలాగే విదేశీ కోటాలో ఒక్క ఆస్ర్టేలియా ఆటగాడిని కూడా వార్న్‌ తన జట్టులో చోటు కల్పించకపోవడం విశేషం. ■\n",
            "÷ తన ప్రతిష్టాత్మక వందో చిత్రమైన చారిత్రక సినిమా ‘గౌతమిపుత్ర శాతకర్ణి’ తెలుగు ప్రేక్షకులను మెప్పించడంతో బాలయ్య హర్షం వ్యక్తం చేస్తున్నారు. ఈ సందర్భంగా ‘ఏబీఎన్’తో ముచ్చటించిన బాలయ్య.. తన మనవడు దేవాన్ష్ గురించి ఆసక్తికర విషయాలను తెలియజేశారు. తన మనవడు దేవాన్ష్‌ గుర్రమంటే భయపడేవాడని, ఇప్పుడు తన సినిమా ‘శాతకర్ణి’ చూశాక ఆ భయం పోయి.. వాళ్ల అమ్మ కొనిచ్చిన గుర్రం బొమ్మపై ఎక్కి దాన్ని తోలుతున్నట్లు ఫీలయి సంతోషపడుతున్నాడని బాలయ్య చెప్పారు. తామిద్దరం తోడుదొంగలమేనంటూ దేవాన్ష్ గురించి బాలయ్య చెప్పిన మరిన్ని ఆసక్తికర విశేషాలు పై వీడియోలో చూడండి. ■\n",
            "÷ న్యూఢిల్లీ: విదేశీ బ్యాంకుల్లో తన పేర ఉన్న ఖాతాలను మూసివేస్తున్నందునే కేంద్ర మాజీ మంత్రి పి.చిదంబరం తనయుడు కార్తి దేశం విడిచి వెళ్లకుండా లుకవుట్‌ నోటీసు జారీ చేశామని సీబీఐ సుప్రీం కోర్టుకు తెలిపింది. దర్యాప్తునకు సంబంధించిన పత్రాలను సీల్డ్‌ కవర్‌లో న్యాయస్థానానికి సమర్పిస్తామని సీబీఐ కోరింది. ఈ సందర్భంగా అడిషనల్‌ సొలిసిటర్‌ జనరల్‌ (ఏఎ్‌సజీ) తుషార్‌ మెహతా తన వాదన వినిపిస్తూ విదేశాల్లో తనకు ఒక్కటే బ్యాంకు ఖాతా ఉందని విచారణలో చెప్పిన కార్తి... విదేశాలకు వెళ్లినప్పుడు పలు ఖాతాలను మూసివేశాడని తెలిపారు. ■\n",
            "÷ హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): తెలంగాణ రియల్‌ ఎస్టేట్‌ డెవలపర్స్‌ అసోసియేషన్‌ (ట్రెడా) కొత్త అధ్యక్షుడిగా పి రవీందర్‌ రావు ఎన్నికయ్యారు. శనివారం నాడిక్కడ జరిగిన వ వార్షిక సర్వసభ్య సమావేశంలో ఈ మేరకు కొత్త కార్యవర్గాన్ని ఎన్నుకున్నారు. ఎగ్జిక్యూటివ్‌ ఉపాధ్యక్షులుగా ఆర్‌ చలపతి రావు, విజయ్‌ సాయి, కార్యదర్శిగా సునీల్‌ చంద్రా రెడ్డి, కోశాధికారిగా కె శ్రీధర్‌ రెడ్డి ఎన్నికయ్యారు. రెండేళ్ల పాటు వీరు ఈ పదవిలో కొనసాగనున్నారు. ■\n",
            "÷ ప్రస్తుతం స్టైలిష్ స్టార్ అల్లుఅర్జున్.. హరీశ్ శంకర్ డైరెక్షన్‌లో దువ్వాడ జగన్నాథం సినిమా చేస్తున్నాడు. ఇటీవలే సినిమాలో బన్నీ లుక్, టీజర్‌ను విడుదల చేశారు. ఈ టీజర్ ఈ మధ్య ట్రెండింగ్ అయింది. దానికి కారణం వేరే చెప్పాల్సిన అవసరం లేదేమో. అయితే తాజాగా బన్నీపై మరో గాసిప్ వినిపిస్తోంది. డీజే తర్వాత బన్నీ డైరెక్టర్ కావాలనుకుంటున్న రైటర్ వక్కంతం వంశీకి చాన్స్ ఇచ్చాడని తెలిసిందే. ఇప్పుడు వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చే అవకాశాలున్నాయని చెబుతున్నారు. ఎందుకంటే.. మధ్యలోకి ఓ సీనియర్ మాస్ డైరెక్టర్ ఎంట్రీ ఇచ్చాడట. ఆ డైరెక్టర్ ఎవరో కాదు.. అల్లు అర్జున్‌తో బన్నీ, బద్రీనాథ్ వంటి చిత్రాలను తీసిన డైరెక్టర్ వీవీ వినాయక్. ఖైదీ నంబర్  సినిమా తర్వాత ఏ హీరోతోనూ సినిమా కమిట్ అవ్వని వినాయక్.. బన్నీకి ఓ కథను వినిపించాడట. ఆ కథ బన్నీకి తెగ నచ్చేసిందట. దీంతో వినాయక్‌తో సినిమా తీసేందుకు ఓకే చెప్పాడట బన్నీ. కానీ, వక్కంతం వంశీ సినిమాను పక్కనబెట్టేసి వినాయక్ మూవీనే మొదట పట్టాలెక్కించే పనిలో ఉన్నాడట బన్నీ. ఈ లెక్కన చూస్తుంటే వక్కంతం వంశీకి బన్నీ హ్యాండిచ్చినట్టేనా మరి!!! ■\n",
            "÷ ప్రిన్స్ మహేశ్‌బాబు హీరోగా మురుగదాస్ దర్శకత్వంలో వస్తున్న సినిమా 'స్పైడర్'. తెలుగు, తమిళ భాషల్లో ఏక కాలంలో తెరక్కుతోంది ఈ సినిమా. మహేశ్ సరసన రకుల్‌ప్రీత్ సింగ్ నటిస్తున్న ఈ మూవీ కోసం టాలీవుడ్ మాత్రమే కాదు.. కోలీవుడ్ కూడా ఆసక్తిగా ఎదురు చూస్తోంది. సినిమా ప్రస్తుతం షూటింగ్ పూర్తిచేసుకొని నిర్మాణాంతర పనులు జరుపుకుంటోంది. స్పైడర్ మూవీ ప్రీ రిలీజ్ ఈవెంట్ ఈ నెల న హైదరాబాద్‌లోని శిల్పకళా వేదికలో నిర్వహించనున్నారు.  కాగా ఈసినిమాకు సంబంధించిన ఓ తాజా సమాచారం ప్రస్తుతం సోషల్‌మీడియాలో చక్కర్లు కొడుతోంది. చిత్రం యొక్క తమిళ శాటిలైట్ హక్కులను సన్ టీవీ వారు భారీమొత్తం చెల్లించి కొనుగోలు చేశారని టాక్ వినిపిస్తోంది. ఈ సినిమా కోసం ప్రేక్షకలోకం వేయికళ్లతో ఎదురుచూస్తోంది. సెప్టెంబర్ న చిత్రం ప్రేక్షకులముందుకు రానుంది. ■\n",
            "÷ న్యూఢిల్లీ  (ఆంధ్రజ్యోతి): దేశంలోనే అత్యంత వేగంగా అభివృద్ధి చెందుతున్న పారిశ్రామిక పార్కుగా శ్రీసిటీ గుర్తింపుపొందింది. వైబ్రంట్‌ అండ్‌ ఫాస్టెస్ట్‌ గ్రోయింగ్‌ ఇండస్ట్రియల్‌ పార్క్‌ ఇన్‌ ఇండియా పేరిట అసోచామ్‌.. శ్రీసిటీకి అవార్డును ప్రకటించింది. బుధవారం నాడిక్కడ సెజ్‌లు, పారిశ్రామిక పార్కులపై జరిగిన వ అంతర్జాతీయ సదస్సులో కేంద్ర చిన్న మధ్య తరహా పరిశ్రమల శాఖ మంత్రి హరిభాయ్‌ ప్రతీభాయ్‌ చౌదరి చేతుల మీదుగా శ్రీ సిటీ ఫౌండేషన్‌ అధ్యక్షుడు రమేశ్‌ సుబ్రమణ్యం ఈ అవార్డును అందుకున్నారు. ఈ సందర్భంగా శ్రీసిటీ  మేనేజింగ్‌ డైరెక్టర్‌ రవీంద్ర సన్నారెడ్డి మాట్లాడుతూ.. ప్రతిష్టాత్మక అసోచామ్‌ అవార్డును అందుకోవడం చాలా సంతోషంగా ఉందని, ఉన్నత స్థాయి విలువలతో దేశంలో అతిపెద్ద బిజినెస్‌ సిటీగా తీర్చిదిద్దుతున్నామని తెలిపారు. ■\n",
            "÷ చెన్నై, డిసెంబరు (ఆంధ్రజ్యోతి): ఆర్‌కే నగర్‌ నియోజకవర్గ నామినేషన్ల వ్యవహారంలో ఎన్నికల అధికారులు తనకు అన్యాయం చేశారని, ఇది ప్రజాస్వామ్యానికి దుర్దినమని సినీ నటుడు విశాల్‌ అన్నారు. ఈ విషయమై రాష్ట్ర ఎన్నికల ప్రధానాధికారి రాజేశ్‌ లఖానీకి బుధవారం ఫిర్యాదు చేశారు. త్వరలో రాష్ట్ర గవర్నర్‌ భన్వరీలాల్‌ పురోహిత్‌కు కూడా ఫిర్యాదు చేస్తానని, తన వద్ద ఉన్న ఆధారాలతో కోర్టులోనూ సవాలు చేస్తానని విశాల్‌ ప్రకటించారు. ఎన్నికల అధికారుల తీరుపై అసంతృప్తి వ్యక్తం చేస్తూ ప్రధానికి, రాష్ట్రపతి కార్యాలయానికి కూడా ట్విటర్‌లో ఫిర్యాదు చేశారు. ■\n",
            "÷ న్యూఢిల్లీ: స్టేట్ బ్యాంక్ ఆఫ్ ఇండియాలో మరో బ్యాంక్ విలీనం కానుంది. భారతీయ మహిళా బ్యాంక్‌ను కూడా అందులో కలపాలని కేంద్ర ప్రభుత్వం సోమవారం నిర్ణయించింది. త్వరలో జరగనున్న అనుబంధ బ్యాంకుల విలీనంతో అతిపెద్ద జాతీయ బ్యాంకుగా ఎస్‌బిఐ అవతరించనుంది. మహిళల కోసం ప్రత్యేకంగా ఏర్పాటు చేసిన బ్యాంకును కూడా ఎస్‌బిఐతో అనుసంధానం చేయడంతో వారికి మరిన్ని సేవలు అందుబాటులోకి వస్తాయని కేంద్రం భావిస్తోంది. ■\n",
            "÷ లంచం ఇవ్వలేదన్న కారణంగా సె్ట్రచర్‌ ఇచ్చేది లేదంటూ కర్ణాటక రాష్ట్రం శివమొగ్గలోని మెగ్గాన ప్రభుత్వ ఆస్పత్రి సిబ్బంది మొండికేశారు. రెండు రోజులు కాళ్లా వేళ్లా పడి బతిమిలాడినా కనికరించలేదు. దీంతో ఆస్తమాతో బాధపడుతున్న భర్తకు ఎక్స్‌రే తీయించేందుకు నేలపై ఈడ్చుకుంటూ తీసుకెళ్లిందా వృద్ధురాలు. ఆస్తమాతో బాధపడుతున్న అమీర్‌()ను స్థానిక ప్రభుత్వ ఆస్పత్రిలో చేర్పించారు. ఎక్స్‌రే తీయించాలని, స్ర్టెచర్‌ లేదా వీల్‌చెయిర్‌ ఇవ్వాలని సిబ్బందిని అమీర్‌ భార్య ఫామిదా() కోరారు. ఇందుకు వారు లంచం అడిగారు. డబ్బు ఇచ్చుకోలే మంటూ రెండు రోజులు బతిమిలాడినా దయచూపలేదు. దీంతో ఫామిదా.. ఆయన కాళ్లు పట్టుకుని నేలపై ఈడ్చుకుంటూ తీసుకెళ్లింది. దీనికి సంబంఽధించిన వీడియో సోషల్‌మీడియాలో వైరల్‌లా పాకింది. విషయం తెలుసుకున్న రాష్ట్ర ఆరోగ్య మంత్రి రమేశకుమార్‌ నలుగురు ఉద్యోగులను సస్పెండ్‌ చేశారు.- బెంగళూరు (ఆంధ్రజ్యోతి) ■\n",
            "÷ ఆంధ్రజ్యోతి గల్ఫ్‌ ప్రతినిధి: ప్రపంచంలోనే భారీగా విద్యుత్‌ సంస్కరణలతో భారత్ ముందుకు వెళ్తోందని కేంద్ర విద్యుత్‌ మంత్రి పియూ ష్‌ గోయల్‌ పేర్కొన్నారు. ఇంధన రంగంలో మరిన్ని పునరుత్పాదక వనరులను గుర్తించే దిశగా ప్రపంచ దేశాలు కృషి చేయవల్సిన అవసరం ఉందన్నారు. ‘ఉజాల’ పథకం కింద రూ.. కోట్ల ఎల్‌ఈడీ విద్యుత్‌ బల్బులను వినియోగదారులకు అందించడం ద్వారా ఏటా రూ. వేల కోట్లు ఆదా చేయగలుగుతున్నామని చెప్పారు. ఆదివారం అబుధాబిలో జరిగిన ఒక అంతర్జాతీయ సదస్సులో మాట్లాడారు. ■\n",
            "÷ ఆధ్యాత్మిక భజన్లతో సంస్కార్‌ టీవీ ‘ఓం శాంతి ఓం’ రియాలిటీ షో అంతిమ దశకు చేరుకుంది. ఈ నెల ,  తేదీల్లో ప్రసారమవుతున్న చివరి ఎపిసోడ్‌ షూటింగ్‌ గత వారమే పూర్తయింది. అయితే ఈ ఎపిసోడ్‌ రాకముందే నలుగురు ఫైనలిస్టుల పేర్లు బయటకు వచ్చేశాయి. రియా భట్టాచార్య (),ప్రియా మాలిక్‌ (), ఆర్ఫిన్‌ రాణా మీర్‌ (), జైద్‌ అలీ () వీరిలో ఉన్నారు. బాలీవుడ్‌ తార సోనాక్షీ సిన్హా, ఆధ్యాత్మిక గురువు బాబా రామ్‌దేవ్‌ షోకు న్యాయనిర్ణేతలుగా వ్యవహరించారు. ■\n",
            "÷ బుల్లితెరపై కన్నడనాట ప్రేక్షకులకు కట్టిపడేస్తున్న బిగ్‌బాస్‌ వ ఎడిషన్‌ ప్రారంభమైంది. ఈసారి వ ఎడిషన్‌లో నటీనటులు, సెలెబ్రిటీలతోపాటు ముగ్గురు సామాన్య ప్రేక్షకులకు తమ ప్రతిభను ప్రదర్శించే అవకాశం కల్పించేందుకు నిర్వాహకులు నిర్ణయించారు. బిగ్‌బాస్‌ రియాలిటీ టైటిల్‌కోసం మొత్తం మంది పోటీపడతారు. ఇదే మొదటిసారి వీరిలో ముగ్గురు సామాన్య ప్రేక్షకులకు కూడా చోటు లభించనుంది.  బిగ్‌బాస్‌లో పాల్గొనదలిచే ప్రేక్షకులు ఓట్‌డాట్‌కామ్‌ ద్వారా నిముషాల తమ ప్రతిభతో కూడిన వీడియోను పంపుకోవాల్సి ఉంటుంది. బిగ్‌బాస్‌లో పాల్గొనేందుకు నాకున్న అర్హత అంటూ ప్రేక్షకులు తమను తాము అత్యంత భిన్నంగా ఈ వీడియోద్వారా పంపుకోవాల్సి ఉంటుంది. ఉత్తమమైన ముగ్గురిని ఎంపిక చేసి పోటీలో తలపడే అవకాశం కల్పిస్తారు. ■\n",
            "÷ న్యూఢిల్లీ: శ్రీలంక సీనియర్‌ స్పిన్నర్‌ రంగన హెరాత్‌ వెన్నునొప్పి కారణంగా చివరిదైన మూడో టెస్టుకు దూరం కానున్నాడు. అతడి స్థానంలో లెగ్‌ స్పిన్నర్‌ జెఫ్రీ వాండర్సేను జట్టులోకి తీసుకున్నారు. వచ్చే నెల  నుంచి ఫిరోజ్‌ షా కోట్ల మైదానంలో చివరి టెస్టు ప్రారంభం కానుంది. లెఫ్టార్మ్‌ స్పిన్నర్‌ మలింద పుష్పకుమారకు మొదట అవకాశం దక్కినా అతను ఫిట్‌నెస్‌ నిరూపించుకోలేకపోయాడు. పేస ర్లకు అనుకూలించిన తొలి టెస్టులో హెరాత్‌కు ఒక్క వికెట్‌ కూడా దక్కకపోగా రెండో టెస్టులో భారత స్పిన్నర్‌ అశ్విన్‌ విజృంభించిన చోట అతను మాత్రం  ఓవర్లలో  పరుగులకు ఒక్క వికెట్‌ మాత్రమే తీయగలిగాడు. ఇక వాండర్సే ఇప్పటిదాకా ఒక్క టెస్టు కూడా ఆడకపోగా,  వన్డేల్లో  వికెట్లు,  టీల్లో నాలుగు వికెట్లు తీశాడు. ■\n",
            "÷ బిల్లుకు పార్లమెంటు ఆమోదం న్యూఢిల్లీ, మార్చి : మానసిక అనారోగ్యంతో బాధపడుతున్నవారు ఆత్మహత్యాయత్నం చేస్తే వారిపై క్రిమినల్‌ కేసు లేకుండా చేసే ‘ద మెంటల్‌ హెల్త్‌కేర్‌’ బిల్లును లోక్‌సభ సోమవారం ఆమోదించింది. మానసిక రోగ పీడితుల హక్కులు, గౌరవానికి భంగం కలగకుండా మెరుగైన వైద్యసంరక్షణను హక్కుగా కల్పించే బిల్లు ఇది. రాజ్యసభలో ఈ బిల్లు గత ఏడాది ఆగస్టులో  సవరణలతో ఆమోదం పొందింది. దీని ప్రకారం.. మానసిక రోగపీడితులు ఆత్మహత్యా యత్నం చేస్తే వారిపై ఐపీసీ సెక్షన్ల కింద కేసు పెట్టడానికి ఉండదు. కాగా.. ఈ బిల్లుపై జరిగిన చర్చలో రవీంద్రబాబు(టీడీపీ), విశ్వేశ్వర రెడ్డి(టీఆర్‌ఎస్‌), బుట్టా రేణుక (వైసీపీ), అసదుద్దీన్‌ ఒవైసీ(ఎంఐఎం) సహా  మంది సభ్యులు పాల్గొన్నారు. ■\n",
            "÷ యువకులే మన దేశ సంపదమహారాష్ట్ర సిఎం ఫడ్నవీస్‌హైదరాబాద్‌ (ఆంధ్రజ్యోతి బిజినెస్‌): నవి ముంబై ఎయిర్‌పోర్ట్‌ తొలి దశ  డిసెంబర్‌నాటికి ప్రారంభమవుతుందని మహారాష్ట్ర ముఖ్యమంత్రి దేవేంద్ర ఫడ్నవీస్‌ ప్రకటించారు. ఐఎస్‌బి నిర్వహించిన లీడర్‌షిప్‌ సదస్సులో ఫడ్నవీస్‌ ఈ విషయం తెలిపారు. భూమి, నిధుల సమీకరణలో ఎదురవుతున్న సమస్యల కారణంగా మార్చి,  వరకు ఈ ఎయిర్‌పోర్ట్‌ ప్రారంభమయ్యే అవకాశం లేదని వార్తలు వస్తున్న నేపధ్యంలో ఫడ్నవిస్‌ ఈ విషయం ప్రకటించడం విశేషం. ముంబై ఎయిర్‌పోర్ట్‌పై ఒత్తిడి తగ్గించేందుకు ప్రభుత్వం లోనే ఈ ప్రాజెక్టును ప్రతిపాదించింది. అయితే వివిధ కారణాలతో లో గానీ ప్రాజెక్టుకు ఆమోద ముద్ర పడలేదు. గత ఏడాది జరిగిన బిడ్డింగ్‌లో రూ., కోట్లకు జివికె గ్రూపు ఈ ప్రాజెక్టును దక్కించుకుంది. వచ్చే ఏడాది కల్లా ఈ ప్రాజెక్టుకు సంబంధించి భూమి చదును వంటి పనులు పూర్తి చేసి జివికె గ్రూపునకు అప్పగిస్తామని ఫడ్నవీస్‌ చెప్పారు. ■\n",
            "÷ హిందూమక్కల్‌ కట్చి వెల్లడిచెన్నై, జూన్ (ఆంధ్రజ్యోతి): తమిళ సూపర్‌స్టార్‌ రజనీకాంత రాజకీయాల్లోకి రావడం ఖాయమనే సంకేతాలు రోజురోజుకు బలపడుతున్నాయి. సోమవారం తనను కలిసిన హిందూమక్కల్‌ కట్చి నేతల వద్ద తను రాజకీయాల్లోకి రానున్నట్లు రజనీ పరోక్షంగా సంకేతాలిచ్చారు. అర్జునసంపత నేతృత్వంలోని పలువురు నేతలు సోమవారం రజనీ నివాసానికి వెళ్లి ఆయన్ని మర్యాద పూర్వకంగా కలుసుకున్నారు. అనంతరం వెలుపలికి వచ్చిన అర్జున మీడియాతో మాట్లాడుతూ.. సింహం సింగిల్‌గానే వస్తుందని వ్యాఖ్యానించారు. ‘రాషా్ట్రనికి, దేశానికి ఏదైనా చేయాలని ఉందని రజనీ అన్నారు. రాజకీయాల్లో చేరే అంశాన్ని పరిశీలిస్తున్నట్లు చెప్పారు’ అన్నారు. రజనీ రాజకీయాల్లోకి వస్తారని తాము గట్టిగా భావిస్తున్నట్లు ఆయన పేర్కొన్నారు. ■\n",
            "÷ రోజుకు  ఎంఎల్‌ మించి తాగొద్దు: ఐఎంఏన్యూఢిల్లీ, జూన్‌ : వైద్యులు ఇతరులతో కలిసి మద్యం తాగొద్దని ఇండియన్‌ మెడికల్‌ అసోసియేషన్‌ సూచించింది. సమాజం ముందు ‘ఆరోగ్యానికి బ్రాండ్‌ అంబాసిడర్‌’ లాగా ఉండాలని పిలుపునిచ్చింది. ‘జూలై  డాక్టర్స్‌ డే’ సందర్భంగా ఐఎంఏ సభ్యులైన వైద్యులకు లేఖలు రాసింది. ఒక మోతాదు మించి మద్యం తాగొద్దని వైద్యులకు సూచించింది. ఒక రోజులో పురుష డాక్టర్లు  ఎంఎల్‌, మహిళా డాక్టర్లు  ఎంఎల్‌ మించి మద్యం తాగరాదని కోరింది. ఐఎంఏ సమావేశాల్లో మద్యం సరఫరా చేయరాదని చెప్పింది. తమ దగ్గరకొచ్చే పేషంట్లకు ఇస్తున్న ఆరోగ్య సలహాలను వైద్యులు కూడా పాటించాలని, అది వారి బాధ్యతని తేల్చిచెప్పింది. రోగులతో మర్యాదగా వ్యవహరించాలని, వృత్తి గౌరవాన్ని కాపాడాలని కోరింది. రోగి డాక్టరును పూర్తిగా నమ్మే పరిస్థితి ఉండాలని చెప్పింది. ఒక్క డాక్టర్‌ తప్పుడు ప్రవర్తన మొత్తం వృత్తికే కళంకం తెస్తుందని హెచ్చరించింది. పొగాకురంగ పరిశ్రమలు నిర్వహించే కార్యక్రమాల్లో రాష్ట్ర ప్రభుత్వ అధికారులు పాల్గొనరాదని హిమాచల్‌ ప్రదేశ్‌ ప్రభుత్వం ఆదేశించింది. ■\n",
            "\n",
            "÷ బంజారా కథలకు ఆహ్వానం ■\n",
            "÷ చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదు: విజయ్ దేవరకొండ ■\n",
            "÷ వార్న్‌ ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ కెప్టెన్‌ ధోనీ  ■\n",
            "÷ మేమిద్దరం తోడు దొంగలమే: బాలకృష్ణ ■\n",
            "÷ విదేశీ ఖాతాలను మూసేసిన కార్తి ■\n",
            "÷ ట్రెడా అధ్యక్షుడిగా రవీందర్‌ రావు  ■\n",
            "÷ వక్కంతం వంశీని బన్నీ పక్కన పెట్టేశాడా? ■\n",
            "÷ 'స్పైడర్' శాటిలైట్ హక్కులు చేజిక్కించుకున్న సన్ టీవీ ! ■\n",
            "÷ శ్రీసిటీకి అసోచామ్‌ అవార్డు ■\n",
            "÷ నామినేషన్‌ తిరస్కారం అన్యాయం: విశాల్‌ ■\n",
            "÷ ఎస్‌బిఐలో.. భారతీయ మహిళా బ్యాంక్ విలీనం ■\n",
            "÷ స్ట్రె‌చర్‌ లేక నేలపై ఈడ్చుకెళ్లి.. ■\n",
            "÷  ‘ఉజాల’తో  వేల కోట్ల ఆదా: గోయల్‌  ■\n",
            "÷ ‘ఓం శాంతి ఓం’ విజేతలు..?  ■\n",
            "÷ బిగ్‌బాస్‌ షోలో పాల్గొనాలనుకుంటున్నారా..! ■\n",
            "÷ చివరి టెస్టుకు హెరాత్‌ దూరం ■\n",
            "÷ మానసిక రోగుల ఆత్మహత్యాయత్నంపై కేసులుండవు  ■\n",
            "÷  నాటికి నవీ ముంబై ఎయిర్‌పోర్ట్‌ ■\n",
            "÷ రజనీ రాజకీయ ప్రవేశం ఖాయం! ■\n",
            "÷ డాక్టర్లూ... ఇతరులతో మందు కొట్టొద్దు ■\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26tBlzafkOOm"
      },
      "source": [
        "r = []\n",
        "for x in s:\n",
        "  translated_text, attention_weights = evaluate(x)\n",
        "  r.append(translated_text)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0scMdjAk3uW"
      },
      "source": [
        "def print_trans(tokens, ground_truth):\n",
        "  print(f'{\"Prediction\":15s}: {tokens}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
        "  print()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhuOrEFdkwrS",
        "outputId": "b4168f8d-c900-4bd4-ee0f-16c5f27009b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(20):\n",
        "  print_trans(r[i],g[i])\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction     : ['÷ దేశం విడిచి వెళ్లొద్దు : దినకరన్ ■']\n",
            "Ground truth   : ÷ బంజారా కథలకు ఆహ్వానం ■\n",
            "\n",
            "Prediction     : ['÷ ఎన్నికల్లో పోటీ చేస్తా : టాప్ హీరోయిన్ ■']\n",
            "Ground truth   : ÷ చెడిపోయే వాళ్లు ఎలాగైనా చెడిపోతారు.. సినిమాల వల్ల కాదు: విజయ్ దేవరకొండ ■\n",
            "\n",
            "Prediction     : ['÷ ధోనీకి హిందుద్.. ధోనీకి టీమిండియా కోచ్ ■']\n",
            "Ground truth   : ÷ వార్న్‌ ఆల్‌టైమ్‌ ఐపీఎల్‌ టీమ్‌ కెప్టెన్‌ ధోనీ  ■\n",
            "\n",
            "Prediction     : ['÷ కుమార్తెతో సెల్ఫీ కాదు లేచిరా? ■']\n",
            "Ground truth   : ÷ మేమిద్దరం తోడు దొంగలమే: బాలకృష్ణ ■\n",
            "\n",
            "Prediction     : ['÷ ఏడాదిలో అధికారం బిజెపిస్ కు బై ■']\n",
            "Ground truth   : ÷ విదేశీ ఖాతాలను మూసేసిన కార్తి ■\n",
            "\n",
            "Prediction     : ['÷ త్వరలో కొత్త చైర్మన్ గా నందకుమార్ ■']\n",
            "Ground truth   : ÷ ట్రెడా అధ్యక్షుడిగా రవీందర్‌ రావు  ■\n",
            "\n",
            "Prediction     : ['÷ బన్నీ న్నీ చాలా సమాధానం : రానారాయ్ ఏమన్నారాయ్ ■']\n",
            "Ground truth   : ÷ వక్కంతం వంశీని బన్నీ పక్కన పెట్టేశాడా? ■\n",
            "\n",
            "Prediction     : ['÷ మరోసారిడర్ సినిమా చూసిన మహేశ్ సోదరిష్ ఏమన్నాడో తెలుసా.. ■']\n",
            "Ground truth   : ÷ 'స్పైడర్' శాటిలైట్ హక్కులు చేజిక్కించుకున్న సన్ టీవీ ! ■\n",
            "\n",
            "Prediction     : ['÷ డిజిటల్ టెక్నాలజీతో ప్లస్ గుడ్ లు ■']\n",
            "Ground truth   : ÷ శ్రీసిటీకి అసోచామ్‌ అవార్డు ■\n",
            "\n",
            "Prediction     : ['÷ మహేష్ , ఎన్టీయార్ ఫ్యాన్స్ కు ధన్యవాదాలు: హరీష్ శంకర్ ■']\n",
            "Ground truth   : ÷ నామినేషన్‌ తిరస్కారం అన్యాయం: విశాల్‌ ■\n",
            "\n",
            "Prediction     : ['÷ ఎస్కార్ట్స్ లో తగ్గిన ప్రమోటర్ల పిలు ■']\n",
            "Ground truth   : ÷ ఎస్‌బిఐలో.. భారతీయ మహిళా బ్యాంక్ విలీనం ■\n",
            "\n",
            "Prediction     : ['÷ రెండో టీకి పది తుపాకులు.. ■']\n",
            "Ground truth   : ÷ స్ట్రె‌చర్‌ లేక నేలపై ఈడ్చుకెళ్లి.. ■\n",
            "\n",
            "Prediction     : ['÷ ఢిల్లీ చేరిన ఆఫ్గేజ్ మెంట్ , కూల్ కశ్మీర్ లో భేటీ ■']\n",
            "Ground truth   : ÷  ‘ఉజాల’తో  వేల కోట్ల ఆదా: గోయల్‌  ■\n",
            "\n",
            "Prediction     : ['÷ ‘మాద్యాకెట్ జాసాని’ లేదట! ■']\n",
            "Ground truth   : ÷ ‘ఓం శాంతి ఓం’ విజేతలు..?  ■\n",
            "\n",
            "Prediction     : ['÷ నాకు నచ్చకపోతే.స్కూ రిజర్వేషన్స్ ఇవ్వాలి ■']\n",
            "Ground truth   : ÷ బిగ్‌బాస్‌ షోలో పాల్గొనాలనుకుంటున్నారా..! ■\n",
            "\n",
            "Prediction     : ['÷ మహిళా మేర్ సర్వీస్ హ్యాట్రిక్ ■']\n",
            "Ground truth   : ÷ చివరి టెస్టుకు హెరాత్‌ దూరం ■\n",
            "\n",
            "Prediction     : ['÷ తమిళనాడు ఇన్ చార్జ్ పై సుప్రీంలో పిటిషన్ ■']\n",
            "Ground truth   : ÷ మానసిక రోగుల ఆత్మహత్యాయత్నంపై కేసులుండవు  ■\n",
            "\n",
            "Prediction     : ['÷ వరల్డ్ స్కిల్ ఒలింపిక్స్ కు కేంద్ర మంత్రి ■']\n",
            "Ground truth   : ÷  నాటికి నవీ ముంబై ఎయిర్‌పోర్ట్‌ ■\n",
            "\n",
            "Prediction     : ['÷ టెక్ వ్యూ : బాలీవుడ్ లో విఫైన్ ■']\n",
            "Ground truth   : ÷ రజనీ రాజకీయ ప్రవేశం ఖాయం! ■\n",
            "\n",
            "Prediction     : ['÷ నేడు తేల్చిన నేనుందాడి హీరోయిన్... ■']\n",
            "Ground truth   : ÷ డాక్టర్లూ... ఇతరులతో మందు కొట్టొద్దు ■\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}